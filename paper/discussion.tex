\section{Discussion \& Future Work}
\label{sec:discussion}

% \wajih{Explain in the discussion section why we chose GraphSage over GCN and TGN and then in the design section you "say the detailed disscussion on why we chose GraphSage blah blah"}

\PP{Reason for Combining FL with \gnnshort} APTs involve causally linked steps across system entities, best modeled by provenance graphs~\cite{inam2023sok}. Traditional log-level systems~\cite{deeplog2017,liu2019log2vec,xia2019loggan} fail to capture these relationships, whereas graph learning techniques effectively detect such patterns~\cite{flash2024,cheng2023kairos,jia2023magic}. By integrating FL with graph representation learning, \Sys enables decentralized, privacy-preserving intrusion detection without sacrificing accuracy.



\PP{Alert Investigation} Validating alerts in systems like \Sys is critical for reliability and avoiding alert fatigue~\cite{nodoze2019}. Traditionally, security analysts manually review alerts based on activities within local provenance graphs, but this process is time-consuming, error-prone, and lacks scalability and privacy. Privacy-preserving techniques such as Secure Multi-party Computation (SMC)~\cite{goldreich1998secure}, Homomorphic Encryption (HE)~\cite{yi2014homomorphic}, and Zero-Knowledge Proofs (ZKP)~\cite{fiege1987zero} can address these challenges. SMC enables collaborative alert validation while preserving input privacy, HE ensures confidentiality during encrypted data analysis, and ZKP allows one party to prove an alert's validity without revealing additional information. We identify privacy-preserving alert verification as a promising research direction. We leave it to future work to develop methods for privately sharing alert data with a central server, enabling security analysts to perform more in-depth attack analysis.

\PP{Explainability} Deep learning models used in \pids, including \Sys, function as black-box systems, making it challenging to interpret their decision-making processes. Like other \pids~\cite{flash2024,cheng2023kairos,yangprographer}, \Sys faces this interpretability issue, which hampers its adoption compared to rule-based systems. Existing explainability techniques~\cite{antwarg2021explaining,brown2018recurrent,ardito2021revisiting,hwang2021sfd} primarily focus on metrics like feature importance. However, modern \pids employ complex feature engineering, such as \flash's use of \wordvec for textual attribute processing and subsequent anomaly detection via \gnn models. This multi-model approach limits the applicability of existing explainable AI techniques. We identify explainable \pids as a critical area for future research. Recent advancements in LLMs~\cite{chang2024survey} offer potential solutions. Future research can leverage LLMs' reasoning capabilities to develop methods for interpreting \pids outputs effectively.


\PP{Log Retention} Effective retention~\cite{wilbert2012log,rapsheet2020} is essential for investigating long-running APTs. In decentralized systems like \Sys and \disdet, local storage constraints limit log history. To mitigate this, \Sys can integrate secure, tamper-resistant cloud storage~\cite{kumar2018secure,hardlog} for backups. During investigations, logs linked to alerts can be retrieved and sanitized~\cite{portillo2019towards} to preserve privacy while enabling detailed analysis.



\PP{Concept Drift} Concept drift occurs when the data distribution of the system evolves over time, potentially invalidating the patterns learned by \Sys during training. Emerging system activities can result in new benign behaviors being misclassified as anomalies. To address this, periodic retraining with recent data is essential to update the models. Strategies from recent works~\cite{lu2018learning, barbero2022transcending,jordaney2017transcend} provide effective approaches for mitigating concept drift.

% \PP{State Explosion in Massive Networks} Scaling FL to larger enterprise networks introduces potential state explosion issues, primarily due to the increasing complexity in managing and integrating updates from a growing number of clients. As more clients participate, each contributing their local model updates, the volume of data to be processed and aggregated can increase significantly. This escalation can strain communication channels, leading to higher bandwidth requirements and increased latency. Furthermore, the aggregation process itself becomes more computationally demanding as the number of updates grows. \Sys addresses these challenges by utilizing an ensemble learning approach and categorizing system activities, which simplifies the aggregation by processing more uniform data segments. Moreover, our system uses models with small network overhead to prevent bandwidth challenges. To further enhance efficiency, additional techniques such as model compression~\cite{choudhary2020comprehensive}, selective update aggregation~\cite{ye2020federated} and the implementation of more robust communication protocols~\cite{laclau2020robust} can significantly improve handling large volumes of updates, thus preventing state explosion and maintaining system performance in large-scale federated learning environments.

\PP{Unseen Tokens in Semantic Encoder} \Sys relies on \wordvec models to encode semantic attributes, but \wordvec only generates embeddings for tokens it has previously encountered, which can degrade the quality of feature vectors for new nodes with unseen tokens. To construct node representations, we combine semantic attributes with neighboring nodes' system calls, but for nodes with unseen tokens, the representation is predominantly based on system calls, as seen in systems like \threatrace~\cite{wang2022threatrace}. To address this limitation, retraining the \wordvec model more frequently or adopting subword-level embedding models like fastText~\cite{joulin2016bag}, which generate embeddings from subword units, can improve coverage. Tokenization methods such as Byte-Pair Encoding~\cite{araabi2022effective} further enhance new token representation by breaking unknown words into smaller subword components.

\PP{Scalability Bottlenecks}
As \Sys scales to large enterprise networks, two key bottlenecks emerge: (i) the utility server may face throughput limits due to processing encrypted tokens from all clients, and (ii) aggregating frequent model updates from many clients risks state explosion, increasing bandwidth and computational costs. \Sys mitigates these via lightweight models, ensemble learning over categorized system activities, and submodel aggregation. To further scale, we plan to explore hierarchical federation~\cite{zhong2022flee}, model compression~\cite{choudhary2020comprehensive}, selective update aggregation~\cite{ye2020federated}, and robust communication protocols~\cite{laclau2020robust}.


% \wajih{add citations for different techniques (SMC, HE, etc.) below}

%\PP{Retraining Frequency} \wajih{Discuss here how often we need to retrain models on client machines. You can say that it depends on enterprise settings, in our experiments we found that XXX times per day gave us good results.}

%\wajih{Investigation using \Sys. We need to add one paragraph saying something about how to do an investigation using \Sys after detection. It does not have to be detailed. We just need to show that we thought about this problem. At the end of the paragraph say that we leave this for future work.}

%\wajih{Talk about why we did not consider other privacy-preserving techniques beyond the federation, such as secure multi-party computation or homomorphic encryption.}