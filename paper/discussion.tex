\section{Discussion \& Limitations}
\label{sec:discussion}

%\wajih{Use macros for common words in this whole section.}

%\wajih{Be consistent with the terminology that you used in the abstract/intro.}

%\wajih{Move adversarial attacks in a separate section.}

\input{adversarial.tex}

\subsection{Alert Investigation} In systems like \Sys, validating the veracity of alerts is crucial for ensuring system reliability and preventing alert fatigue~\cite{nodoze2019}, traditionally involving security analysts manually reviewing each alert based on activities within local provenance graphs. This manual process, while thorough, is time-consuming and prone to errors, posing challenges in scalability and privacy. To enhance privacy and maintain efficiency in alert verification, implementing privacy-preserving techniques such as Secure Multi-party Computation (SMC)~\cite{goldreich1998secure}, Homomorphic Encryption (HE)~\cite{yi2014homomorphic}, and Zero-Knowledge Proofs (ZKP)~\cite{fiege1987zero} is vital. SMC allows multiple stakeholders to collaboratively validate alerts by jointly computing functions over their inputs while keeping those inputs private. HE enables the central server to analyze encrypted data, ensuring data confidentiality, and ZKP offers a way for one party to prove the validity of an alert to another without revealing any other information. Leveraging these technologies allows \Sys to privately and securely validate alerts, enhancing the system's trustworthiness and optimizing operational workflow. We identify privacy-preserving alert verification as a promising research direction. We leave it to future work to develop methods for privately sharing alert data with a central server, enabling security analysts to perform more in-depth attack analysis.


\subsection{Concept Drift} This is a problem where the data distribution of the underlying system evolves over time. For instance, with the emergence of new system activities, the patterns learned by \Sys during training might not remain valid. This drift could lead to misclassifications, as new benign behaviors might be mistakenly identified as anomalies. One mitigation strategy for this involves periodic retraining with more recent data to update the models. Techniques mentioned in recent works~\cite{lu2018learning, barbero2022transcending,jordaney2017transcend} can be leveraged to deal with the problem of concept drift.

\subsection{Explainability} The use of deep learning models in \pids makes them black-box systems, making it difficult to explain the inner decision-making process of these systems. Similar to existing \pids~\cite{flash2024,cheng2023kairos,yangprographer}, \Sys also suffers from this interpretability problem. This issue slows the adoption of these \pids compared to rule-based systems. Existing techniques~\cite{antwarg2021explaining,brown2018recurrent,ardito2021revisiting,hwang2021sfd} for model explainability focus on metrics such as feature importance. However, modern \pids use complex feature engineering techniques. For example, \flash uses a \wordvec model for feature generation from textual attributes in audit logs. These features are then used in a \gnn model for anomaly detection. The use of this multi-model approach renders existing explainable AI techniques impractical for these \pids. We identify explainable \pids as an important area for future research. The recent advancements in Large Language Models (LLMs)~\cite{chang2024survey} from the domain of Natural Language Processing can be utilized to solve this challenge. Future work can focus on using the reasoning power of LLMs to develop techniques for explaining \pids outputs.

% \wajih{add citations for different techniques (SMC, HE, etc.) below}

%\PP{Retraining Frequency} \wajih{Discuss here how often we need to retrain models on client machines. You can say that it depends on enterprise settings, in our experiments we found that XXX times per day gave us good results.}

%\wajih{Investigation using \Sys. We need to add one paragraph saying something about how to do an investigation using \Sys after detection. It does not have to be detailed. We just need to show that we thought about this problem. At the end of the paragraph say that we leave this for future work.}

%\wajih{Talk about why we did not consider other privacy-preserving techniques beyond the federation, such as secure multi-party computation or homomorphic encryption.}