\section{Discussion \& Limitations}
\label{sec:discussion}

%\wajih{Use macros for common words in this whole section.}

%\wajih{Be consistent with the terminology that you used in the abstract/intro.}

%\wajih{Move adversarial attacks in a separate section.}

%\input{adversarial.tex}

\PP{Alert Investigation} In systems like \Sys, validating the veracity of alerts is crucial for ensuring system reliability and preventing alert fatigue~\cite{nodoze2019}, traditionally involving security analysts manually reviewing each alert based on activities within local provenance graphs. This manual process, while thorough, is time-consuming and prone to errors, posing challenges in scalability and privacy. To enhance privacy and maintain efficiency in alert verification, implementing privacy-preserving techniques such as Secure Multi-party Computation (SMC)~\cite{goldreich1998secure}, Homomorphic Encryption (HE)~\cite{yi2014homomorphic}, and Zero-Knowledge Proofs (ZKP)~\cite{fiege1987zero} is vital. SMC allows multiple stakeholders to collaboratively validate alerts by jointly computing functions over their inputs while keeping those inputs private. HE enables the central server to analyze encrypted data, ensuring data confidentiality, and ZKP offers a way for one party to prove the validity of an alert to another without revealing any other information. Leveraging these technologies allows \Sys to privately and securely validate alerts, enhancing the system's trustworthiness and optimizing operational workflow. We identify privacy-preserving alert verification as a promising research direction. We leave it to future work to develop methods for privately sharing alert data with a central server, enabling security analysts to perform more in-depth attack analysis.

\PP{Explainability} The use of deep learning models in \pids makes them black-box systems, making it difficult to explain the inner decision-making process of these systems. Similar to existing \pids~\cite{flash2024,cheng2023kairos,yangprographer}, \Sys also suffers from this interpretability problem. This issue slows the adoption of these \pids compared to rule-based systems. Existing techniques~\cite{antwarg2021explaining,brown2018recurrent,ardito2021revisiting,hwang2021sfd} for model explainability focus on metrics such as feature importance. However, modern \pids use complex feature engineering techniques. For example, \flash uses a \wordvec model for feature generation from textual attributes in audit logs. These features are then used in a \gnn model for anomaly detection. The use of this multi-model approach renders existing explainable AI techniques impractical for these \pids. We identify explainable \pids as an important area for future research. The recent advancements in Large Language Models (LLMs)~\cite{chang2024survey} from the domain of Natural Language Processing can be utilized to solve this challenge. Future work can focus on using the reasoning power of LLMs to develop techniques for explaining \pids outputs.

\PP{Log Retention} Effective log retention \cite{wilbert2012log} is critical for the performance and reliability of \pids. Advanced Persistent Threats (APTs) can span months; therefore, logs need to be stored for extended periods to allow for thorough attack investigations. Decentralized systems like \Sys and \disdet \cite{dong2023distdet} keep raw logs on client machines. However, client machines have limited storage, so they can only store logs for a limited period. The duration for storing these logs depends on the domain in which \Sys is deployed. Secure and tamper-resistant cloud storage solutions \cite{kumar2018secure} can be combined with \Sys to securely back up user logs. In the event of an attack investigation, the logs corresponding to the alert raised by \Sys can be fetched from storage. These logs can then be processed to remove sensitive attributes to preserve user privacy \cite{portillo2019towards}. These logs can then be used for attack investigation.

\PP{Concept Drift} This is a problem where the data distribution of the underlying system evolves over time. For instance, with the emergence of new system activities, the patterns learned by \Sys during training might not remain valid. This drift could lead to misclassifications, as new benign behaviors might be mistakenly identified as anomalies. One mitigation strategy for this involves periodic retraining with more recent data to update the models. Techniques mentioned in recent works~\cite{lu2018learning, barbero2022transcending,jordaney2017transcend} can be leveraged to deal with the problem of concept drift.

% \PP{State Explosion in Massive Networks} Scaling FL to larger enterprise networks introduces potential state explosion issues, primarily due to the increasing complexity in managing and integrating updates from a growing number of clients. As more clients participate, each contributing their local model updates, the volume of data to be processed and aggregated can increase significantly. This escalation can strain communication channels, leading to higher bandwidth requirements and increased latency. Furthermore, the aggregation process itself becomes more computationally demanding as the number of updates grows. \Sys addresses these challenges by utilizing an ensemble learning approach and categorizing system activities, which simplifies the aggregation by processing more uniform data segments. Moreover, our system uses models with small network overhead to prevent bandwidth challenges. To further enhance efficiency, additional techniques such as model compression~\cite{choudhary2020comprehensive}, selective update aggregation~\cite{ye2020federated} and the implementation of more robust communication protocols~\cite{laclau2020robust} can significantly improve handling large volumes of updates, thus preventing state explosion and maintaining system performance in large-scale federated learning environments.

\PP{Unseen Tokens in Semantic Encoder} In \Sys, we rely on \wordvec models to encode semantic attributes. Because \wordvec operates inductively, it only provides embeddings for tokens it has previously learned, which can diminish the quality of feature vectors for new nodes whose attributes contain unseen tokens. To represent each node, we construct a word sequence by combining its semantic attributes with the system calls observed in neighboring nodes. However, for new nodes with previously unseen attribute tokens, the sequence is largely limited to system callsâ€”similar to related systems such as \threatrace~\cite{wang2022threatrace}. To address this challenge, we can retrain the \wordvec model more frequently or adopt subword-level embedding models, such as fastText~\cite{joulin2016bag}, which split words into subword units to generate embeddings for previously unseen tokens. Additionally, tokenization methods like Byte-Pair Encoding~\cite{araabi2022effective} can further break down unknown words into smaller subword components, thereby improving new token coverage.

% \wajih{add citations for different techniques (SMC, HE, etc.) below}

%\PP{Retraining Frequency} \wajih{Discuss here how often we need to retrain models on client machines. You can say that it depends on enterprise settings, in our experiments we found that XXX times per day gave us good results.}

%\wajih{Investigation using \Sys. We need to add one paragraph saying something about how to do an investigation using \Sys after detection. It does not have to be detailed. We just need to show that we thought about this problem. At the end of the paragraph say that we leave this for future work.}

%\wajih{Talk about why we did not consider other privacy-preserving techniques beyond the federation, such as secure multi-party computation or homomorphic encryption.}