\section{Background \& Motivation}
\label{sec:motivation}
% Contemporary host intrusion detection systems, exemplified by \unicorn~\cite{han2020unicorn}, \streamspot~\cite{streamspot}, \threatrace~\cite{wang2022threatrace} and \prographer~\cite{yangprographer}, heavily rely on system audit log data to identify malicious entities within a system. Employing advanced deep learning techniques such as \gnn (\gnnshort), these systems strive to enhance the accuracy of threat detection. However, the efficacy of these techniques is contingent upon vast amounts of data to train the underlying models, often reaching terabytes in size. Acquiring such extensive training data from a single user machine is impractical.

% Our investigation, involving the simulation of normal user workloads on test machines, reveals that the audit logs generated from these activities are relatively small in volume. Consequently, they prove insufficient for adequately training these large-scale machine learning models. To address this limitation, it becomes imperative to aggregate data from a diverse array of machines to a centralized storage system for comprehensive model training.

% Nevertheless, the consolidation of audit logs from various sources poses a significant challenge due to the inherent risk of privacy leakage. These logs contain vital information about the diverse activities carried out by different users, encompassing details about utilized applications, browsing history, and sensitive data like email content, phone numbers, as well as financial and medical information. These privacy concerns are underscored in a report by Datadog~\cite{datadog}, a prominent provider of system monitoring services. Consequently, utilizing existing systems for detecting system threats introduces a potential compromise of user privacy.

% Moreover, the centralized aggregation of all data elevates the risk of data leakage and compromises the efficiency of these systems in terms of both memory utilization and runtime efficiency. As a result, there is a pressing need for innovative solutions that balance the imperative of robust threat detection with the paramount importance of safeguarding user privacy and system efficiency.

% Federated learning (FL) is an establish technique for privacy preserving machine learning. In federated learning the individual client data does not leave the system. Instead each client machine trains a local machine learning model on its local data and then these clients sends the trained model to a central server where the federated averaging is utilized to combine the information from these models to get a unified global model. However our experimentation with existing systems reveal that applying federated learning to them yields poor results because these systems are not designed to work in this fashion.

In this section, we discuss existing host intrusion detection systems and highlight their design shortcomings, particularly in terms of preserving the privacy of user logs. Our system, \Sys, is developed as a node-level intrusion detection system. Consequently, we focus on comparing it with existing systems that share similar detection granularity, ensuring a fair assessment. Flash~\cite{flash2024}, a node-level anomaly detection system, employs \gnn to learn normal system behavior from provenance graphs. It utilizes an advanced featurization approach, leveraging a temporal ordering-aware word2vec model to encapsulate both structural and semantic attributes in audit logs. Additionally, Flash speeds up inference through an \gnnshort embedding store. In contrast, \threatrace~\cite{wang2022threatrace}, another node-level detection system, also relies on a \gnn for anomaly detection. However, it differs from Flash in its scalability limitations and use of simplistic features, hindering its ability to fully exploit the information in provenance graphs. \shadewatcher, an edge-level detection system, draws inspiration from recommendation systems. It models potential interactions within provenance graphs to identify anomalous ones. Lastly, Kairos~\cite{cheng2023kairos} is an anomaly-based detector that segments logs into time window queues and employs temporal graph neural networks for anomaly detection.