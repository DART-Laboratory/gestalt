
\section{Threat Model \& Assumptions}

Our threat model assumes that the central server operates with integrity, conducting the federated averaging process without malicious objectives. However, we recognize the risk that the central server could compromise the privacy of client logs if raw \logs is transmitted to it~\cite{man2021intelligent,li2023efficient}. We also consider the possibility of a curious central server attempting membership inference attacks by utilizing the model weights.

\PP{Realism of Dual-Server Architecture.} Following precedent in cryptographic and federated learning systems~\cite{roy2020crypte,wu2022federated,zhao2024superfl}, we assume the presence of a non-colluding, trusted utility server. This assumption is not only standard but also practically feasible. The utility server processes only encrypted tokens and performs no learning or aggregation itself, making its trust requirement minimal. It can be securely deployed within a Trusted Execution Environment (TEE)~\cite{mckeen2016intel}, monitored by a trusted third-party mediator~\cite{alwen2009collusion}, or hosted as a secure cloud compute instance~\cite{cloudinstance} directly managed by the organization. In this architecture, the central server is responsible for aggregating and coordinating tasks, while the utility server remains under the organization's control. This separation allows the utility server to be operated by trusted internal IT teams, specialized third-party security firms, or a dedicated cloud provider, all of whom prioritize data privacy and encryption. Non-collusion could also be ensured through strict legal agreements~\cite{roy2020crypte}.

\PP{Client-Side Threat Considerations.} For individual clients, we expect that attackers could disguise their harmful activities within benign data, making it difficult to distinguish between legitimate and harmful actions. Our model also considers the threat posed by zero-day vulnerabilities. Despite these challenges, we assume that the activities of attackers will be detectable in the system's records (\logs).

\PP{Data Provenance \& Log Integrity.} In line with prior studies on data provenance~\cite{streamspot,provdetector2020,wang2022threatrace,shadewatcher,yangprographer,han2020unicorn,jia2023magic,flash2024,cheng2023kairos,sigl,inam2023sok}, our approach relies on the provenance collection system's ability to accurately record all system activities and changes. Additionally, we ensure the integrity of audit logs is maintained through the use of established tamper-resistant storage solutions, such as those described by Paccagnella et al.~\cite{paccagnella2020custos} and the Hardlog system~\cite{hardlog}. Similar to other PIDS works, we assume the absence of any attack activities during the training phase.

% We consider the potential of a curious central server attempting membership inference attacks by utilizing the model weights. The central server could theoretically perform this by generating diverse node input features through various combinations of graph structures and node attributes, and then observing the model's output. However, the search space for such an operation is large, necessitating substantial resources. Moreover, the central server's lack of access to the semantic encoder model for feature encoding significantly impedes the feasibility of this attack. Nevertheless, our system remains susceptible to model poisoning attacks perpetrated by malicious clients.

%\wajih{In the threat model, I would like to know about how you deal with membership inference, poisoning, gradient attacks or not deal with. In general, it should specify the limitations of privacy of our privacy-preserving techniques. Also, specifying what specific information (host interactions, process names, etc.) the attacker can learn from gradients. More specific you are the better it is. I have added some papers in the related that will help you think about privacy more in FL settings.}

% \wajih{Reading Nature's paper they have the following limitations:
% "However, FedPerGNN has the following limitations. First,
% FedPerGNN relies on the assumption that third-party server is
% trusted and does not collude with the recommendation server,
% which is somewhat strong. Second, FedPerGNN may be brittle to
% attackers with a large number of malicious clients. Thus, in our
% future work, we will study how to defend against intended attacks
% from malicious clients and platforms. Furthermore, we plan to
% explore the effective and secure deployment of FedPerGNN in
% real-world personalization systems to serve their users under
% privacy preservation."}

% \wajih{Are some of the above limitations applicable to use? If yes, add them to the threat model.}