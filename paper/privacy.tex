\section{Privacy Preservation Analysis}
\label{sec:privacy}

\wajih{Please check existing papers to see if we can add formalism to this subsection. This concern has been raised by several reviewers that our privacy analysis is not robust.}

In this section, we analyze the preservation of user privacy within \Sys, which is structured around three primary components: the central server, the utility server, and clients. The risk to \Sys's privacy arises from the possibility of inference attacks using model weights at the central server and \wordvec tokens at the utility server. These attacks aim to extract information about the training data from model updates. We will discuss the scope and limitations of these attacks on \Sys below:


\PP{Component Roles} The central server's role involves the application of federated averaging to the \gnnshort models received from clients. The utility server performs contextual aggregation of semantic attribute vectors derived from clients' \(\wordvec\) models.  The mathematical representation for averaging vectors of a token \(k\) across \(N\) clients is given by: \( \bar{v}_k = \frac{1}{N} \sum_{i=1}^{N} v_{k,i} \) where \(\bar{v}_k\) is the averaged vector for token \(k\), and \(v_{k,i}\) is the vector representation of token \(k\) from the \(i\)-th client model. Clients are tasked with training the \wordvec and \gnnshort models on provenance graphs, these graphs are constructed from their local system audit logs.

\PP{Privacy Risk Analysis} Within \Sys, potential privacy compromises arise if either the central or utility server can infer specific details about individual clients' logs, such as the applications in use or particular attributes like filenames and IP addresses. Despite the central server's inability to access raw client data directly, it receives model updates from clients, thereby introducing a vulnerability to model inference attacks through analysis of these updates. Consider an attacker's objective to ascertain whether a system entity \(x\) with attributes \(y\) was utilized in training a client model \(m\). This necessitates the generation of multiple candidate node features for \(x\), taking into account various graph structures and interactions with other entities while considering diverse attributes. The search space for this task, \(S\), is extensive, spanning all conceivable processes, files, and network IPs.

Assuming the server generates multiple candidate structures, it then requires access to the specific client's \(\wordvec\) model to generate feature vectors for these structures -- a step prevented by the model's unavailability and inherent algorithmic randomness, rendering each training iteration of the \(\wordvec\) model distinct: \( F(x) = \wordvec(s_x) \) where \(F(x)\) is the feature vector of structure \(x\) and \(s_x\) is the candidate sequence.

Consequently, the dual-server architecture and semantic featurization significantly limits the central server's capacity for inference attacks. The utility server's function of contextually aggregating semantic attribute vectors introduces another potential privacy concern if the server could deduce the entities these vectors represent. This risk is mitigated by the secure encryption of tokens using keys generated by the central server, which the utility server cannot access, ensuring privacy protection.

Furthermore, a malicious client attempting to utilize the global aggregate to infer the applications used across the organization faces similar constraints. Such an attack is limited by the client's lack of access to the semantic attribute vectors widespread across the organization, significantly narrowing the attack's feasibility. Therefore, the architecture of \Sys robustly defends against model inference attacks, affirming the system's capacity to preserve privacy. This resilience is predicated on the non-collusion assumption between the central and utility servers -- a standard premise upheld by related works~\cite{roy2020crypte,wu2022federated}, ensuring the system's high degree of privacy preservation.