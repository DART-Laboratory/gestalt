\section{Privacy Preservation Analysis}
\label{sec:privacy}

%\wajih{Please check existing papers to see if we can add formalism to this subsection. This concern has been raised by several reviewers that our privacy analysis is not robust.}

%\wajih{ There was a comment/review about membership inference for unseen words. Is that addressed below?} Yes

\wajih{We need to make our privacy analysis more formal. Look into  a privacy game where the adversary attempts to distinguish between two datasets. }

\wajih{The private FL papers have a lot theorems, we just need to tailor them for our.}

\wajih{Also we need a theorem for your Privacy Against Model Update Inference. There are two parts here. Define Theorem and then provide proof for that theorem.}

\wajih{}

In this section, we analyze the preservation of user privacy within \Sys, which is structured around three primary components: the central server, the utility server, and clients. The risk to \Sys's privacy arises from the possibility of inference attacks using model weights at the central server and \wordvec tokens at the utility server. These attacks aim to infer whether some system entity or attributes were used in the training data or not. We will discuss the scope and limitations of these attacks on \Sys below:

\PP{Component Roles} The central server's role involves the application of federated averaging to the \gnnshort models received from clients. The utility server performs contextual aggregation of semantic attribute vectors derived from clients' \(\wordvec\) models.  The mathematical representation for averaging vectors of a token \(k\) across \(N\) clients is given by: \( \bar{v}_k = \frac{1}{N} \sum_{i=1}^{N} v_{k,i} \) where \(\bar{v}_k\) is the averaged vector for token \(k\), and \(v_{k,i}\) is the vector representation of token \(k\) from the \(i\)-th client model. Clients are tasked with training the \wordvec and \gnnshort models on provenance graphs, these graphs are constructed from their local system audit logs.

\PP{Privacy Risk Analysis} Within \Sys, potential privacy compromises arise if either the central or utility server can infer specific details about individual clients' logs, such as the applications in use or particular attributes like filenames and IP addresses. Despite the central server's inability to access raw client data directly, it receives model updates from clients, thereby introducing a vulnerability to model inference attacks through analysis of these updates.

Consider an attacker's objective to ascertain whether a system entity \(x\) with attributes \(y\) was utilized in training a client model \(m\). This necessitates the generation of multiple candidate node features for \(x\), taking into account various graph structures and interactions with other entities while considering diverse attributes. The search space for this task, \(S\), is extensive, spanning all conceivable processes, files, and network IPs.

Assuming the server generates multiple candidate structures, it then requires access to the specific client's \(\texttt{\wordvec}\) model to generate feature vectors for these structures---a step prevented by the model's unavailability and inherent algorithmic randomness, rendering each training iteration of the \(\texttt{\wordvec}\) model distinct:
\( F(x) = \texttt{\wordvec}(s_x) \)
where \(F(x)\) is the feature vector of structure \(x\) and \(s_x\) is the candidate sequence.

Formally, the system \Sys is designed to ensure that the probability that an adversary can distinguish between two arbitrary system log datasets based on the observed updates is negligible:
\begin{align*}
\text{Attack}(D_1, D_2) &= \left| \Pr[\mathcal{A}(\text{Enc}(D_1)) = 1] \right. \nonumber \\
&\quad - \left. \Pr[\mathcal{A}(\text{Enc}(D_2)) = 1] \right| \\
&\leq \epsilon \nonumber
\end{align*}
where \(\epsilon\) is a negligible value, \(\text{Enc}(D)\) denotes the encoding of the dataset into model updates, and \(\mathcal{A}\) represents the adversary.

To further quantify the security of \Sys in the context of semantic embeddings at the utility server, consider the scenario where an attacker has access to the \wordvec embeddings but not the original attributes used for generating them. Suppose the attacker attempts to reverse engineer the embedding vectors to recover the original system log data. The complexity, randomness and high dimensionality of the embedding space, combined with the non-linear transformations typically applied during \wordvec embedding process, ensure that the probability of successfully identifying the original tokens from the embeddings is negligibly small:
\[
\Pr[\text{Rev}(\mathcal{E}, e) = t] \leq \frac{1}{|T|}
\]
where \(\text{Rev}\) denotes the hypothetical reverse mapping function from embeddings to tokens, \(\mathcal{E}\) represents the embedding process, \(e\) is the observed embedding, \(t\) is the original token, and \(|T|\) is the cardinality of the token set. This probability indicates that correctly guessing the original token from its embedding is as likely as randomly selecting one token out of the entire set of possible tokens, which is practically infeasible given a sufficiently large and diverse token set.

Consequently, the dual-server architecture and semantic featurization significantly limit the central server's capacity for inference attacks. The utility server's function of contextually aggregating semantic attribute vectors introduces another potential privacy concern if the server could deduce the entities these vectors represent. This risk is mitigated by the secure encryption of tokens using keys generated by the central server, which the utility server cannot access, ensuring privacy protection.

Furthermore, a malicious client attempting to utilize the global aggregate to infer the applications used across the organization faces similar constraints. Such an attack is limited by the client's lack of access to the semantic attribute vectors widespread across the organization, significantly narrowing the attack's feasibility.

Therefore, the architecture of \Sys robustly defends against model inference attacks, affirming the system's capacity to preserve privacy. This resilience is predicated on the non-collusion assumption between the central and utility serversâ€”a standard premise upheld by related works~\cite{roy2020crypte,wu2022federated}, ensuring the system's high degree of privacy preservation.
