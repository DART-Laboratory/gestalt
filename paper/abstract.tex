\begin{abstract}

    Enterprises increasingly rely on Intrusion Detection Systems (\ids) to guard against malicious threats, utilizing \logs for detecting such activities. However, the common practice of centrally managing these logs, which include sensitive data such as IP addresses and file activities, raises privacy concerns, particularly when Managed Security Service Providers (MSSPs) are involved. These third parties, which offer intrusion detection services, may inadvertently breach user privacy when analyzing these sensitive logs on central servers located in the cloud.
    
    In this paper, we propose \Sys that leverages a novel adaptation of Federated Learning (FL) and graph representation learning to enable local model training on \logs at client machines without sending raw logs to a central server, thus promoting decentralization and privacy in \ids. FL presents challenges in \ids due to varying data distribution and heterogeneity among clients, which impacts the generalization of the global model. To mitigate this, we introduce a novel ensemble learning approach and a process entity categorization scheme, where each submodel specializes in distinct system activity patterns across clients, preventing conflation during model aggregation.  Semantically rich feature vectors are crucial for high detection accuracy; however, semantic encoders, such as \wordvec complicate private aggregation on a central server in the FL process. To resolve this, we developed a \wordvec harmonization framework within a multi-server architecture that securely aggregates semantic attributes. One server generates encryption keys for client-level log attributes, while another performs computations on encrypted data without revealing sensitive tokens. Extensive evaluations on DARPA E3, E5, and OpTC datasets show that our system achieves state-of-the-art detection accuracy while being highly scalable and privacy-preserving.
\end{abstract}

% Data provenance transforms \logs logs into detailed provenance graphs, offering a better understanding of host activities. When combined with Graph Neural Networks (GNNs) and FL, it becomes a powerful technique for differentiating benign from malicious behaviors.

% We have designed a multi-server architecture and a robust encryption scheme to preserve the privacy of important user log attributes. To address the challenges of non-IID data distributions, heterogeneous, and imbalanced clients, we implement a sophisticated GNN learning framework personalized at the system entity level. We also present a detailed analysis of our system's resilience against adversarial attacks. Extensive evaluation of our system on real-world datasets from DARPA demonstrates that it achieves state-of-the-art detection performance while being highly scalable and privacy-preserving.