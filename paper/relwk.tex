\section{Related work}
\label{s:relwk}

%\wajih{ Make sure to cite this paper: https://www.usenix.org/system/files/sec23winter-prepub-490-jia.pdf}


\PP{Machine Learning based PIDS} Many existing systems leverage machine learning techniques for threat detection. ProvDetector~\cite{provdetector2020} utilizes the Doc2Vec~\cite{le2014distributed} model to encode attack paths in provenance graphs into embeddings for outlier detection. Attack2Vec~\cite{shen2019attack2vec} employs a temporally aware word-to-embedding encoding scheme to identify attack entities. In the domain of network anomaly detection, DeepAid~\cite{deepaid} utilizes deep neural networks to differentiate anomalous traffic. ProGrapher~\cite{yangprographer} generates provenance graph embeddings for anomalous graph identification by integrating Graph2Vec~\cite{narayanan2017graph2vec} and TextRCNN~\cite{lai2015recurrent} models. StreamSpot~\cite{streamspot}, another graph-level detector, constructs benign models using various graph features and detects anomalies through clustering algorithms. Furthermore, \unicorn~\cite{han2020unicorn} employs graph kernels for graph-level threat detection. Other systems~\cite{aljawarneh2018anomaly, maseer2021benchmarking, gyanchandani2012taxonomy,atlas} also utilize diverse embedding generation techniques. Additionally, studies such as \cite{zolkipli2011approach, chakkaravarthy2019survey, isohara2011kernel} focus on malware detection. Techniques like DeepLog~\cite{deeplog2017} directly process logs using recurrent neural networks. SIGL~\cite{sigl} specifically targets the detection of malicious software installations, while Euler~\cite{king2022euler} employs both GNN and RNN models to detect lateral movements. MAGIC~\cite{jia2023magic} uses masked graph representation learning for detecting system threats. In comparison to all these IDSes, \Sys is the first to utilize the principles of federated learning and address the associated challenges to achieve privacy-preserving and scalable threat detection.

\disdet~\cite{dong2023distdet} detects APTs using Hierarchical System Event Trees (HST) in a decentralized manner. \disdet reduces network costs by summarizing system events in the form of HST but compromises privacy because HSTs must be sent to the server in plain text. Additionally, \disdet identifies anomalies as events simply missing from the benign HST, a method prone to false alarms in dynamically changing system environments. As more new benign processes are added to the system, they will not be present in existing HSTs and would be mistakenly raised as alarms.

\PP{Rules-based IDS} Another category of PIDS focuses on using predefined rules to detect malicious activities, with examples like Holmes~\cite{holmes2019}, Rapsheet~\cite{rapsheet2020}, and Poirot~\cite{poirot2019}. These systems leverage insights from APTs to build their rule bases and generate fewer false positives compared to machine learning-based PIDS. However, their limitations include the inability to detect threats with novel attack signatures and the need for skilled security professionals to develop rule sets.

\PP{Federating Learning in Threat Detection} Few IDS employ federated learning, with most research centered on Network Intrusion Detection. Examples include \cite{man2021intelligent}, proposing FL for IoT threat detection, and \cite{friha20232df}, which introduces a differentially private system for industrial IoT. \cite{li2023efficient} presents an efficient network intrusion detection framework, while \cite{guo2023new} addresses non-IID data issues in FL for intrusion detection. \Sys advances this area by being the first system to integrate FL with graph-based learning techniques for host-based threat detection using a categorized \gnnshort learning framework and secure semantic vector harmonization, enhancing accuracy and privacy in enterprise environments.

\PP{Privacy-Enhancing Cryptographic Techniques} Multi-Party Computation (MPC)~\cite{cramer2015secure} and Fully Homomorphic Encryption (FHE)  \cite{armknecht2015guide} are two techniques for enhancing privacy in cryptographic systems. MPC enables a group of parties to compute a function over their inputs while keeping those inputs private, and FHE allows computations to be performed on encrypted data. However, these techniques can introduce additional system complexity and scalability issues~\cite{du2001secure, gentry2009fully, asharov2013more}, particularly when dealing with extremely large datasets~\cite{menezes2018handbook}. Host intrusion detection systems rely on system logs that can easily reach terabytes in size, making the computational overhead of these techniques prohibitively expensive. Consequently, applying MPC or FHE directly to these massive logs would be impractical and of little utility for real-time threat detection. In contrast, \Sys uses a scalable encryption technique in combination with FL to provide scalability and privacy preservation. We provide a privacy guarantee of our technique in section~\ref{sec:privacy}.

\PP{Privacy-preserving FL} PrivateFL~\cite{yang2023privatefl} tackles the heterogeneity caused by differential privacy (DP) in FL systems through personalized data transformations to protect model updates from inference attacks. Similarly, \cite{annamalai2023fp} applies FL and DP to detect browser fingerprinting, and \cite{dasu2022prov} introduces secure federated averaging using homomorphic encryption. Poseidon~\cite{sav2020poseidon} utilizes multiparty cryptography for privacy-preserving neural network training, while Ppefl~\cite{wang2023ppefl} adopts local DP for FL, addressing privacy and model performance issues. Unlike these methods, \Sys introduces a privacy-preserving multi-model server architecture that avoids DP-induced noise, ensuring robust performance while resisting inference attacks.
 
% \wajih{papers to cite:}
% https://www.usenix.org/system/files/usenixsecurity23-yang-yuchen.pdf


% https://www.ndss-symposium.org/ndss-paper/fp-fed-privacy-preserving-federated-detection-of-browser-fingerprinting/

% https://dl.acm.org/doi/10.1145/3560830.3563729

% https://www.ndss-symposium.org/ndss-paper/poseidon-privacy-preserving-federated-neural-network-learning/

% https://ieeexplore.ieee.org/document/10091486


% https://arxiv.org/abs/2310.20552

% https://dl.acm.org/doi/10.1145/3624017


% \wajih{You need to go through these papers, especially their threat model and evaluation section. Tell me what metrics are they using to prove that their FL is privacy-preserving. And you need to tell me why we can or cannot apply to our system.}
