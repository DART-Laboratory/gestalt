\section{Related work}
\label{s:relwk}

%\wajih{ Make sure to cite this paper: https://www.usenix.org/system/files/sec23winter-prepub-490-jia.pdf}


\PP{Machine Learning based PIDS} Many existing systems leverage machine learning techniques for threat detection. ProvDetector~\cite{provdetector2020} utilizes the Doc2Vec~\cite{le2014distributed} model to encode attack paths in provenance graphs into embeddings for outlier detection. Attack2Vec~\cite{shen2019attack2vec} employs a temporally aware word-to-embedding encoding scheme to identify attack entities. In the domain of network anomaly detection, DeepAid~\cite{deepaid} utilizes deep neural networks to differentiate anomalous traffic. \disdet~\cite{dong2023distdet}, a host intrusion detection system, detects advanced persistent threats (APTs) using hierarchical system event trees. ProGrapher~\cite{yangprographer} generates provenance graph embeddings for anomalous graph identification by integrating Graph2Vec~\cite{narayanan2017graph2vec} and TextRCNN~\cite{lai2015recurrent} models. StreamSpot~\cite{streamspot}, another graph-level detector, constructs benign models using various graph features and detects anomalies through clustering algorithms. Furthermore, \unicorn~\cite{han2020unicorn} employs graph kernels for graph-level threat detection. Other systems~\cite{aljawarneh2018anomaly, maseer2021benchmarking, gyanchandani2012taxonomy,atlas} also utilize diverse embedding generation techniques. Additionally, studies such as \cite{zolkipli2011approach, chakkaravarthy2019survey, isohara2011kernel} focus on malware detection. Techniques like DeepLog~\cite{deeplog2017} directly process logs using recurrent neural networks. SIGL~\cite{sigl} specifically targets the detection of malicious software installations, while Euler~\cite{king2022euler} employs both GNN and RNN models to detect lateral movements. MAGIC~\cite{jia2023magic} uses masked graph representation learning for detecting system threats. In comparison to all these IDSes, \Sys is the first to utilize the principles of federated learning and address the associated challenges to achieve privacy-preserving and scalable threat detection.

\PP{Decentralized PIDS}
\Fix{Note that \disdet reduces network costs by summarizing system events in hierarchical tree data structures but compromises privacy because HSTs must be sent to the server in plain text. Additionally, \disdet identifies anomalies as events simply missing from the benign HST, a method prone to false alarms in dynamically changing system environments.}

Although decentralized IDS like DistDet attempt to address privacy issues by using a Hierarchical System Event Tree (HST) for event storage, they still transmit these HSTs in plaintext, compromising user log privacy.


\PP{Rules-based IDS} Another category of PIDS concentrates on utilizing predefined rules to detect malicious entities. Key examples include Holmes~\cite{holmes2019}, Rapsheet~\cite{rapsheet2020}, and Poirot~\cite{poirot2019}. These approaches leverage insights from APTs to formulate their rule bases. In comparison to PIDS systems based on machine learning, rule-based PIDSes tend to generate fewer false positives. Nevertheless, a significant limitation of these systems is their inability to identify threats featuring novel attack signatures. Additionally, they often necessitate the expertise of skilled security professionals for the development of their rule sets.

\PP{Federating Learning in Threat Detection}
Currently, there are few PIDS that utilize the principles of federated learning. The majority of research focuses on Network Intrusion Detection. \cite{man2021intelligent} proposes a technique for threat detection in IoT devices using FL, while \cite{friha20232df} introduces a differentially private detection system tailored for industrial IoT environments. Additionally, \cite{li2023efficient} presents an efficient network intrusion detection system. Furthermore, \cite{guo2023new} discusses the impact of non-IID data on FL for intrusion detection, proposing methods to mitigate this issue.  \Sys addresses these challenges through the use of categorized \gnnshort learning framework and secure semantic vector harmonization. Lastly, \cite{chaabene2023privacy} describes another FL-based system for IoT intrusion detection.

\PP{Privacy-preserving FL} PrivateFL~\cite{yang2023privatefl} addresses the challenge of heterogeneity introduced by differential privacy (DP) in FL systems. It introduces a personalized data transformation technique to apply DP to model updates in order to prevent inference attacks at the central server. Similarly, \cite{annamalai2023fp} utilizes FL and DP for the privacy-preserving detection of browser fingerprinting. \cite{dasu2022prov} introduces a secure federated averaging technique using homomorphic encryption. Poseidon~\cite{sav2020poseidon} presents a privacy-preserving neural network training scheme that employs multiparty cryptography to preserve the confidentiality of training data under a passive-adversary model. Finally, Ppefl~\cite{wang2023ppefl} proposes a privacy-preserving FL framework based on local DP, addressing the issues of high privacy budget and poor model performance in FL scenarios. In comparison to these approaches, \Sys introduces a robust multi-model server architecture that is privacy-preserving and is resistant to inference attacks without the use of DP. This prevents \Sys's performance from deteriorating by the noise introduced by DP while offering strong privacy guarantees.
 
% \wajih{papers to cite:}
% https://www.usenix.org/system/files/usenixsecurity23-yang-yuchen.pdf


% https://www.ndss-symposium.org/ndss-paper/fp-fed-privacy-preserving-federated-detection-of-browser-fingerprinting/

% https://dl.acm.org/doi/10.1145/3560830.3563729

% https://www.ndss-symposium.org/ndss-paper/poseidon-privacy-preserving-federated-neural-network-learning/

% https://ieeexplore.ieee.org/document/10091486


% https://arxiv.org/abs/2310.20552

% https://dl.acm.org/doi/10.1145/3624017


% \wajih{You need to go through these papers, especially their threat model and evaluation section. Tell me what metrics are they using to prove that their FL is privacy-preserving. And you need to tell me why we can or cannot apply to our system.}
