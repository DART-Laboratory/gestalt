\section{Related work}
\label{s:relwk}

% \wajih{Check NDSS 2025 and USENIX 2024 and IEEE S\&P 2024 to see if there is a paper that we have not cited in the related. If there is provenance related paper or IDS we need to cite it in the Related Work.}


% \wajih{Google scholar search FL+IDS and see if there are some new papers we can cite in the related work.}


%\wajih{ Make sure to cite this paper: https://www.usenix.org/system/files/sec23winter-prepub-490-jia.pdf}

\PP{ML-based IDS} ML techniques are widely used in threat detection. ProvDetector~\cite{provdetector2020} applies Doc2Vec~\cite{le2014distributed} to provenance graphs; Attack2Vec~\cite{shen2019attack2vec} uses temporally aware embeddings. DeepAid~\cite{deepaid} classifies anomalous traffic, ProGrapher~\cite{yangprographer} combines Graph2Vec~\cite{narayanan2017graph2vec} and TextRCNN~\cite{lai2015recurrent}, and StreamSpot~\cite{streamspot} clusters graph features. Other systems~\cite{aljawarneh2018anomaly, maseer2021benchmarking, gyanchandani2012taxonomy, atlas} explore varied embeddings; some focus on malware~\cite{zolkipli2011approach, chakkaravarthy2019survey, isohara2011kernel}. DeepLog~\cite{deeplog2017} uses RNNs on logs, SIGL~\cite{sigl} detects software installs, Euler~\cite{king2022euler} combines GNNs and RNNs, and MAGIC~\cite{jia2023magic} uses masked graph learning. \Sys is the first to combine federated learning with provenance-based IDS, addressing privacy, scalability, and heterogeneity.

DistDet~\cite{dong2023distdet} detects APTs using Hierarchical System Event Trees (HSTs) to summarize local system activity and reduce network overhead. However, this summarization comes at the cost of expressiveness and privacy. HSTs must be transmitted in plaintext to a central server, exposing sensitive execution traces without any formal privacy guarantees. More critically, HSTs encode flat, linear event sequences and lack the structural richness of provenance graphs, limiting their ability to model complex causal and multi-entity interactions. Anomalies are detected by identifying sequences absent from a reference benign HST, a simplistic approach that fails to generalize in dynamic environments and results in frequent false positives.


\PP{Rule-based \pids} Rule-based \pids rely on predefined rules for detecting malicious activities. Examples include Holmes~\cite{holmes2019}, Rapsheet~\cite{rapsheet2020}, Poirot~\cite{poirot2019}, and CAPTAIN~\cite{wang2024incorporating} which leverage insights from APTs to construct rule bases, achieving fewer false positives compared to ML-based systems. However, these systems face significant limitations: they cannot detect threats with novel attack signatures and require skilled security professionals to design and update the rule sets. Additionally, none of these systems ensure privacy preservation during their operation.

\PP{Federating Learning in Threat Detection} Few IDS employ federated learning, with most research centered on Network Intrusion Detection. Examples include \cite{man2021intelligent}, proposing FL for IoT threat detection, and \cite{friha20232df}, which introduces a differentially private system for industrial IoT. \cite{li2023efficient} presents an efficient network intrusion detection framework, while \cite{guo2023new} addresses non-IID data issues in FL for intrusion detection. \Sys advances this area by being the first system to integrate FL with graph-based learning techniques for host-based threat detection using a categorization based \gnnshort ensemble framework and secure \wordvec harmonization. XFedGraph-Hunter \cite{son2023xfedgraph} employs FL and \gnnshort for network intrusion detection, while FedHE-Graph~\cite{mansour2024fedhe} introduces an FL-based intrusion-detection mechanism in a single-server setting. Unlike \Sys, however, their approach lacks semantic harmonization which is essential for leveraging semantic feature vectors and achieving detection performance on par with centralized \pids.

\PP{Cryptographic Techniques} Cryptographic techniques, such as Multi-Party Computation (MPC)~\cite{cramer2015secure} and Fully Homomorphic Encryption (FHE)~\cite{armknecht2015guide}, offer strong privacy guarantees. MPC allows multiple parties to compute a function over their inputs while keeping those inputs private, and FHE enables computations on encrypted data. However, these methods face significant challenges, including increased system complexity and scalability issues~\cite{du2001secure, gentry2009fully, asharov2013more}, particularly with large datasets~\cite{menezes2018handbook}. For instance, host intrusion detection systems often process terabytes of logs, making the computational overhead of MPC or FHE impractical for real-time threat detection~\cite{loggc}. In contrast, \Sys combines a scalable encryption technique with federated learning to ensure both scalability and privacy preservation. Section~\ref{sec:privacy} provides a detailed analysis of the privacy guarantees of this approach.

\PP{Privacy-preserving FL} PrivateFL~\cite{yang2023privatefl} tackles the heterogeneity caused by differential privacy (DP) in FL systems through personalized data transformations to protect model updates from inference attacks. Similarly, \cite{annamalai2023fp} applies FL and DP to detect browser fingerprinting, and \cite{dasu2022prov} introduces secure federated averaging using homomorphic encryption. Poseidon~\cite{sav2020poseidon} utilizes multiparty cryptography for privacy-preserving neural network training, while PpeFL~\cite{wang2023ppefl} adopts local DP for FL, addressing privacy and model performance issues. Unlike these methods, \Sys introduces a privacy-preserving multi-model server architecture that avoids DP-induced noise, ensuring robust performance while resisting inference attacks. We provide experimental results on the issue of applying DP for the PIDS domain in Appendix~\ref{app:dp}.

% \wajih{papers to cite:}
% https://www.usenix.org/system/files/usenixsecurity23-yang-yuchen.pdf


% https://www.ndss-symposium.org/ndss-paper/fp-fed-privacy-preserving-federated-detection-of-browser-fingerprinting/

% https://dl.acm.org/doi/10.1145/3560830.3563729

% https://www.ndss-symposium.org/ndss-paper/poseidon-privacy-preserving-federated-neural-network-learning/

% https://ieeexplore.ieee.org/document/10091486


% https://arxiv.org/abs/2310.20552

% https://dl.acm.org/doi/10.1145/3624017


% \wajih{You need to go through these papers, especially their threat model and evaluation section. Tell me what metrics are they using to prove that their FL is privacy-preserving. And you need to tell me why we can or cannot apply to our system.}
