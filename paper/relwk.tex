\section{Related work}
\label{s:relwk}

\wajih{Check NDSS 2025 and USENIX 2024 and IEEE S\&P 2024 to see if there is a paper that we have not cited in the related. If there is provenance related paper or IDS we need to cite it in the Related Work.}


\wajih{Google scholar search FL+IDS and see if there are some new papers we can cite in the related work.}


%\wajih{ Make sure to cite this paper: https://www.usenix.org/system/files/sec23winter-prepub-490-jia.pdf}

\PP{ML-based IDS} Machine Learning (ML) techniques are widely employed for threat detection. ProvDetector~\cite{provdetector2020} encodes attack paths in provenance graphs into embeddings using Doc2Vec\cite{le2014distributed} for outlier detection. Attack2Vec~\cite{shen2019attack2vec} employs a temporally aware word-to-embedding encoding to identify attack entities. For network anomaly detection, DeepAid~\cite{deepaid} uses deep neural networks to classify anomalous traffic, while ProGrapher~\cite{yangprographer} combines Graph2Vec~\cite{narayanan2017graph2vec} and TextRCNN~\cite{lai2015recurrent} to generate embeddings for anomalous graph identification. StreamSpot~\cite{streamspot} employs clustering algorithms on graph features for anomaly detection, and \unicorn~\cite{han2020unicorn} utilizes graph kernels for graph-level threat detection. Other systems~\cite{aljawarneh2018anomaly, maseer2021benchmarking, gyanchandani2012taxonomy, atlas} leverage diverse embedding techniques, while studies, such as \cite{zolkipli2011approach, chakkaravarthy2019survey, isohara2011kernel} focus on malware detection. Specific techniques like DeepLog~\cite{deeplog2017} apply recurrent neural networks to log data, and SIGL~\cite{sigl} targets malicious software installations. Euler~\cite{king2022euler} integrates GNN and RNN models for lateral movement detection, while MAGIC~\cite{jia2023magic} employs masked graph representation learning for detecting system threats. Unlike these systems, \Sys is the first to utilize federated learning, addressing associated challenges to enable privacy-preserving and scalable threat detection. \disdet~\cite{dong2023distdet} detects APTs using Hierarchical System Event Trees (HST) in a decentralized manner. \disdet reduces network costs by summarizing system events in the form of HST but compromises privacy because HSTs must be sent to the server in plain text. Additionally, \disdet identifies anomalies as events simply missing from the benign HST, a method prone to high false alarms in dynamically changing system environments.


\PP{Rule-based \pids} Rule-based \pids rely on predefined rules for detecting malicious activities. Examples include Holmes~\cite{holmes2019}, Rapsheet~\cite{rapsheet2020}, Poirot~\cite{poirot2019}, and CAPTAIN~\cite{wang2024incorporating} which leverage insights from APTs to construct rule bases, achieving fewer false positives compared to ML-based systems. However, these systems face significant limitations: they cannot detect threats with novel attack signatures and require skilled security professionals to design and update the rule sets. Additionally, none of these systems ensure privacy preservation during their operation.

\PP{Federating Learning in Threat Detection} Few IDS employ federated learning, with most research centered on Network Intrusion Detection. Examples include \cite{man2021intelligent}, proposing FL for IoT threat detection, and \cite{friha20232df}, which introduces a differentially private system for industrial IoT. \cite{li2023efficient} presents an efficient network intrusion detection framework, while \cite{guo2023new} addresses non-IID data issues in FL for intrusion detection. \Sys advances this area by being the first system to integrate FL with graph-based learning techniques for host-based threat detection using a categorization based \gnnshort ensemble framework and secure \wordvec harmonization, enhancing accuracy and privacy in enterprise environments.

\PP{Cryptographic Techniques} Privacy-enhancing cryptographic techniques, such as Multi-Party Computation (MPC)~\cite{cramer2015secure} and Fully Homomorphic Encryption (FHE)~\cite{armknecht2015guide}, offer strong privacy guarantees. MPC allows multiple parties to compute a function over their inputs while keeping those inputs private, and FHE enables computations on encrypted data. However, these methods face significant challenges, including increased system complexity and scalability issues~\cite{du2001secure, gentry2009fully, asharov2013more}, particularly with large datasets~\cite{menezes2018handbook}. For instance, host intrusion detection systems often process terabytes of logs, making the computational overhead of MPC or FHE impractical for real-time threat detection~\cite{loggc}. In contrast, \Sys combines a scalable encryption technique with federated learning to ensure both scalability and privacy preservation. Section~\ref{sec:privacy} provides a detailed analysis of the privacy guarantees of this approach.

\PP{Privacy-preserving FL} PrivateFL~\cite{yang2023privatefl} tackles the heterogeneity caused by differential privacy (DP) in FL systems through personalized data transformations to protect model updates from inference attacks. Similarly, \cite{annamalai2023fp} applies FL and DP to detect browser fingerprinting, and \cite{dasu2022prov} introduces secure federated averaging using homomorphic encryption. Poseidon~\cite{sav2020poseidon} utilizes multiparty cryptography for privacy-preserving neural network training, while PpeFL~\cite{wang2023ppefl} adopts local DP for FL, addressing privacy and model performance issues. Unlike these methods, \Sys introduces a privacy-preserving multi-model server architecture that avoids DP-induced noise, ensuring robust performance while resisting inference attacks. We provide experimental results on the issue of applying DP for the PIDS domain in Appendix~\ref{app:dp}.

% \wajih{papers to cite:}
% https://www.usenix.org/system/files/usenixsecurity23-yang-yuchen.pdf


% https://www.ndss-symposium.org/ndss-paper/fp-fed-privacy-preserving-federated-detection-of-browser-fingerprinting/

% https://dl.acm.org/doi/10.1145/3560830.3563729

% https://www.ndss-symposium.org/ndss-paper/poseidon-privacy-preserving-federated-neural-network-learning/

% https://ieeexplore.ieee.org/document/10091486


% https://arxiv.org/abs/2310.20552

% https://dl.acm.org/doi/10.1145/3624017


% \wajih{You need to go through these papers, especially their threat model and evaluation section. Tell me what metrics are they using to prove that their FL is privacy-preserving. And you need to tell me why we can or cannot apply to our system.}
