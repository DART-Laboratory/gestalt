\section{Design}
\label{sec:methodology}
% \wajih{Do a GLOBAL SEARCH of the paper and replace federated graph learning with federated provenance graph learning and replace anomaly detection with GNN-based anomaly detection where ever appropriate}

% \wajih{Througout this section, replace verbose descriptions with concise references to these symbols/notations to streamline the text (e.g., use \( \psi(p) \) instead of "categorization map", \( \mathcal{P}_{\text{global}} \) instead of "the global set of unique process entities).
% }


\Sys comprises five key modules, starting with the \textit{Provenance Graph Constructor} module on each client machine, which transforms logs into a provenance graph. While our approach to constructing provenance graphs builds on established methods~\cite{inam2023sok,nodoze2019,mpi+ma,loggc,lpm2015,hossain2017sleuth}, detailed information is provided in Appendix~\ref{sub:provconstruct}. The \textit{Semantic Featurization \& Harmonization} module (Section~\ref{semanfeat}) trains word2vec models to encode semantic attributes and consolidates individual client models into a cohesive global model using a trusted utility server and encryption techniques. The \textit{Process Entity Categorization Module} (Section~\ref{sys:catg}) standardizes system entities across clients, ensuring uniformity in GNN model training. The \textit{Federated Provenance Graph Learning Module} (Section~\ref{sys:fpgl}) then trains GNN models on each client machine using harmonized semantic features, with the models aggregated on a central server through federated averaging. Finally, the \textit{Anomaly Detection Module} (Section~\ref{sys:anomaly_detection}) applies the unified global models for anomaly detection on each client machine. Figure~\ref{fig:arch} illustrates the comprehensive architecture of \Sys, with further details in subsequent subsections.

\subsection{Problem Formulation}

\wajih{the start of this subsection sounds very abrupt. It does not flow well.}
We define all mathematical notations for our system in Table~\ref{tab:keynotations}.

%\wajih{let's use the following table. If you think there are other key notations, then add them to table. Make sure to update this susbsection to refer to table as well. Make sure to use these notations in the rest of the subsections}

% \begin{table}[!ht]
%   \centering
%   \scriptsize
%   \caption{Key Notations}
%   \label{tab:keynotations}
%   \begin{tabular}{|c|p{4cm}|}
%   \hline
%   \textbf{Notation} & \textbf{Definition} \\ \hline
%   \( N \) & Total number of clients in federated learning. \\ \hline
%   \( k \) & Number of categories for process entities. \\ \hline
%   \( R \) & Number of federated learning rounds. \\ \hline
%   \( G_{c_i} = (\mathcal{V}_i, \mathcal{E}_i) \) & Provenance graph for client \( i \), with nodes \( \mathcal{V}_i \) and edges \( \mathcal{E}_i \). \\ \hline
%   \( \mathcal{G}_{\text{global}} \) & Set of global GNN models, one per category. \\ \hline
%   \( w_j^{(r)} \) & Weights of global GNN for category \( j \) after round \( r \). \\ \hline
%   \( \mathcal{P}_{\text{global}} \) & Global set of unique process entities. \\ \hline
%   \( \psi(p) \) & Categorization map assigning process \( p \) to category \( \mathcal{C}_j \). \\ \hline
%   \( y_v \) & True label of node \( v \). \\ \hline
%   \( \hat{y}_v^j \) & Predicted label of node \( v \) by submodel \( j \). \\ \hline
%   \( \mathcal{L}^{(r)} \) & Loss function value after round \( r \). \\ \hline
%   \end{tabular}
%   \end{table}
  
  \begin{table}[!t]
    \centering
    \scriptsize
    \caption{Key Notations}
    \label{tab:keynotations}
    \begin{tabular}{|c|p{6cm}|}
    \hline
    \textbf{Notation} & \textbf{Definition} \\ \hline
    \( N \) & Total number of clients in federated learning. \\ \hline
    \( k \) & Number of categories for process entities. \\ \hline
    \( C \) & Set of client machines \(\{Client_1, Client_2, \ldots, Client_N\}\). \\ \hline
    \( G_{c_i} = (\mathcal{V}_i, \mathcal{E}_i) \) & Provenance graph for client \( i \), with nodes \( \mathcal{V}_i \) and edges \( \mathcal{E}_i \). \\ \hline
    \( \mathcal{G}_{\text{global}} \) & Set of global GNN models, one per category. \\ \hline
    \( w_j^{(r)} \) & Weights of global GNN for category \( j \) after round \( r \). \\ \hline
    \( \mathcal{P}_{\text{global}} \) & Global set of unique process entities. \\ \hline
    \( \psi(p) \) & Categorization map assigning process \( p \) to category \( \mathcal{C}_j \). \\ \hline
    \( y_v \) & True label of node \( v \). \\ \hline
    \( \hat{y}_v^j \) & Predicted label of node \( v \) by submodel \( j \). \\ \hline
    \( \mathcal{E}_{\text{sem}} \) & Global semantic encoder converting contextual attributes into vector space. \\ \hline
    \( \mathcal{L}^{(r)} \) & Loss function value after round \( r \). \\ \hline
    \end{tabular}
  \end{table}

Each client machine in the set \( C \) locally maintains its logs to preserve privacy, ensuring that raw logs do not leave the machine. Our objective is to detect anomalous nodes within the client's provenance graphs, \( \{G_{c_1}, G_{c_2}, \ldots, G_{c_N}\} \), generated from these logs. To this end, we propose training a set of global GNN models \( \mathcal{G}_{\text{global}} \) to model the benign behavior exhibited across all client logs without centralizing the log data.

Additionally, we aim to develop a global semantic encoder \( \mathcal{E}_{\text{sem}} \), capable of converting contextual attributes into vector space, thereby generating feature vectors for training our GNN models. Using \( \mathcal{G}_{\text{global}} \), we aim to identify anomalous nodes in clients provenance graphs \( G_{c_i}\). These anomalies could be potential threats as their system activity significantly differs from benign patterns.

\begin{figure*}[t!]
  \centering
  \includegraphics[width=1\textwidth]{fig/archv3.pdf}
  \caption{High-level architecture of \Sys. In the training phase, our system builds local provenance graphs for each client and trains an ensemble of \gnnshort models. Prior to this, we aggregate semantic models contextually for feature encoding. The local \gnnshort models participate in federated learning to develop a global \gnnshort model, which is then utilized for anomaly detection. \wajih{Use key notations in this figure.}}
  \vspace{-3ex}
  \label{fig:arch}
\end{figure*}


  
% Let \( C = \{Client_1, Client_2, \ldots, Client_k\} \) denote the set of client machines, where each machine \( Client_i \), for \( i = 1, 2, \ldots, k \), locally maintains its \logs to preserve privacy, ensuring that raw logs do not leave the machine. Our objective is to detect anomalous nodes within the client's provenance graphs, \( \{G_{c_1}, G_{c_2}, \ldots, G_{c_P}\} \), generated from these logs. To this end, we propose training a set of global \gnnshort models to model the benign behavior exhibited across all client logs without centralizing the log data.

% Additionally, we aim to develop a global semantic encoder, \( \mathcal{E}_{\text{semantic}} \), capable of converting contextual attributes into vector space, thereby generating feature vectors for training our GNN models. Using these global \gnnshort models, we aim to identify anomalous nodes in provenance graphs constructed from \logs during runtime. These anomalies could be potential threats as their system activity significantly differs from benign patterns.


% \begin{figure*}[t!]
%   \centering
%   \includegraphics[width=1\textwidth]{fig/archv3.pdf}
%   \caption{High-level architecture of \Sys. In the training phase, our system builds local provenance graphs for each client and trains an ensemble of \gnnshort models. Prior to this, we aggregate semantic models contextually for feature encoding. The local \gnnshort models participate in federated learning to develop a global \gnnshort model, which is then utilized for anomaly detection. \wajih{Use key notations in this figure.}}
%   \vspace{-3ex}
%   \label{fig:arch}
% \end{figure*}

% % \subsection{Overview}
% \Sys comprises five key modules, starting with the \textit{Provenance Graph Constructor} module on each client machine, which transforms \logs into a provenance graph. While our approach to constructing provenance graphs builds on established methods~\cite{inam2023sok,nodoze2019,mpi+ma,loggc,lpm2015,hossain2017sleuth}, detailed information is provided in Appendix~\ref{sub:provconstruct}. The \textit{Semantic Featurization \& Harmonization} module (Section~\ref{semanfeat}) trains \wordvec models to encode semantic attributes and consolidates individual client models into a cohesive global model using a trusted utility server and encryption techniques. The \textit{Process Entity Categorization Module} (Section~\ref{sys:catg}) standardizes system entities across clients, ensuring uniformity in \gnnshort model training. The \textit{Federated Provenance Graph Learning Module} (Section~\ref{sys:fpgl}) then trains \gnnshort models on each client machine using harmonized semantic features, with the models aggregated on a central server through federated averaging. Finally, the \textit{Anomaly Detection Module} (Section~\ref{sys:anomaly_detection}) applies the unified global models for anomaly detection on each client machine. Figure \ref{fig:arch} illustrates the comprehensive architecture of \Sys, with further details in subsequent sections.


%\wajih{You need to talk about threat detection and alert generation.}

%\wajih{Give two or three sentences about the overall workflow. Think about what are the inputs, how the inputs are processed, and what are the outputs.} \wajih{Annotate "Audit Logs" in the Figure. Also use the word "Word2Vec" instead of Word2vec.}

%\wajih{Please divide this figure as we talked about. Use the color palette as I specified in the Dart Lab channel. Also, what is the difference between black and red edges? Could you add a legend for edges types?}

\subsection{Semantic Featurization \& Harmonization}
\label{semanfeat}

%\wajih{add a subsubsection to discuss non-overlapping token handling}

This module processes the provenance graph generated from system logs by transforming node attributes into feature vectors for the graph learning phase. Existing systems, such as \flash~\cite{flash2024}, have demonstrated the effectiveness of utilizing semantic attributes of nodes to enhance detection performance. System logs are rich in attributes related to various entities, including process names and file paths. These attributes must first be converted into vector space to serve as node features for our GNN model. For this encoding, we employ the \wordvec semantic encoder. The \wordvec model processes different attributes for each type of node: for process nodes, it considers the process name and command line arguments; for file nodes, the file path; for socket nodes, the network IP address and port; and for module nodes, the module name. We transform the subgraph for each node into a document by combining its semantic attributes with the types of causal events, such as system calls, involving its neighbors. These documents are then transformed into fixed-length vectors using a \wordvec model trained on non-malicious system logs. This approach effectively captures the semantic relationships between terms, producing dense embeddings that enhance the subsequent learning of graph representations.

\PP{Overlapping Tokens} Each client independently trains a \wordvec model using their local logs for feature encoding. However, before these models can be utilized to encode text attributes effectively, it is essential to contextually merge individual client \wordvec models into a unified model \( Word2vec_{Global} \) for use across all clients. This unification is crucial; without it, each client would produce a different encoding, \(v_a^i\), for identical inputs, where \(i\) denotes the client. The variability in feature vectors, \(\{v_a^1, v_a^2, \ldots, v_a^N\}\), for the same attribute \(a\) across \(N\) clients, would compromise the consistency of client-based \gnnshort models. To ensure uniformity, the feature vectors for overlapping attributes must be averaged across clients. Such averaging ensures consistency in the feature representation, enhancing the effectiveness of the downstream federated averaging technique by maintaining uniformity in the input space for the \gnnshort models across all clients.

\PP{Non Overlapping Tokens} Our system harmonizes only the tokens that overlap in the \wordvec models across clients. Tokens that do not overlap are not averaged and remain unchanged. While clients share common activities due to standard system-level routines, some variations and patterns are unique to each client. Non-overlapping tokens preserve these unique patterns; however, they contribute to additional heterogeneity, which cannot be eliminated through harmonization. If these unique patterns are not accurately learned, they can lead to high false alarm rates. To capture these distinct local variations between clients, we have developed a novel ensemble GNN learning framework, detailed in Section \ref{sys:fpgl}, where each submodel specializes in distinct system patterns across clients, enhancing model precision as shown in Section \ref{sec:eval}.

Our experiments with the \optc dataset revealed that, on average, different hosts can have up to 75\% overlap in process names, 41\% in files, and 60\% in network flows. This finding aligns with related work \cite{flash2024}, which shows that many system-level processes and files are common across different systems. In a centralized \pids, these attributes are learned by a single semantic encoder, mapping them to the same embedding space. In contrast, a federated setting, where each client trains its own encoder, can introduce model bias into the token embeddings, complicating the convergence for downstream GNN models using these vectors. To address this, it is essential to harmonize overlapping tokens to provide the model with a unified understanding of the semantic information present in system logs. 
The \wordvec model functions as a key-value store, with vocabulary tokens as keys, \(k\), and their corresponding vector representations as values, \(v_k\). To combine these models, we calculate the average vector of overlapping tokens from all client machines, creating a central model. The mathematical representation for averaging vectors of a token \(k\) across \(N\) clients is given by \(\bar{v}_k = \frac{1}{N}\sum_{i=1}^{N} v_{k,i}\) where \(\bar{v}_k\) is the averaged vector for token \(k\), and \(v_{k,i}\) is the vector representation of token \(k\) from the \(i\)-th client model.

However, transferring tokens -- containing sensitive data like process names, file names, and IP addresses -- to a central server could breach user privacy. To mitigate this, we employ a trusted utility server. Initially, the central server uses Fernet symmetric key encryption~\cite{ismail2020fernet,bokhari2016review} to generate an encryption key, which is distributed to clients. Clients then encrypt their \texttt{Word2vec} model tokens using the encryption key: \( E(v_{k}) = v_{k}^{'} \) and send them to the utility server. This server merges the encrypted models and dispatches the unified semantic vectors back to the respective clients, who decrypt them back: \( D(v_{k}^{'}) = v_{k} \). We present experimental studies in Section \ref{app:encrypt} that compare the efficiency of Fernet encryption with other methods.

This procedure ensures that neither the central server nor the utility server can access the actual token information, assuming no collusion between the two servers. The process is explained in detail in Algorithm~\ref{alg:secure_integration_averaging_word2vec}.

\begin{algorithm}[!t]
  \scriptsize
  \DontPrintSemicolon
  \SetKwInOut{Input}{Inputs}
  \SetKwInOut{Output}{Output}
  \Input{Client Word2Vec models $\{Word2vec_1, Word2vec_2, \ldots, Word2vec_k\}$.}
  \Output{Harmonized Word2Vec model $Word2vec_{Global}'$ sent to clients.}
  \BlankLine
  \tcc{Central server distribute symmetric encryption keys to each client.}
  \ForEach{client $C_i$}{

    Send $key$ to $C_i$\\
  }
  \tcc{Clients encrypt their model tokens.}
  \ForEach{client model $word2vec_i$}{
    $Word2vec_i \leftarrow$ EncryptModelTokens($Word2vec_i$, $E$) \tcc*{Encrypt tokens using $E$.}
    Send $Wor2vec_i$ to Utility Server\\
  }
  \tcc{Utility server merges encrypted models.}
  $TokenVectors \leftarrow$ InitializeEmptyDictionary()\\
  $TokenCounts \leftarrow$ InitializeEmptyDictionary()\\
  \ForEach{encrypted model $Word2vec_i$}{
    \ForEach{token $t$ in $Word2vec_i$}{
      $Vector \leftarrow Word2vec_i[t]$\\
      \eIf{$TokenVectors$.HasKey($t$)}{
        $TokenVectors[t] \leftarrow TokenVectors[t] + Vector$\\
        $TokenCounts[t] \leftarrow TokenCounts[t] + 1$\\
      }{
        $TokenVectors[t] \leftarrow Vector$\\
        $TokenCounts[t] \leftarrow 1$\\
      }
    }
  }
  \tcc{Average the vectors for overlapping tokens.}
  \ForEach{token $t$ in $TokenVectors$.Keys()}{
    $TokenVectors[t] \leftarrow TokenVectors[t] / TokenCounts[t]$\\
  }
  $Word2vec_{Global} \leftarrow$ NewModel($TokenVectors$, $EncryptedTokens$) \tcc*{Constructing a new harmonized model.}
  \ForEach{client $C_i$}{
    Send $Word2vec_{Global}$ to $C_i$\\
  }
  \BlankLine
  \Return{Harmonized model $Word2vec_{Global}$ has been dispatched to all clients.}\\
  \BlankLine
  \caption{Privacy preserving harmonization of \wordvec models.}
  \label{alg:secure_integration_averaging_word2vec}
\end{algorithm}

\subsection{Process Entity Categorization}
\label{sys:catg}

% \wajih{Use more formalism in this subsection and add an pseudocode/algorithm as well. You should use some notations like this:
% \begin{itemize}
%     \item \( N \): Total number of clients.
%     \item \( P_i \): Set of encrypted process entities from client \( i \), where \( i \in \{1, \dots, N\} \).
%     \item \( \mathcal{P}_{\text{global}} \): Global set of unique process entities, defined as:
%     \[
%     \mathcal{P}_{\text{global}} = \bigcup_{i=1}^{N} P_i
%     \]
%     \item \( k \): Number of predefined categories.
%     \item \( \mathcal{C} = \{\mathcal{C}_1, \mathcal{C}_2, \dots, \mathcal{C}_k\} \): Set of categories.
%     \item \( \psi(p) \): Categorization map that assigns a process \( p \in \mathcal{P}_{\text{global}} \) to a category \( \mathcal{C}_j \), where:
%     \[
%     \psi(p): \mathcal{P}_{\text{global}} \rightarrow \mathcal{C}
%     \]
% \end{itemize}
% }

Our experimental results, presented in Table~\ref{categorized_gnn}, indicate that a single \( \mathcal{G}_{\text{global}} \) model cannot achieve good detection performance in an FL setting due to the diverse and heterogeneous distributions of clients' data in the set \( C \). The disparity in data distributions among \( N \) clients poses a significant challenge in effectively training a unified model that can generalize well across all clients, since the global model struggles to capture the unique characteristics and patterns inherent in each client's data.

To address this limitation, we developed a comprehensive framework that organizes process entities across different clients into distinct groups. Each category is modeled by a dedicated submodel, enabling it to focus on the unique distribution and intricate patterns of its assigned category and thereby enhance overall detection performance.

The framework employs a central utility server that plays a pivotal role in the categorization process. Clients transmit lists of encrypted process names to the utility server to ensure privacy. The server aggregates these lists into a global list of process names \( \mathcal{P}_{\text{global}} \) and then applies the categorization map \( \psi(p) \) to randomly divide them into \( k \) global categories, where \( k \) is a predefined hyperparameter. Although this division is random, it is performed only once at the global level. Consequently, all occurrences of a given process name are mapped consistently across every client, such that \( \psi(p) = j \) assigns process \( p \) to category \( j \).

To illustrate this, consider two clients: \emph{A} and \emph{B}:
\begin{itemize}
    \item \emph{A} has a set of processes \{\texttt{chrome}, \texttt{ssh}, \texttt{mysql}\}.
    \item \emph{B} has a set of processes \{\texttt{chrome}, \texttt{firefox}, \texttt{ssh}, \texttt{mysql}\}.
\end{itemize}

Both clients send encrypted lists of these process names to the utility server, which merges them into a single global list of unique names \(\{\texttt{chrome}, \texttt{ssh}, \texttt{mysql}, \texttt{firefox}\}\). The server then applies \( \psi \) to randomly assign each name to one of the \( k \) categories, where \( k \) is a predefined hyperparameter. For instance, \( \psi(\texttt{chrome}) \) and \( \psi(\texttt{mysql}) \) might map to category 1, while \( \psi(\texttt{ssh}) \) and \( \psi(\texttt{firefox}) \) map to category 2.

This categorization is sent back to both clients. Now all occurrences of \texttt{chrome} and \texttt{mysql} fall under category~1 for both clients, while \texttt{ssh} and \texttt{firefox} fall under category~2. In this way, each category holds similar processes across all clients, guaranteeing consistency even though the initial split was random.

We conducted experiments to explore the impact of \( k \) on detection accuracy and FL training cost, as detailed in Appendix~\ref{app:ablation}.

The clients use the processes within each bin to generate provenance subgraphs \( G_{c_i} \). The neighborhood hop length of these subgraphs is set to match the number of graph convolution layers in the \( \mathcal{G}_{\text{global}} \). This ensures that the \( \mathcal{G}_{\text{global}} \) has complete neighborhood information for each node and that no interconnections are lost due to the categorization process. In our experiments, we set the hop length to two, which has been shown by prior works~\cite{wang2022threatrace,flash2024} to offer an optimal balance between efficiency and detection accuracy. These subgraphs serve as training data for an ensemble of \( \mathcal{G}_{\text{global}} \) models. Each submodel in the ensemble is trained on the subgraphs corresponding to its designated category and participates in federated averaging. Algorithm~\ref{alg:federated_provenance} explains this process in detail.

This approach ensures a balanced segmentation of data across clients, maintaining consistency in the training datasets for each \( \mathcal{G}_{\text{global}} \) model before federated averaging. By dividing the overall task into sub-tasks (sub-models) and assigning them to different subsets of processes, the influence of clients with large datasets is distributed across multiple models. This prevents any single client from disproportionately affecting the outcome of the federated learning system. Each sub-model specializes in a different aspect of the data, capturing unique patterns and distributions. This specialization promotes more balanced contributions across the ensemble, enhancing the robustness and performance of the overall system.


\begin{algorithm}[!t]
  \scriptsize
  \DontPrintSemicolon
  \SetKwInOut{Input}{Inputs}
  \SetKwInOut{Output}{Output}
  \Input{Number of clients $N$, Number of categories $k$, Client datasets $C$}
  \Output{Trained global GNN models $\mathcal{G}_{\text{global}}$}
  \BlankLine
  \tcc{Initialization of utility server and global process list.}
  $\mathcal{P}_{\text{global}} \leftarrow \emptyset$\\
  \ForEach{client $C_i \in C$}{
      Transmit encrypted process list to utility server\\
      \tcc{Utility server operates on encrypted lists to preserve privacy.}
      $\mathcal{P}_{\text{global}} \leftarrow \mathcal{P}_{\text{global}} \cup \text{Encrypt}(C_i)$
  }
  \BlankLine
  \tcc{Categorization of processes into $k$ categories.}
  \For{$p \in \mathcal{P}_{\text{global}}$}{
      $\psi(p) \leftarrow \text{RandomCategory}(k)$
  }
  \BlankLine
  \tcc{Distribute global category assignments to clients.}
  \ForEach{client $C_i \in C$}{
      Send categorization $\psi$ to $C_i$
  }
  \BlankLine
  \tcc{Local training of submodels for each category.}
  \ForEach{client $C_i \in C$}{
      \ForEach{$p \in C_i$}{
          $j \leftarrow \psi(p)$\\
          Train GNN submodel on $G_{c_i}$ using processes in category $j$
      }
  }
  \BlankLine
  \tcc{Aggregation and federated averaging of submodels.}
  \ForEach{category $j \in \{1, \ldots, k\}$}{
      $w_j^{(0)} \leftarrow \text{InitializeRandomWeights}()$\\
      \ForEach{client $C_i \in C$}{
          $w_j^{(i)} \leftarrow \text{ExtractWeights}(C_i, j)$
      }
      $w_j^{(r)} \leftarrow \text{FederatedAveraging}(\{w_j^{(i)}\})$
  }
  \BlankLine
  \Return $\mathcal{G}_{\text{global}} \leftarrow \{w_1^{(r)}, w_2^{(r)}, \ldots, w_k^{(r)}\}$\\
  \BlankLine
  \caption{FL with system entity categorization.}
  \label{alg:federated_provenance}
  \end{algorithm}  

\subsection{FL with Categorized Provenance Subgraphs}
\label{sys:fpgl}


% \wajih{I feel like the section should be named something like FL with Categorized Provenance Subgraphs. Use foramlism in this section as well:
% \begin{itemize}
%   \item \( \mathcal{G}_{\text{global}} \): Set of global GNN models initialized by the central server.
%   \item \( \mathcal{G}_i^{(j)} \): Local provenance graph for client \( i \) and category \( j \), where \( i \in \{1, \dots, N\} \) and \( j \in \{1, \dots, k\} \).
%   \item \( \mathcal{W}_{\text{global}} = \{w_1, w_2, \dots, w_k\} \): Parameters of the global GNN models for \( k \) categories.
%   \item \( w_j^{(r)} \): Weight vector of the global model for category \( j \) after FL round \( r \).
%   \item \( w_{i,j}^{(r)} \): Weight vector of the local model for client \( i \), category \( j \), and round \( r \).
%   \item \( N \): Total number of clients participating in the FL process.
%   \item \( k \): Number of predefined process categories.
%   \item \( R \): Total number of FL training rounds.
% \end{itemize}
% }

Advanced persistent threats involve multiple causally linked attack steps across various system entities, highlighting the need to capture and model the interactions among these entities for effective detection. Analyzing each system event in isolation does not allow us to capture these interactions properly, as observed in existing log-level systems~\cite{deeplog2017,liu2019log2vec,xia2019loggan}; hence, provenance graphs, \( G_{c_i} \), are being used to effectively model the interaction of system entities. Moreover, Graph Representation Learning is used to learn the patterns present in these graphs, as shown in related works~\cite{flash2024,cheng2023kairos,jia2023magic}. We integrate federated learning with graph representation learning to bring privacy and decentralization to intrusion detection while maintaining the strong detection performance offered by the provenance graph learning technique.

Our approach includes a central server responsible for initializing the global GNN models, \(\mathcal{G}_{\text{global}}\), with random weights, \( w_j^{(0)} \), which are then sent to all clients in \( C \). These clients use their local process subgraphs, \( G_{c_i} \), and semantic feature vectors to train the GNN models in an unsupervised way, following a training method similar to Flash. The objective of the GNN model is to classify each node \( v \) into its corresponding type, yielding predictions \(\hat{y}_v^j\). The server then applies the federated averaging algorithm to merge the GNN models into a set of global models, \(\mathcal{G}_{\text{global}}\), based on the process entity categories on which they were trained. This ensures that models with similar distributions are combined together to address the data heterogeneity problem. Specifically, the server aggregates parameters from \( N \) client models to update the global model as \(\bar{w} = \frac{1}{N} \sum_{i=1}^{N} w_i\).

The federated averaging process is repeated for a set number of rounds \( R \), and concludes when there is no further reduction in the training loss, \(\mathcal{L}^{(r)}\). %Algorithm~\ref{alg:federated_learning} shows the training and aggregation process of GNN for a given process category and one round of FL.

% \begin{algorithm}[!t]
%   \scriptsize
%   \DontPrintSemicolon
%   \SetKwInOut{Input}{Inputs}
%   \SetKwInOut{Output}{Output}
%   \Input{Set of client models $\{GNN_1, GNN_2, \ldots, GNN_N\}$;\\}
%   \Output{Global GNN model $GNN_{Global}$.}
%   \BlankLine
%   \tcc{Initialize global GNN model with random weights for a given process Category.}
%   %\tcc{This initialization happens for the first FL round only.}
%   $G \leftarrow \text{InitializeRandomWeights}()$\\
%   \tcc{Distribute $GNN$ to all clients.}
%   \ForEach{client}{
%     Send $GNN$ to $Client_i$\\
%     $GNN \leftarrow \text{TrainOnLocalData}(ProcessCategory_i)$
%   }
%   \BlankLine
%   \tcc{Aggregate trained models from clients.}
%   $AggregatedWeights \leftarrow list([])$\\
%   \ForEach{client model $GNN_i$}{
%     $AggregatedWeights.append(\text{ExtractWeights}(GNN_i))$\\
%   }
%   \tcc{Apply federated averaging.}
%   $GNN_{Global} \leftarrow \text{FederatedAveraging}(AggregatedWeights)$\\
%   \BlankLine
%   \Return $GNN_{Global}$\\
%   \BlankLine
%   \caption{Federated Provenance Graph Learning}
%   \label{alg:federated_learning}
% \end{algorithm}

\subsection{GNN-based Anomaly Detection}
\label{sys:anomaly_detection}

\Sys employs a standard node level detection methodology focusing on identifying irregular nodes through the comparison of their expected and observed types. This approach is grounded in a detailed analysis of both the surrounding structures and inherent properties of the nodes, to define normal pattern baselines for various node types. Typically, entities with malicious intentions display neighborhood structures and characteristics deviating from these established norms. In operational phases, the detection of anomalies that diverge from the pre-established node distribution patterns often results in their misclassification. The emergence of nodes misclassified in the system's output is indicative of potential security issues.

\Sys performs threat detection in a decentralized manner on client's provenance graphs (\( \{G_{c_1}, G_{c_2}, \ldots, G_{c_P}\} \)) in an organization. For a given provenance graph on a client machine containing nodes \(V\) and edges \(E\), \Sys uses the global \(\{GNN_1, GNN_2, \ldots, GNN_k\}\) \gnnshort models trained using federated learning. Each submodel performs inference on client's full provenance graph, utilizing the nodes' features \(X_v\) and the graph's adjacency matrix \(A\) to predict each node \(v\)'s label \(y_v^i\). A node \(v\) is identified as an anomaly if it is misclassified by all submodels, indicating that none of the submodels recognize the neighborhood structure or features displayed by this node. 

To regulate the frequency of alerts, we define a threshold \(T\) similar to \flash. This parameter sets a threshold on the likelihood of a classification being considered valid, with a higher value of \(T\) implying stronger confidence and increasing the probability of identifying anomalies. 