\section{\Sys Design}
\label{sec:methodology}

In this section, we outline the architecture of our system, \Sys, which comprises five principal modules. The first module, the \textit{Provenance Graph Constructor}, operates on each client machine, transforming audit logs into a provenance graph. The second module, \textit{Semantic Featurization}, focuses on encoding semantic attributes from audit logs into feature vectors, which aids in the training of the client-specific \gnnshort models. This process utilizes word2vec models, each individually trained on its respective client's logs.

The third module, \textit{Semantic Vectors Harmonization}, is tasked with merging these individual word2vec models into a unified global model. This is achieved using a trusted utility server and encryption techniques to safeguard sensitive model data. Subsequent to this, the \textit{Graph Learning Module} is responsible for training \gnnshort models on each client machine, using the harmonized semantic features.

The fifth module, positioned on the central server, is the \textit{Federated Learning Module}. It employs the federated averaging algorithm to process \gnnshort models gathered from clients. Finally, the \textit{Anomaly Detection Module} utilizes the aggregated global models for local anomaly detection on each client machine. Figure \ref{arch} illustrates the overarching architecture of \Sys, with a more comprehensive explanation provided in the following subsections:

\subsection{Provenance Graph Constructor}
\subsection{Semantic Featurization}
\subsection{Semantic Vectors Harmonization}
\subsection{Graph Learning}
\subsection{Federated Learning}
\subsection{Anomaly Detection}





% \subsection{Provenance Graph Constructor}
% Our approach starts by converting system logs into provenance graphs through a three-step process. Initially, the system, \Sys, processes system logs like Windows Event Logs or Linux Audit Logs, which are composed of host event details including process activities, file interactions, and network engagements. \Sys works with batches of audit logs, utilizing a sliding window technique to create the provenance graph. This graph consists of two kinds of nodes: process nodes and object nodes. The object nodes represent various system entities such as files, network streams, modules, and other system components. The connections between these nodes are marked with labels indicating the event type, elucidating the cause-and-effect relationship among the connected nodes and the event's timestamp. Additionally, these nodes are equipped with attributes like process identifiers, command lines, file paths, IP addresses, port details, and module paths, offering additional insights and specifics.

% \subsection{Semantic Vectors Harmonization}
% \wajih{You need to add formalism in this subsection overall. If there is a Math related to Harmonization add that. Look into the Flash paper -- we gave so much internal details about the algorithms. }
% Our system employs the word2vec model to encode various semantic attributes into a vector space, which is pivotal in distinguishing normal system entities from anomalies. Traditional approaches utilize a centralized word2vec model for this encoding. However, in a federated learning context, complexities arise as each individual client must train its word2vec model for attribute encoding. Consequently, different clients might encode the same attributes into diverse vectors, leading to a non-Independent and Identically Distributed (Non-IID) problem. This variation hampers the convergence of the Graph Neural Network (GNN) model in federated learning scenarios. 

% To address this issue, we have developed a technique leveraging a utility server to synchronize disparate models across clients. This approach achieves uniformity in encoding the same attributes while preserving privacy, as clients are not required to share their attributes. The process initiates with the main server distributing an encryption and decryption key to each client. Clients then encrypt their word2vec model tokens, concealing their meanings. Subsequently, these encrypted models are sent to the utility server, which remains unaware of the encryption key used. The utility server then averages the vectors for the corresponding encrypted tokens, creating a unified and harmonized word2vec model. Finally, this model is returned to the clients, who utilize the decryption key to revert their encrypted tokens to their original attributes.

% \subsection{Federated Learning Module}
% \wajih{You need to add formalism in this subsection overall. If there is a Math related to FL add that. Look into the Flash paper -- we gave so much internal details about the algorithms. }
% Each client machine independently trains a \gnn model on a provenance graph built from its local log data, thereby preserving privacy. These individually trained models are then sent to the main server. Upon receiving them, the main server applies a federated averaging algorithm to integrate these models into a single, centralized model. This unified model is subsequently distributed back to each client. This cycle of training and unification is repeated over several rounds until the model reaches convergence. Finally, clients employ the fully trained model to perform anomaly detection.

% \subsection{Anomaly Detection}
% \wajih{Again missing scientific details about your approach.}
% \Sys utilizes an advanced approach to pinpoint irregular nodes by assessing the disparity between their expected and observed types. This method is rooted in a thorough examination of the surrounding structures and intrinsic qualities of nodes, aiming to establish a baseline of normal patterns for various node classifications. It is observed that entities with malicious intent often manifest neighborhood configurations and characteristics that are inconsistent with these established norms. During operational phases, encountering such anomalies that stand apart from the pre-learned node distribution patterns leads to their erroneous classification. The presence of nodes incorrectly categorized in the output serves as an indicator of potential security concerns. We have introduced a regulatory mechanism in the form of a threshold parameter, $T$, to oversee the frequency of alerts. This parameter effectively caps the classification likelihood for a given prediction. A higher parameter value correlates with stronger conviction in the prediction, signaling a greater chance of uncovering anomalies.


\begin{figure}[t!]
    \centering
    \includegraphics[width=0.45\textwidth]{fig/arch.pdf}
    \caption{High Level Architecture of \Sys. \wajih{This diagram is not acceptable. It does not give much details and also it lacks aesthetics. Look how detailed the Flash paper diagram was. Also, look at that Nature paper diagram.}}
    \vspace{-3ex}
    \label{arch}
  \end{figure}
