{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import json\n",
    "import copy\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from multiprocessing import Pool\n",
    "from itertools import compress\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import multiprocessing\n",
    "import random\n",
    "import xxhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_word2vec_models(models):\n",
    "    # Create an empty unified model\n",
    "    unified_model = Word2Vec(vector_size=models[0].vector_size, window=models[0].window, min_count=models[0].min_count, sg=models[0].sg)\n",
    "\n",
    "    # Initialize the vocabulary with the words from the first model\n",
    "    unified_model.build_vocab([list(models[0].wv.index_to_key)])\n",
    "\n",
    "    # Copy the vectors from the first model to the unified model for the initial vocabulary\n",
    "    for word in unified_model.wv.index_to_key:\n",
    "        unified_model.wv[word] = models[0].wv[word]\n",
    "\n",
    "    # Iterate through the remaining models and add their unique words and average vectors for overlapping words\n",
    "    for model in models[1:]:\n",
    "        # Get the set of unique words in the current model's vocabulary\n",
    "        unique_words = set(model.wv.index_to_key) - set(unified_model.wv.index_to_key)\n",
    "\n",
    "        # Add the unique words to the unified model's vocabulary\n",
    "        unified_model.build_vocab([list(unique_words)], update=True)\n",
    "\n",
    "        # Iterate through the overlapping words and average their vectors\n",
    "        for word in set(model.wv.index_to_key).intersection(set(unified_model.wv.index_to_key)):\n",
    "            unified_model.wv[word] = (unified_model.wv[word] + model.wv[word]) / 2.0\n",
    "\n",
    "        # Copy the vectors for the unique words from the current model to the unified model\n",
    "        for word in unique_words:\n",
    "            unified_model.wv[word] = model.wv[word]\n",
    "\n",
    "    return unified_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryptography.fernet import Fernet\n",
    "import gensim\n",
    "import base64\n",
    "\n",
    "def generate_key():\n",
    "    \"\"\"\n",
    "    Generates a random encryption key.\n",
    "\n",
    "    Returns:\n",
    "    bytes: A random encryption key.\n",
    "    \"\"\"\n",
    "    return Fernet.generate_key()\n",
    "\n",
    "def encrypt_word2vec_model(word2vec_model, encryption_key):\n",
    "    \"\"\"\n",
    "    Encrypts the tokens in a Word2Vec model using a given encryption key.\n",
    "\n",
    "    Args:\n",
    "    word2vec_model (gensim.models.Word2Vec): The Word2Vec model to encrypt.\n",
    "    encryption_key (bytes): The encryption key for token privacy.\n",
    "\n",
    "    Returns:\n",
    "    gensim.models.Word2Vec: The modified Word2Vec model with encrypted tokens.\n",
    "    \"\"\"\n",
    "    f = Fernet(encryption_key)\n",
    "    vector_size = word2vec_model.vector_size  # Get the vector size from the original model\n",
    "    encrypted_model = gensim.models.Word2Vec(vector_size=vector_size, min_count=1)  # Create a new Word2Vec model\n",
    "    \n",
    "    for word in word2vec_model.wv.index_to_key:\n",
    "        vector = word2vec_model.wv.get_vector(word)\n",
    "        # Encrypt the word using the encryption_key\n",
    "        encrypted_word = f.encrypt(word.encode()).decode()\n",
    "        \n",
    "        # Add the encrypted word and its vector to the new model\n",
    "        encrypted_model.wv[encrypted_word] = vector\n",
    "    \n",
    "    return encrypted_model\n",
    "\n",
    "def decrypt_word2vec_model(word2vec_model, encryption_key):\n",
    "    \"\"\"\n",
    "    Decrypts the tokens in an encrypted Word2Vec model using a given encryption key.\n",
    "\n",
    "    Args:\n",
    "    encrypted_model (gensim.models.Word2Vec): The encrypted Word2Vec model to decrypt.\n",
    "    encryption_key (bytes): The encryption key used for encryption.\n",
    "\n",
    "    Returns:\n",
    "    gensim.models.Word2Vec: The Word2Vec model with original tokens.\n",
    "    \"\"\"\n",
    "    f = Fernet(encryption_key)\n",
    "    vector_size = word2vec_model.vector_size  # Get the vector size from the original model\n",
    "    decrypted_model = gensim.models.Word2Vec(vector_size=vector_size, min_count=1)  # Create a new Word2Vec model\n",
    "    \n",
    "    for word in word2vec_model.wv.index_to_key:\n",
    "        vector = word2vec_model.wv.get_vector(word)\n",
    "        # Encrypt the word using the encryption_key\n",
    "        decrypted_word = f.decrypt(word.encode()).decode()\n",
    "        \n",
    "        # Add the encrypted word and its vector to the new model\n",
    "        decrypted_model.wv[decrypted_word] = vector\n",
    "    \n",
    "    return decrypted_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "encryption_key = generate_key()\n",
    "\n",
    "encrypted_models = []\n",
    "for path in [\"051.txt.model\", \"201.txt.model\", \"501.txt.model\"]:\n",
    "    word2vec_model = gensim.models.Word2Vec.load(f\"Content_FL_Exp/{path}\")\n",
    "    \n",
    "    # Encrypt the Word2Vec model\n",
    "    encrypted_model = encrypt_word2vec_model(word2vec_model, encryption_key)\n",
    "    encrypted_models.append(encrypted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = combine_word2vec_models(encrypted_models)\n",
    "final_model.save(\"Content_FL_Exp/encrypted_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "decrypted_model = decrypt_word2vec_model(final_model, encryption_key)\n",
    "decrypted_model.save(\"Content_FL_Exp/decrypted_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gAAAAABlHz7S60-hZnmgRNwnRGm6uQ9pJ2PyYyC_CTf2I3sgl3ucsgCAdLNP96cOgwMQST07L2Ot0k7ZwE81VBkKStI2rR64mA==\n",
      "gAAAAABlHz7V9YJPTFuBgzdMNDAnIi59A2QTUPK__jXGBvy58wvf0hArQfPa72u4SDvDNYkHJs0dJLOuBcfFQxEnl6lt8nhPQA==\n",
      "gAAAAABlHz7lANrRUR7DU9spkuVsCeUGwNHfPguyyuzTPBKzqyt64LVz5n1PKCm9WwBQ_MeNns4fMq_qgIG9A5LVBUOSssrGyg==\n"
     ]
    }
   ],
   "source": [
    "print(encrypted_models[0].wv.index_to_key[0])\n",
    "print(encrypted_models[1].wv.index_to_key[0])\n",
    "print(encrypted_models[2].wv.index_to_key[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(final_model.wv.index_to_key[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Device\\HarddiskVolume1\\WINDOWS\\SYSTEM32\\WPDBUSENUM.DLL\n"
     ]
    }
   ],
   "source": [
    "print(decrypted_model.wv.index_to_key[100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.12.0",
   "language": "python",
   "name": "pytorch-1.12.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
