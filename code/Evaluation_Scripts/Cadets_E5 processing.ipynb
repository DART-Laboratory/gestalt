{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_264608/3095134833.py:7: DeprecationWarning: The 'http_auth' parameter is deprecated. Use 'basic_auth' or 'bearer_auth' parameters instead\n",
      "  es = Elasticsearch([host], http_auth=(username, password))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Elasticsearch.\n",
      "Index cadets* exists.\n",
      "Total documents to process: 1217886929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Documents:   0%|          | 3247001/1217886929 [03:44<22:42:25, 14858.77it/s]"
     ]
    }
   ],
   "source": [
    "username = 'elastic'\n",
    "password = 'stimulus5affect-roof'\n",
    "host = 'http://128.143.69.88:9200'\n",
    "index_name = \"cadets*\"\n",
    "\n",
    "# Initialize Elasticsearch client\n",
    "es = Elasticsearch([host], http_auth=(username, password))\n",
    "\n",
    "# Test connection and index existence\n",
    "if not es.ping():\n",
    "    print(\"Elasticsearch cluster is not accessible!\")\n",
    "else:\n",
    "    print(\"Connected to Elasticsearch.\")\n",
    "if not es.indices.exists(index=index_name):\n",
    "    print(f\"Index {index_name} does not exist.\")\n",
    "else:\n",
    "    print(f\"Index {index_name} exists.\")\n",
    "\n",
    "# Define the query\n",
    "query = {\"query\": {\"match_all\": {}}}\n",
    "\n",
    "# Get total count of documents to process\n",
    "total_docs = es.count(index=index_name, body=query)['count']\n",
    "print(f\"Total documents to process: {total_docs}\")\n",
    "\n",
    "edge_types = set([\n",
    "    'EVENT_CLOSE',\n",
    "    'EVENT_OPEN',\n",
    "    'EVENT_READ',\n",
    "    'EVENT_WRITE',\n",
    "    'EVENT_EXECUTE',\n",
    "    'EVENT_RECVFROM',\n",
    "    'EVENT_RECVMSG',\n",
    "    'EVENT_SENDMSG',\n",
    "    'EVENT_SENDTO',\n",
    "])\n",
    "\n",
    "# Define file paths\n",
    "id_to_type_file = 'e5_data/cadets_id_to_type.json'\n",
    "net2prop_file = 'e5_data/cadets_net2prop.json'\n",
    "\n",
    "# Define file paths\n",
    "id_to_type_file = 'e5_data/cadets_id_to_type.json'\n",
    "net2prop_file = 'e5_data/cadets_net2prop.json'\n",
    "info_file = 'e5_data/cadets_info.json'\n",
    "\n",
    "# Initialize buffers\n",
    "net2prop_buffer = []\n",
    "id_to_type_buffer = []\n",
    "info_buffer = []\n",
    "buffer_size = 1000000  # Change this number to adjust the buffer size\n",
    "\n",
    "# Function to append data to a file\n",
    "def append_to_file(file_path, data):\n",
    "    with open(file_path, 'a') as file:\n",
    "        for item in data:\n",
    "            file.write(json.dumps(item) + '\\n')\n",
    "\n",
    "# Function to check buffer and flush if necessary\n",
    "def check_and_flush_buffer():\n",
    "    global net2prop_buffer, id_to_type_buffer, info_buffer\n",
    "    if len(net2prop_buffer) >= buffer_size:\n",
    "        append_to_file(net2prop_file, net2prop_buffer)\n",
    "        net2prop_buffer = []\n",
    "    if len(id_to_type_buffer) >= buffer_size:\n",
    "        append_to_file(id_to_type_file, id_to_type_buffer)\n",
    "        id_to_type_buffer = []\n",
    "    if len(info_buffer) >= buffer_size:\n",
    "        append_to_file(info_file, info_buffer)\n",
    "        info_buffer = []\n",
    "        \n",
    "# Start processing documents\n",
    "with tqdm(total=total_docs, desc=\"Processing Documents\") as pbar:\n",
    "    for doc in helpers.scan(es, query=query, index=index_name, size=1000):\n",
    "        pbar.update(1)\n",
    "        \n",
    "        line = doc['_source']\n",
    "        str_line = json.dumps(line)\n",
    "        \n",
    "        if \"avro.cdm20.NetFlowObject\" in str_line:\n",
    "            net_flow_object = line['datum']['com.bbn.tc.schema.avro.cdm20.NetFlowObject']\n",
    "            try:\n",
    "                nodeid = net_flow_object['uuid']\n",
    "                srcaddr = net_flow_object['localAddress'].get('string')\n",
    "                srcport = net_flow_object['localPort'].get('int')\n",
    "                dstaddr = net_flow_object['remoteAddress'].get('string')\n",
    "                dstport = net_flow_object['remotePort'].get('int')\n",
    "\n",
    "                net2prop_data = {nodeid: [srcaddr, srcport, dstaddr, dstport]}\n",
    "                id_to_type_data = {nodeid: 'NETFLOW'}\n",
    "                net2prop_buffer.append(net2prop_data)\n",
    "                id_to_type_buffer.append(id_to_type_data)\n",
    "            except: \n",
    "                pass\n",
    "\n",
    "        if \"schema.avro.cdm20.Subject\" in str_line:\n",
    "            subject = line['datum']['com.bbn.tc.schema.avro.cdm20.Subject']\n",
    "            uuid = subject['uuid']\n",
    "            record_type = subject['type'] \n",
    "            id_to_type_data = {uuid: record_type}\n",
    "            id_to_type_buffer.append(id_to_type_data)\n",
    "\n",
    "        if \"schema.avro.cdm20.FileObject\" in str_line:\n",
    "            file_object = line['datum']['com.bbn.tc.schema.avro.cdm20.FileObject']\n",
    "            uuid = file_object['uuid']\n",
    "            file_type = file_object['type']\n",
    "            id_to_type_data = {uuid: file_type}\n",
    "            id_to_type_buffer.append(id_to_type_data)\n",
    "            \n",
    "        try:\n",
    "            x = line\n",
    "            \n",
    "            try:\n",
    "                action = x['datum']['com.bbn.tc.schema.avro.cdm20.Event']['type']\n",
    "            except KeyError:\n",
    "                action = ''\n",
    "            try:\n",
    "                actor = x['datum']['com.bbn.tc.schema.avro.cdm20.Event']['subject']['com.bbn.tc.schema.avro.cdm20.UUID']\n",
    "            except KeyError:\n",
    "                actor = ''\n",
    "            try:\n",
    "                obj = x['datum']['com.bbn.tc.schema.avro.cdm20.Event']['predicateObject']['com.bbn.tc.schema.avro.cdm20.UUID']\n",
    "            except KeyError:\n",
    "                obj = ''\n",
    "            try:\n",
    "                cmd = x['datum']['com.bbn.tc.schema.avro.cdm20.Event']['properties']['map']['exec']\n",
    "            except KeyError:\n",
    "                cmd = ''\n",
    "            try:\n",
    "                path = x['datum']['com.bbn.tc.schema.avro.cdm20.Event']['predicateObjectPath']['string']\n",
    "            except KeyError:\n",
    "                path = ''\n",
    "            try:\n",
    "                timestampnano = x['datum']['com.bbn.tc.schema.avro.cdm20.Event']['timestampNanos']\n",
    "                timestamp = x['@timestamp']\n",
    "            except KeyError:\n",
    "                timestamp = ''\n",
    "                timestampnano = ''\n",
    "\n",
    "            if action in edge_types:\n",
    "                info_data = {'actorID': actor, 'objectID': obj, 'action': action, 'timestampNanos': timestampnano, 'timestamp': timestamp, 'exec': cmd, 'path': path, 'hostid': x['hostId']}\n",
    "                info_buffer.append(info_data)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        check_and_flush_buffer()\n",
    "        \n",
    "append_to_file(net2prop_file, net2prop_buffer)\n",
    "append_to_file(id_to_type_file, id_to_type_buffer)\n",
    "append_to_file(info_file, info_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.12.0",
   "language": "python",
   "name": "pytorch-1.12.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
