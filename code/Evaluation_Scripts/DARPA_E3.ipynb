{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "F1op-CbyLuN4"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Importing the require libraries here\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import json \n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "warnings.filterwarnings('ignore')\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "import multiprocessing\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading libraries and setting up working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nM7KaeCbA_mQ"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Importing some additional libraries\n",
    "'''\n",
    "from pprint import pprint\n",
    "import gzip\n",
    "from sklearn.manifold import TSNE\n",
    "import json\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 10 2 10\n",
    "num_of_ctg = 10\n",
    "learning_rounds = 3\n",
    "epochs = 10\n",
    "hosts = ['cadets','theia','trace']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining functions for loading, cleaning and constructing features from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "BfjmrhfUr3pK"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This is the main featurizer. It constructs the graph for the cadets dataset.\n",
    "\n",
    "Args:\n",
    "    df (DataFrame): This is the main dataframe containing all the system events from the cadets dataset.\n",
    "\n",
    "return:\n",
    "    features (list): Contains word2vec encoded feature vectors for each node\n",
    "    feat_labels (list): Contains label for each node\n",
    "    edge_index (list): Contains information about edges between nodes in the graph.\n",
    "    mapp (list): contains id of each node\n",
    "'''\n",
    "\n",
    "tokens = ['SUBJECT_PROCESS',\n",
    "          'FILE_OBJECT_FILE',\n",
    "          'NetFlowObject'\n",
    "         ]\n",
    "\n",
    "def prepare_graph(df):\n",
    "    nodes = {}\n",
    "    labels = {}\n",
    "    edges = []\n",
    "    proc = {}\n",
    "    \n",
    "    global tokens\n",
    "    dummies = {token: index for index, token in enumerate(tokens)}\n",
    "\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        x = df.iloc[i]\n",
    "        action = x[\"action\"]\n",
    "        \n",
    "        actorid = x[\"actorID\"]\n",
    "        if not (actorid in nodes):\n",
    "            nodes[actorid] =  []\n",
    "        nodes[actorid].append(x['exec'])\n",
    "        nodes[actorid].append(action)\n",
    "        if x['path'] != '':\n",
    "            nodes[actorid].append(x['path'])\n",
    "        labels[actorid] = dummies[x['actor_type']]\n",
    "\n",
    "        objectid = x[\"objectID\"]\n",
    "        if not (objectid in nodes):\n",
    "            nodes[objectid] =  []\n",
    "        nodes[objectid].append(x['exec'])\n",
    "        nodes[objectid].append(action)\n",
    "        if x['path'] != '':\n",
    "             nodes[objectid].append(x['path'])\n",
    "        labels[objectid] = dummies[x['object']]\n",
    "\n",
    "        edges.append(( actorid, objectid ))\n",
    "        \n",
    "        proc[actorid] = x['actorID']\n",
    "\n",
    "    features = []\n",
    "    feat_labels = []\n",
    "    edge_index = [[],[]]\n",
    "    index  = {}\n",
    "    mapp = []\n",
    "\n",
    "    all_procs = set()\n",
    "\n",
    "    for k,v in nodes.items():\n",
    "        features.append(v)\n",
    "        feat_labels.append(labels[k])\n",
    "        index[k] = len(features) - 1\n",
    "        mapp.append(k)\n",
    "        \n",
    "        if k in proc:\n",
    "            all_procs.add(proc[k])\n",
    "\n",
    "    for x in edges:\n",
    "        src = index[x[0]]\n",
    "        dst = index[x[1]]\n",
    "\n",
    "        edge_index[0].append(src)\n",
    "        edge_index[1].append(dst)\n",
    "        \n",
    "    idx_to_proc = {}\n",
    "    for i in range(len(mapp)):\n",
    "        if mapp[i] in proc:\n",
    "            idx_to_proc[i] = proc[mapp[i]]\n",
    "            \n",
    "    all_procs = list(all_procs)\n",
    "\n",
    "    return features,feat_labels,edge_index,mapp,all_procs,idx_to_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import SAGEConv, GATConv\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self,in_channel,out_channel):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channel, 32, normalize=True)\n",
    "        self.conv2 = SAGEConv(32, out_channel, normalize=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
    "    \n",
    "        x = self.encode(x, edge_index)\n",
    "        return F.softmax(x, dim=1)\n",
    "    \n",
    "    def encode(self, x: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.tanh(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "    \n",
    "    def freeze_conv_layers(self):\n",
    "        for param in self.conv1.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.conv2.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YBuP_tSq94f4"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This function helps visualize the output of the model.\n",
    "'''\n",
    "def visualize(h, color):\n",
    "    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding semantic attributes from the raw cadets data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function is used for attributing semnatic information like process names, executable paths,\n",
    "file paths etc using the raw cadets data\n",
    "'''\n",
    "\n",
    "def add_attributes(d,p):\n",
    "    \n",
    "    f = open(p)\n",
    "    data = [json.loads(x) for x in f if \"EVENT\" in x]\n",
    "\n",
    "    info = []\n",
    "    for x in data:\n",
    "        try:\n",
    "            action = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['type']\n",
    "        except:\n",
    "            action = ''\n",
    "        try:\n",
    "            actor = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['subject']['com.bbn.tc.schema.avro.cdm18.UUID']\n",
    "        except:\n",
    "            actor = ''\n",
    "        try:\n",
    "            obj = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['predicateObject']['com.bbn.tc.schema.avro.cdm18.UUID']\n",
    "        except:\n",
    "            obj = ''\n",
    "        try:\n",
    "            timestamp = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['timestampNanos']\n",
    "        except:\n",
    "            timestamp = ''\n",
    "        try:\n",
    "            cmd = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['properties']['map']['exec']\n",
    "        except:\n",
    "            cmd = ''\n",
    "        try:\n",
    "            path = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['predicateObjectPath']['string']\n",
    "        except:\n",
    "            path = ''\n",
    "        try:\n",
    "            path2 = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['predicateObject2Path']['string']\n",
    "        except:\n",
    "            path2 = ''\n",
    "        try:\n",
    "            obj2 = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['predicateObject2']['com.bbn.tc.schema.avro.cdm18.UUID']\n",
    "            info.append({'actorID':actor,'objectID':obj2,'action':action,'timestamp':timestamp,'exec':cmd, 'path':path2})\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        info.append({'actorID':actor,'objectID':obj,'action':action,'timestamp':timestamp,'exec':cmd, 'path':path})\n",
    "\n",
    "    rdf = pd.DataFrame.from_records(info).astype(str)\n",
    "    d = d.astype(str)\n",
    "\n",
    "    return d.merge(rdf,how='inner',on=['actorID','objectID','action','timestamp']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_word2vec_models(models):\n",
    "    # Create an empty unified model\n",
    "    unified_model = Word2Vec(vector_size=models[0].vector_size, window=models[0].window, min_count=models[0].min_count, sg=models[0].sg)\n",
    "\n",
    "    # Initialize the vocabulary with the words from the first model\n",
    "    unified_model.build_vocab([list(models[0].wv.index_to_key)])\n",
    "\n",
    "    # Copy the vectors from the first model to the unified model for the initial vocabulary\n",
    "    for word in unified_model.wv.index_to_key:\n",
    "        unified_model.wv[word] = models[0].wv[word]\n",
    "\n",
    "    # Iterate through the remaining models and add their unique words and average vectors for overlapping words\n",
    "    for model in models[1:]:\n",
    "        # Get the set of unique words in the current model's vocabulary\n",
    "        unique_words = set(model.wv.index_to_key) - set(unified_model.wv.index_to_key)\n",
    "\n",
    "        # Add the unique words to the unified model's vocabulary\n",
    "        unified_model.build_vocab([list(unique_words)], update=True)\n",
    "\n",
    "        # Iterate through the overlapping words and average their vectors\n",
    "        for word in set(model.wv.index_to_key).intersection(set(unified_model.wv.index_to_key)):\n",
    "            unified_model.wv[word] = (unified_model.wv[word] + model.wv[word]) / 2.0\n",
    "\n",
    "        # Copy the vectors for the unique words from the current model to the unified model\n",
    "        for word in unique_words:\n",
    "            unified_model.wv[word] = model.wv[word]\n",
    "\n",
    "    return unified_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from multiprocessing import Pool\n",
    "from itertools import compress\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_models = []\n",
    "#for m in ['cadets','theia','trace']:\n",
    "#    word2vec = Word2Vec.load(f\"content/word2vec_{m}_E3.model\")\n",
    "#    word_models.append(word2vec)\n",
    "\n",
    "#global_word = combine_word2vec_models(word_models)\n",
    "#global_word.save(\"Content_FL_Exp/global_word2vec_E3.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#phrases,labels,edges,mapp = prepare_graph(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "3RDmGME5iPb5"
   },
   "outputs": [],
   "source": [
    "#word2vec = Word2Vec(sentences=phrases, vector_size=30, window=5, min_count=1, workers=8,epochs=300,callbacks=[saver,logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "p3TAi69zI1bO"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Defining the train and test function in this cell \n",
    "'''\n",
    "from sklearn.utils import class_weight\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Vn_pMyt5Jd-6"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Encoding function for running word2vec inference\n",
    "'''\n",
    "from collections import Counter\n",
    "word2vec = Word2Vec.load(\"Content_FL_Exp/global_word2vec_E3.model\")\n",
    "\n",
    "def infer(doc):\n",
    "    global word2vec\n",
    "    temp = dict(Counter(doc))\n",
    "    emb = np.zeros(30)\n",
    "    count = 0\n",
    "    for k,v in temp.items():\n",
    "        if k in word2vec.wv:\n",
    "            emb = emb + word2vec.wv[k]*v\n",
    "            count = count + 1\n",
    "    emb = emb / count\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_gnns():\n",
    "    global num_of_ctg,tokens\n",
    "    n = num_of_ctg \n",
    "    gnn_models = []\n",
    "    for i in range(n):\n",
    "        m = GCN(30,len(tokens)).to(device)\n",
    "        gnn_models.append(m)\n",
    "    return gnn_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_categories(pids):\n",
    "    global num_of_ctg\n",
    "    n = num_of_ctg - 1\n",
    "    ctg = set(pids)\n",
    "    ctg = list(ctg)\n",
    "    k, m = divmod(len(ctg), n)\n",
    "    return [set(ctg[i * k + min(i, m):(i + 1) * k + min(i + 1, m)]) for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def map_pids_to_category_indices(pids, categories):\n",
    "    pid_to_category_index = {}\n",
    "    \n",
    "    for pid in pids:\n",
    "        for category_index, category_set in enumerate(categories):\n",
    "            if pid in category_set:\n",
    "                pid_to_category_index[pid] = category_index \n",
    "                break \n",
    "    \n",
    "    return pid_to_category_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from sklearn.utils import class_weight\n",
    "import copy\n",
    "\n",
    "templates = init_gnns()\n",
    "\n",
    "def train_gnn_func(nodes,labels,edges,mapp,pids,idx_to_pid):\n",
    "    \n",
    "    global categories ,epochs\n",
    "    \n",
    "    pid_to_gnn_index = map_pids_to_category_indices(pids, categories)\n",
    "    \n",
    "    set_pids = set(pids)\n",
    "\n",
    "    proc_index = [i for i in range(len(mapp)) if mapp[i] in set_pids]\n",
    "\n",
    "    train_splits = [[] for _ in range(len(categories))]\n",
    "\n",
    "    for i in proc_index:\n",
    "        pname = idx_to_pid[str(i)]\n",
    "        split_indx = pid_to_gnn_index[pname]\n",
    "        train_splits[split_indx].append(int(i))\n",
    "        \n",
    "    local_models = [copy.deepcopy(x) for x in templates]\n",
    "    \n",
    "    for i in range(len(local_models)-1):\n",
    "            \n",
    "        if len(train_splits[i]) == 0:\n",
    "            local_models[i] = None\n",
    "        else:\n",
    "            if f\"target_e3_global{i}.pth\" in os.listdir(\"Content_FL_Exp\"):\n",
    "                local_models[i].load_state_dict(torch.load(f\"Content_FL_Exp/target_e3_global{i}.pth\"))\n",
    "\n",
    "            optimizer = torch.optim.Adam(local_models[i].parameters(), lr=0.01, weight_decay=5e-4)\n",
    "            criterion = CrossEntropyLoss()\n",
    "\n",
    "            graph = Data(x=torch.tensor(nodes,dtype=torch.float).to(device),y=torch.tensor(labels,dtype=torch.long).to(device), edge_index=torch.tensor(edges,dtype=torch.long).to(device))\n",
    "            mask = torch.tensor([False]*graph.num_nodes, dtype=torch.bool)\n",
    "            mask[train_splits[i]] = True\n",
    "            \n",
    "            def get_neighbors(edge_index, nodes):\n",
    "                neighbors = []\n",
    "                for node in nodes:\n",
    "                    mask = edge_index[0] == node\n",
    "                    neighbors.extend(edge_index[1, mask].tolist())\n",
    "                return torch.tensor(list(set(neighbors)), dtype=torch.long)\n",
    "\n",
    "            one_hop_neighbors = get_neighbors(graph.edge_index, train_splits[i])\n",
    "            two_hop_neighbors = get_neighbors(graph.edge_index, one_hop_neighbors)\n",
    "            two_hop_neighbors = two_hop_neighbors[~mask[two_hop_neighbors]]\n",
    "            mask[two_hop_neighbors] = True\n",
    "            \n",
    "            for epoch in range(epochs):\n",
    "                print(f'Training GNN Category {i} Model for Epoch {epoch}')\n",
    "\n",
    "                loader = NeighborLoader(graph, num_neighbors=[-1,-1], batch_size=5000,input_nodes=mask)\n",
    "                total_loss = 0\n",
    "                for subg in loader:\n",
    "                    local_models[i].train()\n",
    "                    optimizer.zero_grad() \n",
    "                    out = local_models[i](subg.x, subg.edge_index) \n",
    "                    loss = criterion(out, subg.y) \n",
    "                    loss.backward() \n",
    "                    optimizer.step()      \n",
    "                    total_loss += loss.item() * subg.batch_size\n",
    "                print(\"Loss: \", total_loss / mask.sum().item(), '\\n')\n",
    "    \n",
    "    graph = Data(x=torch.tensor(nodes,dtype=torch.float).to(device),y=torch.tensor(labels,dtype=torch.long).to(device), edge_index=torch.tensor(edges,dtype=torch.long).to(device))\n",
    "    optimizer = torch.optim.Adam(local_models[-1].parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    criterion = CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f'Training Catch all GNN Category Model for Epoch {epoch}')    \n",
    "        local_models[-1].train()\n",
    "        optimizer.zero_grad() \n",
    "        out = local_models[-1](graph.x, graph.edge_index) \n",
    "        loss = criterion(out, graph.y) \n",
    "        loss.backward() \n",
    "        optimizer.step()      \n",
    "        print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "    return local_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "procs_total = []\n",
    "data_cache = {}\n",
    "categories = None\n",
    "\n",
    "def load_clients_data():\n",
    "    \n",
    "    global data_cache,categories,procs_total,tokens\n",
    "    \n",
    "    for name in ['cadets','theia','trace']:\n",
    "        if name == 'cadets':\n",
    "            train_file = 'content/darpatc/cadets_train.txt'\n",
    "            attribute_file = \"content/ta1-cadets-e3-official.json.1\"\n",
    "\n",
    "        if name == 'theia':\n",
    "            train_file = \"content/darpatc/theia_train.txt\"\n",
    "            attribute_file = \"content/ta1-theia-e3-official-1r.json\"\n",
    "\n",
    "        if name == 'trace':\n",
    "            train_file = \"content/darpatc/trace_train.txt\"\n",
    "            attribute_file = \"content/ta1-trace-e3-official-1.json\"  \n",
    "\n",
    "        f = open(train_file)\n",
    "\n",
    "        data = f.read().split('\\n')\n",
    "        data = [line.split('\\t') for line in data]\n",
    "\n",
    "        df = pd.DataFrame (data, columns = ['actorID', 'actor_type','objectID','object','action','timestamp'])\n",
    "        df = df.dropna()\n",
    "        df.sort_values(by='timestamp', ascending=True,inplace=True)\n",
    "        df = add_attributes(df,attribute_file)\n",
    "        df = df[df['actor_type'] == 'SUBJECT_PROCESS'] \n",
    "        df = df[df['object'].isin(tokens)]    \n",
    "\n",
    "        docs,labels,edges,mapp,pids,idx_to_pid = prepare_graph(df)\n",
    "        data_cache[name] = [docs,labels,edges,mapp,pids,idx_to_pid]\n",
    "        procs_total = procs_total + pids\n",
    "\n",
    "    categories = define_categories(procs_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def client_handling_loop(client_id):    \n",
    "    print(f\"Running Setup on Client {client_id} \\n\")\n",
    "    \n",
    "    docs,labels,edges,mapp,pids,idx_to_pid = data_cache[client_id]\n",
    "    \n",
    "    nodes_feat = []\n",
    "    for x in docs:\n",
    "        nodes_feat.append(infer(x)) \n",
    "        \n",
    "    trained_local_models = train_gnn_func(nodes_feat,labels,edges,mapp,pids,idx_to_pid)\n",
    "    return trained_local_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def server_aggregate(all_models):\n",
    "    global_models = copy.deepcopy(templates)\n",
    "    \n",
    "    for l in range(len(all_models)):\n",
    "        \n",
    "        current_models = all_models[l]\n",
    "        current_models = [x for x in current_models if x != None]\n",
    "        \n",
    "        if not len(current_models) == 0:\n",
    "        \n",
    "            global_dict = global_models[l].state_dict()\n",
    "\n",
    "            for k in global_dict.keys():\n",
    "                param_list = [current_models[i].state_dict()[k] for i in range(len(current_models))]\n",
    "                global_dict[k] = torch.stack(param_list, 0).mean(0)\n",
    "\n",
    "            global_models[l].load_state_dict(global_dict)\n",
    "            torch.save(global_models[l].state_dict(), f\"Content_FL_Exp/target_e3_global{l}.pth\")\n",
    "                   \n",
    "    return global_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def perform_federated_learning(n_clients):\n",
    "    client_models = []\n",
    "    for c in n_clients:\n",
    "        local_gnns = client_handling_loop(c)\n",
    "        client_models.append(local_gnns)\n",
    "    return client_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!rm Content_FL_Exp/target_e3_*.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('Content_FL_Exp/e3_ensemble_ben.json', 'r') as f:\n",
    "    data_cache = json.load(f)\n",
    "\n",
    "proc_total = []\n",
    "for x in ['cadets','theia','trace']:\n",
    "    proc_total = proc_total + data_cache[x][-2]\n",
    "    \n",
    "categories = define_categories(proc_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_clients_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Federated Learning Round Number: 0\n",
      "\n",
      "Running Setup on Client cadets \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 0\n",
      "Loss:  0.9031902814850337 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 1\n",
      "Loss:  0.848799349019059 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 2\n",
      "Loss:  0.8410778808701492 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 3\n",
      "Loss:  0.8378615077911256 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 4\n",
      "Loss:  0.8355518227909261 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 5\n",
      "Loss:  0.834439787604051 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 6\n",
      "Loss:  0.8340568921759433 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 7\n",
      "Loss:  0.8337925688435961 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 8\n",
      "Loss:  0.8335847639257686 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 9\n",
      "Loss:  0.8333903634730323 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  1.1877612544934397 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.8852920220380369 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8742166309350792 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8685513657777488 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8648308571946421 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8643682715549245 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8638708490092738 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8633033065937445 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.862825544107528 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8624599997320511 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 0\n",
      "Loss:  0.897752627720212 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 1\n",
      "Loss:  0.8407138496657659 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 2\n",
      "Loss:  0.8375518391062471 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 3\n",
      "Loss:  0.8358930248993144 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 4\n",
      "Loss:  0.83530348344327 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 5\n",
      "Loss:  0.8345062063515551 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 6\n",
      "Loss:  0.8341088213722317 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 7\n",
      "Loss:  0.833880785093392 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 8\n",
      "Loss:  0.8334449384597669 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 9\n",
      "Loss:  0.8331456588658656 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 0\n",
      "Loss:  0.9273463932407082 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 1\n",
      "Loss:  0.8861691644716984 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 2\n",
      "Loss:  0.8759628302592696 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 3\n",
      "Loss:  0.8718393999222288 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 4\n",
      "Loss:  0.8704892233432497 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 5\n",
      "Loss:  0.8702068614007072 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 6\n",
      "Loss:  0.8702013992078876 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 7\n",
      "Loss:  0.8701361292253045 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 8\n",
      "Loss:  0.869916559746147 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 9\n",
      "Loss:  0.8695075276989659 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 0\n",
      "Loss:  1.1636550525256009 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 1\n",
      "Loss:  0.8944275526658326 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 2\n",
      "Loss:  0.8783529220228979 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 3\n",
      "Loss:  0.8750149556810822 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 4\n",
      "Loss:  0.8721815546580945 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 5\n",
      "Loss:  0.8690140900960213 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 6\n",
      "Loss:  0.8652913031634172 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 7\n",
      "Loss:  0.862911122981815 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 8\n",
      "Loss:  0.8618994293346925 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 9\n",
      "Loss:  0.8612775350439137 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 0\n",
      "Loss:  1.0616029358348964 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 1\n",
      "Loss:  0.8818833524248997 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 2\n",
      "Loss:  0.8471490109237856 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 3\n",
      "Loss:  0.8407037415602542 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 4\n",
      "Loss:  0.838362716673428 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 5\n",
      "Loss:  0.8369004510232835 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 6\n",
      "Loss:  0.8355214106223506 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 7\n",
      "Loss:  0.8349470267309604 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 8\n",
      "Loss:  0.8342972646461674 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 9\n",
      "Loss:  0.8337941631992042 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 0\n",
      "Loss:  0.8956410679850063 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 1\n",
      "Loss:  0.8951338102162608 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 2\n",
      "Loss:  0.8666095694519083 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 3\n",
      "Loss:  0.8634921691047586 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 4\n",
      "Loss:  0.8613610583757001 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 5\n",
      "Loss:  0.8606443567318255 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 6\n",
      "Loss:  0.8609034921405431 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 7\n",
      "Loss:  0.8603955298554596 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 8\n",
      "Loss:  0.8592598533724267 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 9\n",
      "Loss:  0.8577699431208732 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 0\n",
      "Loss:  1.1010915644925856 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 1\n",
      "Loss:  0.8893638806881186 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 2\n",
      "Loss:  0.8766742575090157 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 3\n",
      "Loss:  0.871361688678094 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 4\n",
      "Loss:  0.8685456788170773 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 5\n",
      "Loss:  0.8657735247277097 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 6\n",
      "Loss:  0.8643080181758603 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 7\n",
      "Loss:  0.8628571083828885 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 8\n",
      "Loss:  0.8614243955490775 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 9\n",
      "Loss:  0.8604340534313608 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 0\n",
      "Loss:  1.0793841667176307 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 1\n",
      "Loss:  0.9287004853658473 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 2\n",
      "Loss:  0.9096158417033835 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 3\n",
      "Loss:  0.9036695855170999 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 4\n",
      "Loss:  0.9015267775392537 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 5\n",
      "Loss:  0.8998142270615064 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 6\n",
      "Loss:  0.8971907155121173 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 7\n",
      "Loss:  0.8931742205279685 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 8\n",
      "Loss:  0.8889145260474577 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 9\n",
      "Loss:  0.8850900703349883 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.1752554178237915\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.065651297569275\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 1.0162179470062256\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.9923893213272095\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.9799237847328186\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.972741425037384\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.9677250981330872\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.9631378650665283\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.9578102231025696\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.9508700966835022\n",
      "Running Setup on Client theia \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 0\n",
      "Loss:  0.9883651733398438 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 1\n",
      "Loss:  0.9015635251998901 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 2\n",
      "Loss:  0.8840464949607849 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 3\n",
      "Loss:  0.8766610026359558 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 4\n",
      "Loss:  0.8688591718673706 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 5\n",
      "Loss:  0.8608039617538452 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 6\n",
      "Loss:  0.8535212874412537 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 7\n",
      "Loss:  0.8475062251091003 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 8\n",
      "Loss:  0.8429430723190308 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 9\n",
      "Loss:  0.8398237824440002 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  1.1627658605575562 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.9796054363250732 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.9274834394454956 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.9100562930107117 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.9027532935142517 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8987019062042236 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8956437110900879 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8927465081214905 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8896955251693726 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8863834142684937 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 0\n",
      "Loss:  1.0719996690750122 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 1\n",
      "Loss:  0.9509071111679077 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 2\n",
      "Loss:  0.9208043813705444 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 3\n",
      "Loss:  0.908668041229248 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 4\n",
      "Loss:  0.898551344871521 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 5\n",
      "Loss:  0.8896443843841553 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 6\n",
      "Loss:  0.8821555376052856 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 7\n",
      "Loss:  0.8762444257736206 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 8\n",
      "Loss:  0.8717984557151794 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 9\n",
      "Loss:  0.8685089349746704 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 0\n",
      "Loss:  1.0850579869732357 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 1\n",
      "Loss:  0.89226092944569 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 2\n",
      "Loss:  0.8754575347062944 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 3\n",
      "Loss:  0.8712608582461284 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 4\n",
      "Loss:  0.868131815033727 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 5\n",
      "Loss:  0.8643424735966782 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 6\n",
      "Loss:  0.8594996733447222 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 7\n",
      "Loss:  0.8538406999246098 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 8\n",
      "Loss:  0.8482400407198157 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 9\n",
      "Loss:  0.8440907629157542 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 0\n",
      "Loss:  1.2860674858093262 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 1\n",
      "Loss:  1.1833616495132446 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 2\n",
      "Loss:  1.0455938577651978 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 3\n",
      "Loss:  0.9485101103782654 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 4\n",
      "Loss:  0.895041286945343 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 5\n",
      "Loss:  0.8707591891288757 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 6\n",
      "Loss:  0.860683262348175 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 7\n",
      "Loss:  0.8566762804985046 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 8\n",
      "Loss:  0.855242133140564 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 9\n",
      "Loss:  0.8548679351806641 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 0\n",
      "Loss:  1.201334834098816 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 1\n",
      "Loss:  1.004515290260315 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 2\n",
      "Loss:  0.9231135249137878 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 3\n",
      "Loss:  0.8929800987243652 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 4\n",
      "Loss:  0.8791380524635315 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 5\n",
      "Loss:  0.8720204830169678 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 6\n",
      "Loss:  0.8675958514213562 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 7\n",
      "Loss:  0.864216685295105 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 8\n",
      "Loss:  0.8612725734710693 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 9\n",
      "Loss:  0.858605682849884 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 0\n",
      "Loss:  1.0063869953155518 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 1\n",
      "Loss:  0.8990999460220337 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 2\n",
      "Loss:  0.8875948786735535 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 3\n",
      "Loss:  0.8728815913200378 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 4\n",
      "Loss:  0.8612469434738159 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 5\n",
      "Loss:  0.8532112836837769 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 6\n",
      "Loss:  0.8471055626869202 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 7\n",
      "Loss:  0.8440797924995422 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 8\n",
      "Loss:  0.8449665904045105 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 9\n",
      "Loss:  0.8462152481079102 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 0\n",
      "Loss:  1.1116498708724976 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 1\n",
      "Loss:  1.0075745582580566 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 2\n",
      "Loss:  0.9575973153114319 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 3\n",
      "Loss:  0.928388774394989 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 4\n",
      "Loss:  0.9075992703437805 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 5\n",
      "Loss:  0.8907236456871033 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 6\n",
      "Loss:  0.8762606382369995 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 7\n",
      "Loss:  0.8645918369293213 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 8\n",
      "Loss:  0.8571246266365051 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 9\n",
      "Loss:  0.8542221784591675 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 0\n",
      "Loss:  1.1444101333618164 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 1\n",
      "Loss:  1.0063080787658691 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 2\n",
      "Loss:  0.9335191249847412 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 3\n",
      "Loss:  0.8992480635643005 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 4\n",
      "Loss:  0.881924569606781 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 5\n",
      "Loss:  0.872992217540741 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 6\n",
      "Loss:  0.8686186075210571 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 7\n",
      "Loss:  0.8667024374008179 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 8\n",
      "Loss:  0.8659580945968628 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 9\n",
      "Loss:  0.8655814528465271 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.0545544624328613\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.0102304220199585\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9887228012084961\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.9712713956832886\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.954851508140564\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.9372746348381042\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.9185576438903809\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.900381863117218\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.8846564888954163\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.8721877932548523\n",
      "Running Setup on Client trace \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 0\n",
      "Loss:  0.9880222082138062 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 1\n",
      "Loss:  0.9738185405731201 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 2\n",
      "Loss:  0.9597631692886353 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 3\n",
      "Loss:  0.9434917569160461 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 4\n",
      "Loss:  0.9224579334259033 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 5\n",
      "Loss:  0.898574948310852 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 6\n",
      "Loss:  0.8848252892494202 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 7\n",
      "Loss:  0.8801037073135376 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 8\n",
      "Loss:  0.8778910040855408 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 9\n",
      "Loss:  0.8783065676689148 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  1.0119824649257854 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.9922731590486855 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.9644467674689121 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.9379663683795472 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.9156283441962092 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8981492113372942 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8905636102103984 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.891443424055129 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8841020402044042 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8755935099436846 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 0\n",
      "Loss:  1.1716271630550548 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 1\n",
      "Loss:  1.0071156307802362 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 2\n",
      "Loss:  0.9945902558171738 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 3\n",
      "Loss:  0.9873450711622076 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 4\n",
      "Loss:  0.9809838839447272 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 5\n",
      "Loss:  0.9737711403804905 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 6\n",
      "Loss:  0.9644675885929781 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 7\n",
      "Loss:  0.953749223577893 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 8\n",
      "Loss:  0.9443095045336936 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 9\n",
      "Loss:  0.9344400469945411 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 0\n",
      "Loss:  1.01699697971344 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 1\n",
      "Loss:  0.9483946561813354 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 2\n",
      "Loss:  0.9207390546798706 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 3\n",
      "Loss:  0.9017258882522583 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 4\n",
      "Loss:  0.8862951993942261 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 5\n",
      "Loss:  0.8740465044975281 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 6\n",
      "Loss:  0.8691869974136353 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 7\n",
      "Loss:  0.8694333434104919 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 8\n",
      "Loss:  0.8699732422828674 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 9\n",
      "Loss:  0.8689737915992737 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 0\n",
      "Loss:  1.2150551080703735 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 1\n",
      "Loss:  1.1122163534164429 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 2\n",
      "Loss:  1.0534080266952515 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 3\n",
      "Loss:  1.0011869668960571 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 4\n",
      "Loss:  0.9622640013694763 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 5\n",
      "Loss:  0.9405741095542908 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 6\n",
      "Loss:  0.9298809170722961 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 7\n",
      "Loss:  0.9248592257499695 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 8\n",
      "Loss:  0.9227011799812317 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 9\n",
      "Loss:  0.921937882900238 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 0\n",
      "Loss:  1.1718065738677979 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 1\n",
      "Loss:  1.0399019718170166 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 2\n",
      "Loss:  0.972118616104126 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 3\n",
      "Loss:  0.9511128067970276 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 4\n",
      "Loss:  0.9446125626564026 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 5\n",
      "Loss:  0.9419096112251282 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 6\n",
      "Loss:  0.9404813051223755 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 7\n",
      "Loss:  0.9394650459289551 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 8\n",
      "Loss:  0.938482403755188 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 9\n",
      "Loss:  0.9373416304588318 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 0\n",
      "Loss:  1.1309465309821418 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 1\n",
      "Loss:  0.984925588222412 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 2\n",
      "Loss:  0.9707920455988959 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 3\n",
      "Loss:  0.9575322038219313 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 4\n",
      "Loss:  0.9420940408372372 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 5\n",
      "Loss:  0.9227031139277623 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 6\n",
      "Loss:  0.9046910151152594 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 7\n",
      "Loss:  0.8990930607582744 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 8\n",
      "Loss:  0.9143835025164216 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 9\n",
      "Loss:  0.922782310072293 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 0\n",
      "Loss:  1.1413711309432983 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 1\n",
      "Loss:  0.9675152897834778 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 2\n",
      "Loss:  0.9271741509437561 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 3\n",
      "Loss:  0.9132609367370605 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 4\n",
      "Loss:  0.9086658954620361 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 5\n",
      "Loss:  0.9069969058036804 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 6\n",
      "Loss:  0.9058333039283752 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 7\n",
      "Loss:  0.9047076106071472 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 8\n",
      "Loss:  0.9037761092185974 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 9\n",
      "Loss:  0.9031921625137329 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 0\n",
      "Loss:  1.1169065104696572 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 1\n",
      "Loss:  0.9969285632057893 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 2\n",
      "Loss:  0.9639103406901547 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 3\n",
      "Loss:  0.9315593179016073 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 4\n",
      "Loss:  0.9054754261719821 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 5\n",
      "Loss:  0.8893958742312504 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 6\n",
      "Loss:  0.8814767315796862 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 7\n",
      "Loss:  0.8798422855569866 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 8\n",
      "Loss:  0.880222342747321 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 9\n",
      "Loss:  0.8781686070635378 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.0696868896484375\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.0038845539093018\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9983996152877808\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.9930362105369568\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.9886646270751953\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.984940230846405\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.9815253615379333\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.9781486392021179\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.9745761156082153\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.9706323146820068\n",
      "Federated Learning Round Number: 1\n",
      "\n",
      "Running Setup on Client cadets \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 0\n",
      "Loss:  0.8368289697829538 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 1\n",
      "Loss:  0.8378029118719116 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 2\n",
      "Loss:  0.8343277287939838 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 3\n",
      "Loss:  0.8330273008074637 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 4\n",
      "Loss:  0.8321056833107138 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 5\n",
      "Loss:  0.8318001212728955 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 6\n",
      "Loss:  0.8312584899409191 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 7\n",
      "Loss:  0.8307448521028777 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 8\n",
      "Loss:  0.8318826980890447 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 9\n",
      "Loss:  0.8332642280904098 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.8728445598794563 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.8700475253362897 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8622336831812366 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8593884470216566 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8580026080671769 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.855186927849375 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8539431692275576 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8518362367086817 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.850762521291708 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8493360674668774 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 0\n",
      "Loss:  0.8431144431893648 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 1\n",
      "Loss:  0.8423994270489178 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 2\n",
      "Loss:  0.8396240906725144 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 3\n",
      "Loss:  0.8353737769438933 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 4\n",
      "Loss:  0.8339085690245469 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 5\n",
      "Loss:  0.83338862247181 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 6\n",
      "Loss:  0.8330811158117178 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 7\n",
      "Loss:  0.8329080874284434 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 8\n",
      "Loss:  0.8326137378334431 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 9\n",
      "Loss:  0.8335270026385093 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 0\n",
      "Loss:  0.8687074492739807 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 1\n",
      "Loss:  0.8667347846999282 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 2\n",
      "Loss:  0.8611445490665106 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 3\n",
      "Loss:  0.8581328728672752 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 4\n",
      "Loss:  0.8548524209155377 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 5\n",
      "Loss:  0.8531926110805239 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 6\n",
      "Loss:  0.849369250093114 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 7\n",
      "Loss:  0.8457235375954317 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 8\n",
      "Loss:  0.8467015522345096 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 9\n",
      "Loss:  0.8448821880390011 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 0\n",
      "Loss:  0.8654561042298599 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 1\n",
      "Loss:  0.8642373589990887 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 2\n",
      "Loss:  0.8567893006653933 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 3\n",
      "Loss:  0.8557499099896028 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 4\n",
      "Loss:  0.8553636471008355 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 5\n",
      "Loss:  0.8509988319174412 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 6\n",
      "Loss:  0.848343249463357 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 7\n",
      "Loss:  0.8468414616752321 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 8\n",
      "Loss:  0.8451351506255347 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 9\n",
      "Loss:  0.8441642610577513 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 0\n",
      "Loss:  0.8523897565000541 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 1\n",
      "Loss:  0.848705579381865 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 2\n",
      "Loss:  0.8483666849024499 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 3\n",
      "Loss:  0.8411433008852008 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 4\n",
      "Loss:  0.8362543252735352 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 5\n",
      "Loss:  0.8350035497446173 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 6\n",
      "Loss:  0.8342428609207192 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 7\n",
      "Loss:  0.8344252594366525 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 8\n",
      "Loss:  0.8343814842669123 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 9\n",
      "Loss:  0.8356077786560568 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 0\n",
      "Loss:  0.8669452635546298 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 1\n",
      "Loss:  0.8592941176511829 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 2\n",
      "Loss:  0.855861624949167 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 3\n",
      "Loss:  0.8541773255433964 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 4\n",
      "Loss:  0.8536860070386636 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 5\n",
      "Loss:  0.8526316993855475 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 6\n",
      "Loss:  0.8508253220773189 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 7\n",
      "Loss:  0.8500722628129597 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 8\n",
      "Loss:  0.8491494553301191 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 9\n",
      "Loss:  0.8474190239832758 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 0\n",
      "Loss:  0.8753192298542735 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 1\n",
      "Loss:  0.8748292093370091 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 2\n",
      "Loss:  0.8650306926304526 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 3\n",
      "Loss:  0.861568386750978 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 4\n",
      "Loss:  0.8597108954518522 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 5\n",
      "Loss:  0.8576511603649772 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 6\n",
      "Loss:  0.8547728832761683 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 7\n",
      "Loss:  0.8531216138298425 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 8\n",
      "Loss:  0.8517312630761826 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 9\n",
      "Loss:  0.8512882579619193 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 0\n",
      "Loss:  0.8958713389474526 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 1\n",
      "Loss:  0.8817587961131206 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 2\n",
      "Loss:  0.8802940018932054 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 3\n",
      "Loss:  0.8805891659823211 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 4\n",
      "Loss:  0.8739343492310854 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 5\n",
      "Loss:  0.8740875918667261 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 6\n",
      "Loss:  0.8709534349509452 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 7\n",
      "Loss:  0.8702168019415786 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 8\n",
      "Loss:  0.866923280238497 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 9\n",
      "Loss:  0.8641934780014098 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.1752554178237915\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.065651297569275\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 1.0162180662155151\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.9923893213272095\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.9799237847328186\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.9727413654327393\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.9677250981330872\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.9631378650665283\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.9578102231025696\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.9508700966835022\n",
      "Running Setup on Client theia \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 0\n",
      "Loss:  0.8566352128982544 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 1\n",
      "Loss:  0.8452115058898926 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 2\n",
      "Loss:  0.8384131789207458 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 3\n",
      "Loss:  0.8370928168296814 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 4\n",
      "Loss:  0.8361101150512695 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 5\n",
      "Loss:  0.8346063494682312 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 6\n",
      "Loss:  0.8332958817481995 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 7\n",
      "Loss:  0.8324041962623596 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 8\n",
      "Loss:  0.8318222761154175 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 9\n",
      "Loss:  0.8313794136047363 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.8839842081069946 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.8481247425079346 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8585231900215149 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8430197834968567 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8385288715362549 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8376068472862244 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8381640315055847 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8374601006507874 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8352172374725342 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8331803679466248 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 0\n",
      "Loss:  0.8858543634414673 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 1\n",
      "Loss:  0.8556527495384216 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 2\n",
      "Loss:  0.8482752442359924 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 3\n",
      "Loss:  0.8447031378746033 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 4\n",
      "Loss:  0.8428121209144592 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 5\n",
      "Loss:  0.8405317664146423 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 6\n",
      "Loss:  0.8380285501480103 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 7\n",
      "Loss:  0.8363353610038757 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 8\n",
      "Loss:  0.8355265259742737 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 9\n",
      "Loss:  0.8351125121116638 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 0\n",
      "Loss:  0.8500614135172724 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 1\n",
      "Loss:  0.8449476501589361 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 2\n",
      "Loss:  0.836713466689543 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 3\n",
      "Loss:  0.8349564346794289 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 4\n",
      "Loss:  0.834229447845028 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 5\n",
      "Loss:  0.8322331580854337 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 6\n",
      "Loss:  0.831865482493582 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 7\n",
      "Loss:  0.8317564949089274 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 8\n",
      "Loss:  0.8311255938071657 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 9\n",
      "Loss:  0.8309679167880135 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 0\n",
      "Loss:  0.8635166883468628 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 1\n",
      "Loss:  0.8552893400192261 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 2\n",
      "Loss:  0.8506518602371216 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 3\n",
      "Loss:  0.844322144985199 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 4\n",
      "Loss:  0.839195728302002 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 5\n",
      "Loss:  0.8395258188247681 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 6\n",
      "Loss:  0.8366103172302246 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 7\n",
      "Loss:  0.8344508409500122 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 8\n",
      "Loss:  0.8335332870483398 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 9\n",
      "Loss:  0.833148717880249 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 0\n",
      "Loss:  0.8722389340400696 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 1\n",
      "Loss:  0.8518028259277344 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 2\n",
      "Loss:  0.8425977826118469 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 3\n",
      "Loss:  0.846843957901001 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 4\n",
      "Loss:  0.8407831788063049 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 5\n",
      "Loss:  0.8377419114112854 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 6\n",
      "Loss:  0.8349213600158691 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 7\n",
      "Loss:  0.8332735300064087 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 8\n",
      "Loss:  0.8333582282066345 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 9\n",
      "Loss:  0.8336916565895081 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 0\n",
      "Loss:  0.8606392741203308 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 1\n",
      "Loss:  0.8536486625671387 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 2\n",
      "Loss:  0.8490797877311707 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 3\n",
      "Loss:  0.8430636525154114 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 4\n",
      "Loss:  0.8399829268455505 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 5\n",
      "Loss:  0.8390783667564392 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 6\n",
      "Loss:  0.8385474681854248 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 7\n",
      "Loss:  0.8380529284477234 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 8\n",
      "Loss:  0.8379259705543518 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 9\n",
      "Loss:  0.8379384279251099 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 0\n",
      "Loss:  0.881713330745697 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 1\n",
      "Loss:  0.8496809005737305 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 2\n",
      "Loss:  0.8489065170288086 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 3\n",
      "Loss:  0.8446730375289917 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 4\n",
      "Loss:  0.8438924551010132 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 5\n",
      "Loss:  0.839592456817627 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 6\n",
      "Loss:  0.8368383646011353 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 7\n",
      "Loss:  0.8356537222862244 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 8\n",
      "Loss:  0.8347705006599426 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 9\n",
      "Loss:  0.8341853022575378 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 0\n",
      "Loss:  0.8688026070594788 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 1\n",
      "Loss:  0.854366660118103 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 2\n",
      "Loss:  0.8464605808258057 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 3\n",
      "Loss:  0.8413597345352173 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 4\n",
      "Loss:  0.8415281176567078 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 5\n",
      "Loss:  0.840530514717102 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 6\n",
      "Loss:  0.8394234776496887 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 7\n",
      "Loss:  0.8376871943473816 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 8\n",
      "Loss:  0.836307942867279 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 9\n",
      "Loss:  0.8355541229248047 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.0545544624328613\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.0102304220199585\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9887228012084961\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.9712713956832886\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.954851508140564\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.9372746348381042\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.9185576438903809\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.900381863117218\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.884656548500061\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.8721877932548523\n",
      "Running Setup on Client trace \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 0\n",
      "Loss:  0.9238678216934204 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 1\n",
      "Loss:  0.8973912000656128 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 2\n",
      "Loss:  0.8768362998962402 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 3\n",
      "Loss:  0.8920912742614746 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 4\n",
      "Loss:  0.8740525245666504 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 5\n",
      "Loss:  0.8617464303970337 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 6\n",
      "Loss:  0.8610444664955139 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 7\n",
      "Loss:  0.8615865707397461 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 8\n",
      "Loss:  0.8604418635368347 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 9\n",
      "Loss:  0.8581798672676086 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.9660351860169807 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.8818366067904299 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.889260847742469 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8756466646950388 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8773976589590919 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8707100033400306 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8639800851920263 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8605628247564097 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8604202316854048 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.857991590807583 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 0\n",
      "Loss:  0.9703284422398089 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 1\n",
      "Loss:  0.9193901137364351 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 2\n",
      "Loss:  0.9205400975846341 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 3\n",
      "Loss:  0.902935553821229 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 4\n",
      "Loss:  0.8961569684690397 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 5\n",
      "Loss:  0.8918267202044532 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 6\n",
      "Loss:  0.8888847335266805 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 7\n",
      "Loss:  0.8860744154702869 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 8\n",
      "Loss:  0.8851561712719508 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 9\n",
      "Loss:  0.8870020136162862 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 0\n",
      "Loss:  0.9829183220863342 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 1\n",
      "Loss:  0.9209995269775391 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 2\n",
      "Loss:  0.8949832916259766 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 3\n",
      "Loss:  0.8938924074172974 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 4\n",
      "Loss:  0.881898820400238 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 5\n",
      "Loss:  0.8693640828132629 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 6\n",
      "Loss:  0.8689310550689697 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 7\n",
      "Loss:  0.8706085085868835 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 8\n",
      "Loss:  0.8687599301338196 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 9\n",
      "Loss:  0.8646726608276367 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 0\n",
      "Loss:  0.9294032454490662 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 1\n",
      "Loss:  0.9260338544845581 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 2\n",
      "Loss:  0.9164441227912903 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 3\n",
      "Loss:  0.9020317792892456 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 4\n",
      "Loss:  0.8852767944335938 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 5\n",
      "Loss:  0.879692554473877 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 6\n",
      "Loss:  0.8845086693763733 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 7\n",
      "Loss:  0.8762949109077454 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 8\n",
      "Loss:  0.8708748817443848 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 9\n",
      "Loss:  0.8687988519668579 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 0\n",
      "Loss:  0.9452515244483948 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 1\n",
      "Loss:  0.9345642924308777 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 2\n",
      "Loss:  0.9235901832580566 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 3\n",
      "Loss:  0.9053128957748413 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 4\n",
      "Loss:  0.8895530700683594 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 5\n",
      "Loss:  0.8837082386016846 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 6\n",
      "Loss:  0.8840076327323914 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 7\n",
      "Loss:  0.8790909647941589 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 8\n",
      "Loss:  0.8714087605476379 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 9\n",
      "Loss:  0.862305760383606 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 0\n",
      "Loss:  0.9563864010579476 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 1\n",
      "Loss:  0.8893392576904643 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 2\n",
      "Loss:  0.8886868350615695 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 3\n",
      "Loss:  0.8846331588298892 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 4\n",
      "Loss:  0.8847187562644271 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 5\n",
      "Loss:  0.8786909744325422 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 6\n",
      "Loss:  0.8733081270644588 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 7\n",
      "Loss:  0.8701232285093914 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 8\n",
      "Loss:  0.8685304517819216 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 9\n",
      "Loss:  0.8690164362694063 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 0\n",
      "Loss:  0.90550696849823 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 1\n",
      "Loss:  0.9036811590194702 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 2\n",
      "Loss:  0.8998143076896667 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 3\n",
      "Loss:  0.8939726948738098 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 4\n",
      "Loss:  0.8904015421867371 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 5\n",
      "Loss:  0.8876479864120483 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 6\n",
      "Loss:  0.8829658627510071 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 7\n",
      "Loss:  0.8782521486282349 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 8\n",
      "Loss:  0.8748054504394531 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 9\n",
      "Loss:  0.8732373714447021 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 0\n",
      "Loss:  0.9282366871229324 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 1\n",
      "Loss:  0.8913746862243518 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 2\n",
      "Loss:  0.8814197919163221 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 3\n",
      "Loss:  0.8714865615980638 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 4\n",
      "Loss:  0.8701002290161699 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 5\n",
      "Loss:  0.870481373024903 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 6\n",
      "Loss:  0.868190086823258 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 7\n",
      "Loss:  0.8643791752877095 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 8\n",
      "Loss:  0.8616520680998178 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 9\n",
      "Loss:  0.8600982230028408 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.0696868896484375\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.0038845539093018\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9983996152877808\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.9930362105369568\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.9886646270751953\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.984940230846405\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.9815253615379333\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.9781486392021179\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.974575936794281\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.9706323146820068\n",
      "Federated Learning Round Number: 2\n",
      "\n",
      "Running Setup on Client cadets \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 0\n",
      "Loss:  0.8362504865037054 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 1\n",
      "Loss:  0.8399876530308453 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 2\n",
      "Loss:  0.8355163785239972 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 3\n",
      "Loss:  0.8326262095576337 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 4\n",
      "Loss:  0.8321591043102887 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 5\n",
      "Loss:  0.831804734290172 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 6\n",
      "Loss:  0.8311646977803875 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 7\n",
      "Loss:  0.8311824418791961 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 8\n",
      "Loss:  0.8311156322167513 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 9\n",
      "Loss:  0.8309440237105419 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.8588278898502767 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.8620201281802331 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8546473944563149 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8506990955726704 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8476873426505203 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8463344590930786 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8429438510498444 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8433137602399143 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8411665093994612 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8408377208898447 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 0\n",
      "Loss:  0.8353843521974326 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 1\n",
      "Loss:  0.8342317279374917 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 2\n",
      "Loss:  0.8367635637785841 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 3\n",
      "Loss:  0.836330928969887 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 4\n",
      "Loss:  0.8340678531130561 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 5\n",
      "Loss:  0.834868421421298 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 6\n",
      "Loss:  0.834050439008662 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 7\n",
      "Loss:  0.8333393182572493 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 8\n",
      "Loss:  0.8334793025486796 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 9\n",
      "Loss:  0.8327520840332145 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 0\n",
      "Loss:  0.8594512709016161 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 1\n",
      "Loss:  0.8547178199172792 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 2\n",
      "Loss:  0.8522025333882408 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 3\n",
      "Loss:  0.8492320665272987 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 4\n",
      "Loss:  0.8467642901139435 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 5\n",
      "Loss:  0.8446216654056606 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 6\n",
      "Loss:  0.842620596643658 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 7\n",
      "Loss:  0.8420026543073469 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 8\n",
      "Loss:  0.841844457722637 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 9\n",
      "Loss:  0.8393782745427241 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 0\n",
      "Loss:  0.8601049818835201 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 1\n",
      "Loss:  0.8575825762624034 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 2\n",
      "Loss:  0.8546016748618955 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 3\n",
      "Loss:  0.853281419891648 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 4\n",
      "Loss:  0.8519577022899423 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 5\n",
      "Loss:  0.8504271044959467 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 6\n",
      "Loss:  0.8492009390567443 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 7\n",
      "Loss:  0.8485506278935904 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 8\n",
      "Loss:  0.8467725242522636 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 9\n",
      "Loss:  0.8448293282327591 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 0\n",
      "Loss:  0.840960970707036 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 1\n",
      "Loss:  0.8490550302073914 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 2\n",
      "Loss:  0.8540531395790337 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 3\n",
      "Loss:  0.8449672802782626 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 4\n",
      "Loss:  0.8413486677100623 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 5\n",
      "Loss:  0.8404386267684419 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 6\n",
      "Loss:  0.8352107122588872 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 7\n",
      "Loss:  0.8351076493320031 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 8\n",
      "Loss:  0.8355855612882161 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 9\n",
      "Loss:  0.8336141004712089 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 0\n",
      "Loss:  0.8680846961279325 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 1\n",
      "Loss:  0.8558813321578687 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 2\n",
      "Loss:  0.8545642579662084 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 3\n",
      "Loss:  0.8516151406039635 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 4\n",
      "Loss:  0.8506433504857037 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 5\n",
      "Loss:  0.8501978381015763 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 6\n",
      "Loss:  0.847581761525739 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 7\n",
      "Loss:  0.8442309388849905 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 8\n",
      "Loss:  0.8407421412333371 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 9\n",
      "Loss:  0.8404884113614427 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 0\n",
      "Loss:  0.8644381467225238 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 1\n",
      "Loss:  0.8579225646007768 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 2\n",
      "Loss:  0.8542006309331589 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 3\n",
      "Loss:  0.8547774344049286 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 4\n",
      "Loss:  0.8527074514411263 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 5\n",
      "Loss:  0.8508964953703947 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 6\n",
      "Loss:  0.8506860934436636 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 7\n",
      "Loss:  0.8492750480460791 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 8\n",
      "Loss:  0.8478720235341008 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 9\n",
      "Loss:  0.8480386121114335 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 0\n",
      "Loss:  0.8882013884325191 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 1\n",
      "Loss:  0.8823583606668977 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 2\n",
      "Loss:  0.8746233406476973 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 3\n",
      "Loss:  0.8694488282688774 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 4\n",
      "Loss:  0.8708942835156337 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 5\n",
      "Loss:  0.8701256604203258 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 6\n",
      "Loss:  0.8675978189639005 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 7\n",
      "Loss:  0.8627477569510127 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 8\n",
      "Loss:  0.8609666146874188 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 9\n",
      "Loss:  0.8593617322291073 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.1752554178237915\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.065651297569275\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 1.0162180662155151\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.9923893213272095\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.9799237847328186\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.972741425037384\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.9677250981330872\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.9631378650665283\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.9578102231025696\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.9508700966835022\n",
      "Running Setup on Client theia \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 0\n",
      "Loss:  0.8388313055038452 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 1\n",
      "Loss:  0.8512898087501526 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 2\n",
      "Loss:  0.8350246548652649 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 3\n",
      "Loss:  0.8372046947479248 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 4\n",
      "Loss:  0.8359270095825195 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 5\n",
      "Loss:  0.8339308500289917 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 6\n",
      "Loss:  0.8337314128875732 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 7\n",
      "Loss:  0.8339099287986755 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 8\n",
      "Loss:  0.8335351347923279 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 9\n",
      "Loss:  0.8327483534812927 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.8499546051025391 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.8436793088912964 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8352657556533813 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8328823447227478 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8337502479553223 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8338704109191895 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8328945636749268 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8319099545478821 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8314123153686523 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8311630487442017 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 0\n",
      "Loss:  0.836023211479187 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 1\n",
      "Loss:  0.8476738333702087 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 2\n",
      "Loss:  0.8368552923202515 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 3\n",
      "Loss:  0.8368094563484192 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 4\n",
      "Loss:  0.8349654674530029 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 5\n",
      "Loss:  0.8328877687454224 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 6\n",
      "Loss:  0.8343109488487244 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 7\n",
      "Loss:  0.8336747288703918 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 8\n",
      "Loss:  0.8324123620986938 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 9\n",
      "Loss:  0.8320611119270325 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 0\n",
      "Loss:  0.8364547279914347 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 1\n",
      "Loss:  0.8373808796701436 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 2\n",
      "Loss:  0.8317793646306249 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 3\n",
      "Loss:  0.8330158353993841 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 4\n",
      "Loss:  0.8313045969071996 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 5\n",
      "Loss:  0.8309376963554851 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 6\n",
      "Loss:  0.831296569905172 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 7\n",
      "Loss:  0.8302134678510564 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 8\n",
      "Loss:  0.8298235778079422 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 9\n",
      "Loss:  0.8300238682252201 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 0\n",
      "Loss:  0.8480741381645203 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 1\n",
      "Loss:  0.8339521288871765 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 2\n",
      "Loss:  0.8456856608390808 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 3\n",
      "Loss:  0.8355307579040527 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 4\n",
      "Loss:  0.8333954215049744 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 5\n",
      "Loss:  0.8335563540458679 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 6\n",
      "Loss:  0.8343446850776672 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 7\n",
      "Loss:  0.8339947462081909 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 8\n",
      "Loss:  0.8327667117118835 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 9\n",
      "Loss:  0.8320050239562988 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 0\n",
      "Loss:  0.8530966639518738 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 1\n",
      "Loss:  0.8445830345153809 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 2\n",
      "Loss:  0.8339478373527527 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 3\n",
      "Loss:  0.8339816331863403 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 4\n",
      "Loss:  0.8345996141433716 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 5\n",
      "Loss:  0.834437906742096 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 6\n",
      "Loss:  0.8334447741508484 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 7\n",
      "Loss:  0.8326534628868103 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 8\n",
      "Loss:  0.8325854539871216 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 9\n",
      "Loss:  0.8327057957649231 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 0\n",
      "Loss:  0.8534896373748779 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 1\n",
      "Loss:  0.8368183970451355 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 2\n",
      "Loss:  0.8384495973587036 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 3\n",
      "Loss:  0.838664710521698 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 4\n",
      "Loss:  0.8371546268463135 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 5\n",
      "Loss:  0.8352478742599487 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 6\n",
      "Loss:  0.8336849808692932 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 7\n",
      "Loss:  0.8327077627182007 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 8\n",
      "Loss:  0.8321504592895508 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 9\n",
      "Loss:  0.8318238258361816 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 0\n",
      "Loss:  0.863161027431488 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 1\n",
      "Loss:  0.8395355343818665 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 2\n",
      "Loss:  0.8395763039588928 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 3\n",
      "Loss:  0.8419328331947327 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 4\n",
      "Loss:  0.8393587470054626 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 5\n",
      "Loss:  0.8359740376472473 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 6\n",
      "Loss:  0.8342025279998779 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 7\n",
      "Loss:  0.8339478373527527 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 8\n",
      "Loss:  0.8341506719589233 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 9\n",
      "Loss:  0.8341055512428284 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 0\n",
      "Loss:  0.8538865447044373 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 1\n",
      "Loss:  0.844318687915802 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 2\n",
      "Loss:  0.8403995037078857 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 3\n",
      "Loss:  0.8371904492378235 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 4\n",
      "Loss:  0.8380342721939087 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 5\n",
      "Loss:  0.8387568593025208 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 6\n",
      "Loss:  0.8381962180137634 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 7\n",
      "Loss:  0.8375489115715027 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 8\n",
      "Loss:  0.8368099927902222 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 9\n",
      "Loss:  0.8361174464225769 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.0545544624328613\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.0102304220199585\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9887228012084961\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.9712713956832886\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.954851508140564\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.9372746348381042\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.9185576438903809\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.900381863117218\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.884656548500061\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.8721877932548523\n",
      "Running Setup on Client trace \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 0\n",
      "Loss:  0.9161869287490845 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 1\n",
      "Loss:  0.8769649267196655 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 2\n",
      "Loss:  0.8776158690452576 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 3\n",
      "Loss:  0.8789573907852173 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 4\n",
      "Loss:  0.8695590496063232 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 5\n",
      "Loss:  0.8573339581489563 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 6\n",
      "Loss:  0.8565926551818848 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 7\n",
      "Loss:  0.8566225171089172 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 8\n",
      "Loss:  0.8558748364448547 \n",
      "\n",
      "Training GNN Category 0 Model for Epoch 9\n",
      "Loss:  0.8544453978538513 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.9213187564187547 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.880061348018311 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8759989477211261 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8713064209915025 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8701912246375996 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8672133108745476 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8646215029006611 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8609395404490954 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8577811511862707 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8549904624162549 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 0\n",
      "Loss:  0.9356192016411398 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 1\n",
      "Loss:  0.898434082746268 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 2\n",
      "Loss:  0.8903034814927775 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 3\n",
      "Loss:  0.8858011954446376 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 4\n",
      "Loss:  0.8856591204346593 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 5\n",
      "Loss:  0.8819089371447312 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 6\n",
      "Loss:  0.8781266577341265 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 7\n",
      "Loss:  0.8785325029673628 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 8\n",
      "Loss:  0.8808637620920199 \n",
      "\n",
      "Training GNN Category 2 Model for Epoch 9\n",
      "Loss:  0.873110324887193 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 0\n",
      "Loss:  0.9172520041465759 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 1\n",
      "Loss:  0.8779935836791992 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 2\n",
      "Loss:  0.8831522464752197 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 3\n",
      "Loss:  0.8769212961196899 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 4\n",
      "Loss:  0.8653550744056702 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 5\n",
      "Loss:  0.8624476194381714 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 6\n",
      "Loss:  0.861393392086029 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 7\n",
      "Loss:  0.8596886992454529 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 8\n",
      "Loss:  0.857635498046875 \n",
      "\n",
      "Training GNN Category 3 Model for Epoch 9\n",
      "Loss:  0.8558110594749451 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 0\n",
      "Loss:  0.9209843277931213 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 1\n",
      "Loss:  0.9008809328079224 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 2\n",
      "Loss:  0.8891268372535706 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 3\n",
      "Loss:  0.8698503375053406 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 4\n",
      "Loss:  0.8740412592887878 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 5\n",
      "Loss:  0.8725347518920898 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 6\n",
      "Loss:  0.8660596609115601 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 7\n",
      "Loss:  0.8615283966064453 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 8\n",
      "Loss:  0.8607010245323181 \n",
      "\n",
      "Training GNN Category 4 Model for Epoch 9\n",
      "Loss:  0.8593950867652893 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 0\n",
      "Loss:  0.930181622505188 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 1\n",
      "Loss:  0.8927155137062073 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 2\n",
      "Loss:  0.880426287651062 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 3\n",
      "Loss:  0.8718891143798828 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 4\n",
      "Loss:  0.8730252385139465 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 5\n",
      "Loss:  0.8713716864585876 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 6\n",
      "Loss:  0.8689815402030945 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 7\n",
      "Loss:  0.863950788974762 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 8\n",
      "Loss:  0.8586872220039368 \n",
      "\n",
      "Training GNN Category 5 Model for Epoch 9\n",
      "Loss:  0.8595434427261353 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 0\n",
      "Loss:  0.9391223045726985 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 1\n",
      "Loss:  0.8842556096991951 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 2\n",
      "Loss:  0.8771658169091711 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 3\n",
      "Loss:  0.869802542796704 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 4\n",
      "Loss:  0.8676367726275281 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 5\n",
      "Loss:  0.8661611737722297 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 6\n",
      "Loss:  0.8637425284209145 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 7\n",
      "Loss:  0.864051188925863 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 8\n",
      "Loss:  0.8631833641958218 \n",
      "\n",
      "Training GNN Category 6 Model for Epoch 9\n",
      "Loss:  0.8604798163894407 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 0\n",
      "Loss:  0.8895660638809204 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 1\n",
      "Loss:  0.8847415447235107 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 2\n",
      "Loss:  0.8792359232902527 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 3\n",
      "Loss:  0.8773934841156006 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 4\n",
      "Loss:  0.8744279146194458 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 5\n",
      "Loss:  0.871904194355011 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 6\n",
      "Loss:  0.8686236143112183 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 7\n",
      "Loss:  0.8663684725761414 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 8\n",
      "Loss:  0.8641388416290283 \n",
      "\n",
      "Training GNN Category 7 Model for Epoch 9\n",
      "Loss:  0.8623698949813843 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 0\n",
      "Loss:  0.8936507616610663 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 1\n",
      "Loss:  0.8697214340380997 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 2\n",
      "Loss:  0.8650174935499699 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 3\n",
      "Loss:  0.8620022661150822 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 4\n",
      "Loss:  0.8611178158091201 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 5\n",
      "Loss:  0.8559483081014881 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 6\n",
      "Loss:  0.849805054614981 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 7\n",
      "Loss:  0.8459418194752742 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 8\n",
      "Loss:  0.8446863969548849 \n",
      "\n",
      "Training GNN Category 8 Model for Epoch 9\n",
      "Loss:  0.84536697303323 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.0696868896484375\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.0038845539093018\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9983996152877808\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.9930362105369568\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.9886646270751953\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.9849401116371155\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.9815253615379333\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.9781486392021179\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.9745760560035706\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.9706323146820068\n"
     ]
    }
   ],
   "source": [
    "for r in range(learning_rounds):\n",
    "    print(f\"Federated Learning Round Number: {r}\\n\")\n",
    "    client_models = perform_federated_learning(hosts)\n",
    "    arranged_models =  [list(group) for group in zip(*client_models)]\n",
    "    global_models = server_aggregate(arranged_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the trained GNN model starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "PKJ53Fh5ogvy"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This function is used for constructing neighborhood around a given \n",
    "set of nodes for backwards or forward tracking\n",
    "'''\n",
    "from itertools import compress\n",
    "from torch_geometric import utils\n",
    "\n",
    "def construct_neighborhood(ids,mapp,edges,hops):\n",
    "    if hops == 0:\n",
    "        return set()\n",
    "    else:\n",
    "        neighbors = set()\n",
    "        for i in range(len(edges[0])):\n",
    "            if mapp[edges[0][i]] in ids:\n",
    "                neighbors.add(mapp[edges[1][i]])\n",
    "            if mapp[edges[1][i]] in ids:\n",
    "                neighbors.add(mapp[edges[0][i]])\n",
    "        return neighbors.union( construct_neighborhood(neighbors,mapp,edges,hops-1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "vgqyu7E5qPet"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This function logs the evaluation metrics.\n",
    "'''\n",
    "\n",
    "def helper(MP,all_pids,GP,edges,mapp):\n",
    "\n",
    "    TP = MP.intersection(GP)  \n",
    "    FP = MP - GP              \n",
    "    FN = GP - MP              \n",
    "    TN = all_pids - (GP | MP)\n",
    "    \n",
    "    two_hop_gp = construct_neighborhood(GP,mapp,edges,2)\n",
    "    two_hop_tp = construct_neighborhood(TP,mapp,edges,2)\n",
    "    FPL = FP - two_hop_gp\n",
    "    TPL = TP.union(FN.intersection(two_hop_tp))\n",
    "    FN = FN - two_hop_tp\n",
    "    \n",
    "    alerts = TP.union(FP)\n",
    "\n",
    "    TP,FP,FN,TN = len(TPL),len(FPL),len(FN),len(TN)\n",
    "    \n",
    "    FPR = FP / (FP+TN)\n",
    "    TPR = TP / (TP+FN)\n",
    "\n",
    "    print(f\"Number of True Positives: {TP}\")\n",
    "    print(f\"Number of Fasle Positives: {FP}\")\n",
    "    print(f\"Number of False Negatives: {FN}\")\n",
    "    print(f\"Number of True Negatives: {TN}\\n\")\n",
    "\n",
    "    prec = TP / (TP + FP)\n",
    "    print(f\"Precision: {prec}\")\n",
    "\n",
    "    rec = TP / (TP + FN)\n",
    "    print(f\"Recall: {rec}\")\n",
    "\n",
    "    fscore = (2*prec*rec) / (prec + rec)\n",
    "    print(f\"Fscore: {fscore}\\n\")\n",
    "    \n",
    "    #return alerts\n",
    "    return TPL,FPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cache_mal = {}\n",
    "def load_data_test():\n",
    "    \n",
    "    test_file = None\n",
    "    attribute_file = None\n",
    "    \n",
    "    for name in ['cadets','theia','trace']:\n",
    "\n",
    "        if name == 'cadets':\n",
    "            test_file = 'content/darpatc/cadets_test.txt'\n",
    "            attribute_file = \"content/ta1-cadets-e3-official-2.json\"\n",
    "\n",
    "        if name == 'theia':\n",
    "            test_file = \"content/darpatc/theia_test.txt\"\n",
    "            attribute_file = \"content/ta1-theia-e3-official-6r.json.8\"\n",
    "\n",
    "        if name == 'trace':\n",
    "            test_file = \"content/darpatc/trace_test.txt\"\n",
    "            attribute_file = \"content/ta1-trace-e3-official-1.json.4\"\n",
    "\n",
    "        f = open(test_file)\n",
    "\n",
    "        data = f.read().split('\\n')\n",
    "        data = [line.split('\\t') for line in data]\n",
    "\n",
    "        df = pd.DataFrame (data, columns = ['actorID', 'actor_type','objectID','object','action','timestamp'])\n",
    "        df = df.dropna()\n",
    "        df.sort_values(by='timestamp', ascending=True,inplace=True)\n",
    "\n",
    "        df = add_attributes(df,attribute_file)\n",
    "\n",
    "        df = df[df['actor_type'] == 'SUBJECT_PROCESS'] \n",
    "        df = df[df['object'].isin(tokens)]\n",
    "\n",
    "        docs,labels,edges,mapp,pids,idx_to_pid = prepare_graph(df)\n",
    "        data_cache_mal[name] = [docs,labels,edges,mapp,pids,idx_to_pid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('Content_FL_Exp/e3_ensemble_mal.json', 'r') as f:\n",
    "    data_cache_mal = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_data_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"Content_FL_Exp/e3_ensemble_mal2.json\", 'w') as file:\n",
    "#    json.dump(data_cache_mal, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation(data_name,thresh):    \n",
    "    global word2vec,tokens\n",
    "\n",
    "    client_data = data_cache_mal[data_name]\n",
    "            \n",
    "    phrases,labels,edges,mapp,pids,idx_to_pid = client_data\n",
    "\n",
    "    gt = open(f\"{data_name}.txt\").read()\n",
    "    GT_mal = gt.split(\"\\n\")\n",
    "    GT_mal = set(GT_mal)\n",
    "\n",
    "    model = GCN(30,len(tokens)).to(device)\n",
    "    word2vec = Word2Vec.load(\"Content_FL_Exp/global_word2vec_E3.model\")\n",
    "\n",
    "    nodes = [infer(x) for x in phrases]\n",
    "    nodes = np.array(nodes)  \n",
    "\n",
    "    all_ids = set(mapp)\n",
    "        \n",
    "    graph = Data(x=torch.tensor(nodes,dtype=torch.float).to(device),y=torch.tensor(labels,dtype=torch.long).to(device), edge_index=torch.tensor(edges,dtype=torch.long).to(device))\n",
    "\n",
    "    flag = torch.tensor([True]*graph.num_nodes, dtype=torch.bool)\n",
    "    \n",
    "    for m_n in range(num_of_ctg):\n",
    "        if f\"target_e3_global{m_n}.pth\" in os.listdir(\"Content_FL_Exp\"): \n",
    "            model.load_state_dict(torch.load(f\"Content_FL_Exp/target_e3_global{m_n}.pth\"))\n",
    "            \n",
    "        model.eval()\n",
    "        out = model(graph.x, graph.edge_index)\n",
    "\n",
    "        sorted, indices = out.sort(dim=1,descending=True)\n",
    "        conf = (sorted[:,0] - sorted[:,1]) / sorted[:,0]\n",
    "        conf = (conf - conf.min()) / conf.max()\n",
    "\n",
    "        pred = indices[:,0]\n",
    "        cond = (pred == graph.y) & (conf >= thresh)\n",
    "        flag[cond] = torch.logical_and(flag[cond], torch.tensor([False]*len(flag[cond]), dtype=torch.bool))\n",
    "\n",
    "    index = utils.mask_to_index(flag).tolist()\n",
    "    ids = set([mapp[x] for x in index])\n",
    "    metrics = helper(set(ids),set(all_ids),GT_mal,edges,mapp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of True Positives: 12846\n",
      "Number of Fasle Positives: 308\n",
      "Number of False Negatives: 12\n",
      "Number of True Negatives: 104785\n",
      "\n",
      "Precision: 0.9765850691804774\n",
      "Recall: 0.999066728884741\n",
      "Fscore: 0.987697985545133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = run_evaluation('cadets',0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of True Positives: 25311\n",
      "Number of Fasle Positives: 697\n",
      "Number of False Negatives: 48\n",
      "Number of True Negatives: 32299\n",
      "\n",
      "Precision: 0.9732005536757921\n",
      "Recall: 0.9981071808825269\n",
      "Fscore: 0.985496525006327\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = run_evaluation('theia',0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of True Positives: 67357\n",
      "Number of Fasle Positives: 3599\n",
      "Number of False Negatives: 816\n",
      "Number of True Negatives: 32099\n",
      "\n",
      "Precision: 0.9492784260668583\n",
      "Recall: 0.9880304519384507\n",
      "Fscore: 0.9682668602519963\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = run_evaluation('trace',0.8)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "PyTorch 1.12.0",
   "language": "python",
   "name": "pytorch-1.12.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
