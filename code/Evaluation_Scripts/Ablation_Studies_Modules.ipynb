{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "### Modular Components for Mirage System Ablation Studies\n",
    "\n",
    "This notebook provides **plug-and-play modules** for conducting various ablation studies on the Mirage system. To evaluate a particular variant, replace the corresponding vanilla component in base core script with the specialized component implementation supplied here.\n",
    "\n",
    "For comprehensive guidance on designing and interpreting ablation experiments, refer to the relevant sections of the paper.\n",
    "\n",
    "**Key points**\n",
    "\n",
    "* The module APIs replicate those of the baseline code, enabling a straightforward drop-in workflow.\n",
    "* Achieving optimal results typically requires:\n",
    "\n",
    "  * a solid understanding of the prior work on which each component is based, and\n",
    "  * careful hyperparameter tuning.\n",
    "    *(The underlying GNN implementation is inherently stochastic; seeds can vary across execution run.)*\n",
    "\n",
    "Use these modules to explore how existing methods interact with and potentially affect the Mirage system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Add_benign_system_noise(attack_df, benign_df, benign_structure_count):\n",
    "    unique_benign_procs = list(set(benign_df['actorID']))\n",
    "    selected_benign_procs = unique_benign_procs[:benign_structure_count]\n",
    "    selected_benign_df = benign_df[benign_df['actorID'].isin(selected_benign_procs)]\n",
    "\n",
    "    combined_df = pd.concat([attack_df, selected_benign_df], ignore_index=True)\n",
    "                      \n",
    "    event_template = {'actorID': None, 'objectID': None, 'action': '', 'timestamp': '', 'exec': '', 'path': ''}\n",
    "    \n",
    "    for malicious_proc in GT_mal:\n",
    "        for benign_proc in selected_benign_procs:\n",
    "            new_event = event_template.copy()\n",
    "            new_event['actorID'] = malicious_proc\n",
    "            new_event['objectID'] = benign_proc\n",
    "            combined_df = combined_df.append(new_event, ignore_index=True)\n",
    "    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "FedProx client-side training loop used for our ablation study.\n",
    "\n",
    "This function mirrors the API of `train_gnn_func`, allowing it to be\n",
    "plug-and-played in any notebook of the base system:\n",
    "\n",
    "1. Replace calls to `train_gnn_func` with `FedProx_model_training`.\n",
    "2. Restart the notebook and run all cells with `training=True` to retrain\n",
    "   the local GNN models under FedProx.\n",
    "3. Execute the evaluation cells once training finishes to obtain results.\n",
    "\n",
    "The workflow is identical across datasets; every notebook follows the same\n",
    "code structure.\n",
    "'''\n",
    "\n",
    "def FedProx_model_training(nodes, labels, edges, mapp, pids, idx_to_pid, mu=0.1):\n",
    "    \n",
    "    global categories, epochs\n",
    "    \n",
    "    pid_to_gnn_index = map_pids_to_category_indices(pids, categories)\n",
    "    \n",
    "    set_pids = set(pids)\n",
    "    proc_index = list(idx_to_pid.keys())\n",
    "\n",
    "    train_splits = [[] for _ in range(len(categories))]\n",
    "    \n",
    "    for i in proc_index:\n",
    "        pname = idx_to_pid[str(i)]\n",
    "        split_indx = pid_to_gnn_index[pname]\n",
    "        train_splits[split_indx].append(int(i))\n",
    "        \n",
    "    local_models = [copy.deepcopy(x) for x in templates]\n",
    "    \n",
    "    for i in range(len(local_models)):\n",
    "        \n",
    "        if len(train_splits[i]) == 0:\n",
    "            local_models[i] = None\n",
    "        else:\n",
    "            global_model = None\n",
    "            if f\"global{i}.pth\" in os.listdir(\"Content_FL_Exp\"):\n",
    "                global_model = copy.deepcopy(local_models[i])\n",
    "                global_model.load_state_dict(torch.load(f\"Content_FL_Exp/global{i}.pth\"))\n",
    "\n",
    "            optimizer = torch.optim.Adam(local_models[i].parameters(), lr=0.01, weight_decay=5e-4)\n",
    "            criterion = CrossEntropyLoss()\n",
    "\n",
    "            graph = Data(x=torch.tensor(nodes, dtype=torch.float).to(device),\n",
    "                         y=torch.tensor(labels, dtype=torch.long).to(device),\n",
    "                         edge_index=torch.tensor(edges, dtype=torch.long).to(device))\n",
    "            \n",
    "            mask = torch.tensor([False] * graph.num_nodes, dtype=torch.bool)\n",
    "            mask[train_splits[i]] = True\n",
    "            \n",
    "            def get_neighbors(edge_index, nodes):\n",
    "                neighbors = []\n",
    "                for node in nodes:\n",
    "                    mask = edge_index[0] == node\n",
    "                    neighbors.extend(edge_index[1, mask].tolist())\n",
    "                return torch.tensor(list(set(neighbors)), dtype=torch.long)\n",
    "\n",
    "            one_hop_neighbors = get_neighbors(graph.edge_index, train_splits[i])\n",
    "            two_hop_neighbors = get_neighbors(graph.edge_index, one_hop_neighbors)\n",
    "            two_hop_neighbors = two_hop_neighbors[~mask[two_hop_neighbors]]\n",
    "            mask[two_hop_neighbors] = True\n",
    "            \n",
    "            for epoch in range(epochs):\n",
    "                print(f'Training GNN Category {i} Model for Epoch {epoch}')\n",
    "\n",
    "                loader = NeighborLoader(graph, num_neighbors=[-1, -1], batch_size=5000, input_nodes=mask)\n",
    "                total_loss = 0\n",
    "                for subg in loader:\n",
    "                    local_models[i].train()\n",
    "                    optimizer.zero_grad() \n",
    "                    out = local_models[i](subg.x, subg.edge_index) \n",
    "                    loss = criterion(out, subg.y)\n",
    "                    \n",
    "                    if global_model:\n",
    "                        prox_term = 0.0\n",
    "                        for param, global_param in zip(local_models[i].parameters(), global_model.parameters()):\n",
    "                            prox_term += (mu / 2) * torch.norm(param - global_param) ** 2\n",
    "                        loss += prox_term\n",
    "                    \n",
    "                    loss.backward() \n",
    "                    optimizer.step()      \n",
    "                    total_loss += loss.item() * subg.batch_size\n",
    "                print(\"Loss: \", total_loss / mask.sum().item(), '\\n')\n",
    "    return local_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FedOpt server-side aggregation loop used in our ablation study.\n",
    "\n",
    "This routine mirrors the API of `server_aggregate`, so you can swap it\n",
    "into any notebook of the base system.\n",
    "\n",
    "Usage\n",
    "-----\n",
    "1. Replace calls to `server_aggregate` with `FedOpt_model_aggregation`.\n",
    "2. Restart the notebook and run all cells with `training=True` to retrain\n",
    "   the global models under FedOpt.\n",
    "3. Run the evaluation cells once training completes to obtain results.\n",
    "\n",
    "Because every notebook shares the same structure, the steps above work\n",
    "for all datasets.\n",
    "\"\"\"\n",
    "\n",
    "def FedOpt_model_aggragation(all_global_models):\n",
    "    global_models = [copy.deepcopy(x) for x in templates]\n",
    "    for l in range(len(all_global_models)):\n",
    "        clients = [m for m in all_global_models[l] if m is not None]\n",
    "        if not clients:\n",
    "            continue\n",
    "        g = global_models[l]\n",
    "        device = next(g.parameters()).device\n",
    "        avg = {}\n",
    "        with torch.no_grad():\n",
    "            for k in g.state_dict().keys():\n",
    "                avg[k] = torch.stack([c.state_dict()[k].to(device) for c in clients], 0).mean(0)\n",
    "        global_opt[l].zero_grad()\n",
    "        for name, p in g.named_parameters():\n",
    "            p.grad = (p.data - avg[name]).detach()\n",
    "        global_opt[l].step()\n",
    "        torch.save(g.state_dict(), f\"Content_FL_Exp/global{l}.pth\")\n",
    "    return global_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_poisoning_simulation_with_multikrum_averaging(all_models, num_poisoned_clients=1, f=1, noise_scale=0.5):\n",
    "    global_models = templates\n",
    "    for l in range(len(all_models)):\n",
    "        current = all_models[l]\n",
    "        valid = [i for i, m in enumerate(current) if m is not None]\n",
    "        n = len(valid)\n",
    "        if n == 0:\n",
    "            continue\n",
    "        if num_poisoned_clients:\n",
    "            poison = np.random.choice(valid, min(num_poisoned_clients, n), replace=False)\n",
    "        else:\n",
    "            poison = []\n",
    "        for idx in poison:\n",
    "            for p in current[idx].parameters():\n",
    "                p.data += torch.randn_like(p) * noise_scale\n",
    "        if n < 2 * f + 3:\n",
    "            avg_state = {}\n",
    "            for k in current[valid[0]].state_dict().keys():\n",
    "                avg_state[k] = torch.stack([current[i].state_dict()[k] for i in valid]).mean(0)\n",
    "            global_models[l].load_state_dict(avg_state)\n",
    "            torch.save(global_models[l].state_dict(), f\"Content_FL_Exp/global{l}.pth\")\n",
    "            continue\n",
    "        g_state = global_models[l].state_dict()\n",
    "        updates = []\n",
    "        for i in valid:\n",
    "            flat = []\n",
    "            c_state = current[i].state_dict()\n",
    "            for k in g_state.keys():\n",
    "                flat.append((c_state[k] - g_state[k]).flatten())\n",
    "            updates.append(torch.cat(flat))\n",
    "        updates = torch.stack(updates)\n",
    "        dist = torch.cdist(updates, updates, p=2).pow(2)\n",
    "        mkr = n - f - 2\n",
    "        scores = []\n",
    "        for i in range(n):\n",
    "            s, _ = torch.sort(dist[i])\n",
    "            scores.append(s[1:mkr + 1].sum())\n",
    "        scores = torch.tensor(scores)\n",
    "        m = mkr\n",
    "        sel = scores.topk(m, largest=False).indices\n",
    "        avg_update = updates[sel].mean(0)\n",
    "        ptr = 0\n",
    "        new_state = {}\n",
    "        for k in g_state.keys():\n",
    "            numel = g_state[k].numel()\n",
    "            new_state[k] = g_state[k] + avg_update[ptr:ptr + numel].view_as(g_state[k])\n",
    "            ptr += numel\n",
    "        global_models[l].load_state_dict(new_state)\n",
    "        torch.save(global_models[l].state_dict(), f\"Content_FL_Exp/global{l}.pth\")\n",
    "    return global_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_poisoning_with_fed_averaging(all_models, num_poisoned_clients=1, noise_scale=0.1):\n",
    "    global_models = copy.deepcopy(templates)\n",
    "    client_indices = [(l, i) for l, layer in enumerate(all_models) for i, m in enumerate(layer) if m is not None]\n",
    "    if not client_indices:\n",
    "        return global_models\n",
    "    k = min(num_poisoned_clients, len(client_indices))\n",
    "    poisoned_clients = set(tuple(client_indices[i]) for i in np.random.choice(len(client_indices), k=k, replace=False))\n",
    "    for l, layer in enumerate(all_models):\n",
    "        if all(m is None for m in layer):\n",
    "            continue\n",
    "        global_state = global_models[l].state_dict()\n",
    "        running_sum = {k: torch.zeros_like(v, dtype=torch.float32) for k, v in global_state.items()}\n",
    "        count = 0\n",
    "        for i, client_model in enumerate(layer):\n",
    "            if client_model is None:\n",
    "                continue\n",
    "            client_sd = client_model.state_dict()\n",
    "            is_poisoned = (l, i) in poisoned_clients\n",
    "            for p_key in global_state.keys():\n",
    "                param = client_sd[p_key].float()\n",
    "                if is_poisoned:\n",
    "                    param = param + torch.randn_like(param) * noise_scale\n",
    "                running_sum[p_key] += param\n",
    "            count += 1\n",
    "        for p_key in global_state.keys():\n",
    "            global_state[p_key] = (running_sum[p_key] / count).type(global_state[p_key].dtype)\n",
    "        global_models[l].load_state_dict(global_state)\n",
    "        torch.save(global_state, f\"Content_FL_Exp/global{l}.pth\")\n",
    "    return global_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_aggregation_with_differential_privacy(client_models, epsilon=0.1, delta=0.01, C=1.0):\n",
    "    global_model = copy.deepcopy(template)\n",
    "    global_sd = global_model.state_dict()\n",
    "    num_clients = len(client_models)\n",
    "    sigma = (C / num_clients) * np.sqrt(2 * np.log(1.25 / delta)) / epsilon\n",
    "    clipped_updates = []\n",
    "    for m in client_models:\n",
    "        upd = {k: (m.state_dict()[k] - global_sd[k]).float() for k in global_sd}\n",
    "        flat = torch.cat([v.view(-1) for v in upd.values()])\n",
    "        coeff = min(1.0, C / (torch.norm(flat, p=2) + 1e-12))\n",
    "        for k in upd:\n",
    "            upd[k] *= coeff\n",
    "        clipped_updates.append(upd)\n",
    "    for k in global_sd:\n",
    "        stacked = torch.stack([u[k] for u in clipped_updates])\n",
    "        mean_update = stacked.mean(0)\n",
    "        noise = torch.randn_like(mean_update) * sigma\n",
    "        global_sd[k] += (mean_update + noise).type(global_sd[k].dtype)\n",
    "    global_model.load_state_dict(global_sd)\n",
    "    torch.save(global_sd, \"Content_FL_Exp/global.pth\")\n",
    "    return global_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
