{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "F1op-CbyLuN4"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Importing the require libraries here\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import json \n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "warnings.filterwarnings('ignore')\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "import multiprocessing\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading libraries and setting up working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nM7KaeCbA_mQ"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Importing some additional libraries\n",
    "'''\n",
    "from pprint import pprint\n",
    "import gzip\n",
    "from sklearn.manifold import TSNE\n",
    "import json\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 10 2 10\n",
    "num_of_ctg = 3\n",
    "learning_rounds = 10\n",
    "epochs = 10\n",
    "hosts = ['cadets','theia','trace']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining functions for loading, cleaning and constructing features from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BfjmrhfUr3pK"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This is the main featurizer. It constructs the graph for the cadets dataset.\n",
    "\n",
    "Args:\n",
    "    df (DataFrame): This is the main dataframe containing all the system events from the cadets dataset.\n",
    "\n",
    "return:\n",
    "    features (list): Contains word2vec encoded feature vectors for each node\n",
    "    feat_labels (list): Contains label for each node\n",
    "    edge_index (list): Contains information about edges between nodes in the graph.\n",
    "    mapp (list): contains id of each node\n",
    "'''\n",
    "\n",
    "def prepare_graph(df):\n",
    "    nodes = {}\n",
    "    labels = {}\n",
    "    edges = []\n",
    "    proc = {}\n",
    "    \n",
    "    dummies = {'SUBJECT_PROCESS': 0,'FILE_OBJECT_FILE': 1,'NetFlowObject': 2,}\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        x = df.iloc[i]\n",
    "        action = x[\"action\"]\n",
    "        \n",
    "        actorid = x[\"actorID\"]\n",
    "        if not (actorid in nodes):\n",
    "            nodes[actorid] =  []\n",
    "        nodes[actorid].append(x['exec'])\n",
    "        nodes[actorid].append(action)\n",
    "        if x['path'] != '':\n",
    "            nodes[actorid].append(x['path'])\n",
    "        labels[actorid] = dummies[x['actor_type']]\n",
    "\n",
    "        objectid = x[\"objectID\"]\n",
    "        if not (objectid in nodes):\n",
    "            nodes[objectid] =  []\n",
    "        nodes[objectid].append(x['exec'])\n",
    "        nodes[objectid].append(action)\n",
    "        if x['path'] != '':\n",
    "             nodes[objectid].append(x['path'])\n",
    "        labels[objectid] = dummies[x['object']]\n",
    "\n",
    "        edges.append(( actorid, objectid ))\n",
    "        \n",
    "        proc[actorid] = x['actorID']\n",
    "\n",
    "    features = []\n",
    "    feat_labels = []\n",
    "    edge_index = [[],[]]\n",
    "    index  = {}\n",
    "    mapp = []\n",
    "\n",
    "    all_procs = set()\n",
    "\n",
    "    for k,v in nodes.items():\n",
    "        features.append(v)\n",
    "        feat_labels.append(labels[k])\n",
    "        index[k] = len(features) - 1\n",
    "        mapp.append(k)\n",
    "        \n",
    "        if k in proc:\n",
    "            all_procs.add(proc[k])\n",
    "\n",
    "    for x in edges:\n",
    "        src = index[x[0]]\n",
    "        dst = index[x[1]]\n",
    "\n",
    "        edge_index[0].append(src)\n",
    "        edge_index[1].append(dst)\n",
    "        \n",
    "    idx_to_proc = {}\n",
    "    for i in range(len(mapp)):\n",
    "        if mapp[i] in proc:\n",
    "            idx_to_proc[i] = proc[mapp[i]]\n",
    "            \n",
    "    all_procs = list(all_procs)\n",
    "\n",
    "    return features,feat_labels,edge_index,mapp,all_procs,idx_to_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fmXWs1dKIzD8"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Defining the model. The model consists of two sageconv layers from the paper GraphSage\n",
    "'''\n",
    "#from torch_geometric.nn import SAGEConv, PDNConv\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self,in_channel,out_channel):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channel, 32, normalize=True)\n",
    "        self.conv2 = SAGEConv(32, out_channel, normalize=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "YBuP_tSq94f4"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This function helps visualize the output of the model.\n",
    "'''\n",
    "def visualize(h, color):\n",
    "    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding semantic attributes from the raw cadets data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function is used for attributing semnatic information like process names, executable paths,\n",
    "file paths etc using the raw cadets data\n",
    "'''\n",
    "\n",
    "def add_attributes(d,p):\n",
    "    \n",
    "    f = open(p)\n",
    "    data = [json.loads(x) for x in f if \"EVENT\" in x]\n",
    "\n",
    "    info = []\n",
    "    for x in data:\n",
    "        try:\n",
    "            action = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['type']\n",
    "        except:\n",
    "            action = ''\n",
    "        try:\n",
    "            actor = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['subject']['com.bbn.tc.schema.avro.cdm18.UUID']\n",
    "        except:\n",
    "            actor = ''\n",
    "        try:\n",
    "            obj = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['predicateObject']['com.bbn.tc.schema.avro.cdm18.UUID']\n",
    "        except:\n",
    "            obj = ''\n",
    "        try:\n",
    "            timestamp = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['timestampNanos']\n",
    "        except:\n",
    "            timestamp = ''\n",
    "        try:\n",
    "            cmd = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['properties']['map']['exec']\n",
    "        except:\n",
    "            cmd = ''\n",
    "        try:\n",
    "            path = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['predicateObjectPath']['string']\n",
    "        except:\n",
    "            path = ''\n",
    "        try:\n",
    "            path2 = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['predicateObject2Path']['string']\n",
    "        except:\n",
    "            path2 = ''\n",
    "        try:\n",
    "            obj2 = x['datum']['com.bbn.tc.schema.avro.cdm18.Event']['predicateObject2']['com.bbn.tc.schema.avro.cdm18.UUID']\n",
    "            info.append({'actorID':actor,'objectID':obj2,'action':action,'timestamp':timestamp,'exec':cmd, 'path':path2})\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        info.append({'actorID':actor,'objectID':obj,'action':action,'timestamp':timestamp,'exec':cmd, 'path':path})\n",
    "\n",
    "    rdf = pd.DataFrame.from_records(info).astype(str)\n",
    "    d = d.astype(str)\n",
    "\n",
    "    return d.merge(rdf,how='inner',on=['actorID','objectID','action','timestamp']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_word2vec_models(models):\n",
    "    # Create an empty unified model\n",
    "    unified_model = Word2Vec(vector_size=models[0].vector_size, window=models[0].window, min_count=models[0].min_count, sg=models[0].sg)\n",
    "\n",
    "    # Initialize the vocabulary with the words from the first model\n",
    "    unified_model.build_vocab([list(models[0].wv.index_to_key)])\n",
    "\n",
    "    # Copy the vectors from the first model to the unified model for the initial vocabulary\n",
    "    for word in unified_model.wv.index_to_key:\n",
    "        unified_model.wv[word] = models[0].wv[word]\n",
    "\n",
    "    # Iterate through the remaining models and add their unique words and average vectors for overlapping words\n",
    "    for model in models[1:]:\n",
    "        # Get the set of unique words in the current model's vocabulary\n",
    "        unique_words = set(model.wv.index_to_key) - set(unified_model.wv.index_to_key)\n",
    "\n",
    "        # Add the unique words to the unified model's vocabulary\n",
    "        unified_model.build_vocab([list(unique_words)], update=True)\n",
    "\n",
    "        # Iterate through the overlapping words and average their vectors\n",
    "        for word in set(model.wv.index_to_key).intersection(set(unified_model.wv.index_to_key)):\n",
    "            unified_model.wv[word] = (unified_model.wv[word] + model.wv[word]) / 2.0\n",
    "\n",
    "        # Copy the vectors for the unique words from the current model to the unified model\n",
    "        for word in unique_words:\n",
    "            unified_model.wv[word] = model.wv[word]\n",
    "\n",
    "    return unified_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from multiprocessing import Pool\n",
    "from itertools import compress\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_models = []\n",
    "#for m in ['cadets','theia','trace']:\n",
    "#    word2vec = Word2Vec.load(f\"content/word2vec_{m}_E3.model\")\n",
    "#    word_models.append(word2vec)\n",
    "\n",
    "#global_word = combine_word2vec_models(word_models)\n",
    "#global_word.save(\"Content_FL_Exp/global_word2vec_E3.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#phrases,labels,edges,mapp = prepare_graph(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3RDmGME5iPb5"
   },
   "outputs": [],
   "source": [
    "#word2vec = Word2Vec(sentences=phrases, vector_size=30, window=5, min_count=1, workers=8,epochs=300,callbacks=[saver,logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "p3TAi69zI1bO"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Defining the train and test function in this cell \n",
    "'''\n",
    "from sklearn.utils import class_weight\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Vn_pMyt5Jd-6"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Encoding function for running word2vec inference\n",
    "'''\n",
    "from collections import Counter\n",
    "word2vec = Word2Vec.load(\"Content_FL_Exp/global_word2vec_E3.model\")\n",
    "\n",
    "def infer(doc):\n",
    "    global word2vec\n",
    "    temp = dict(Counter(doc))\n",
    "    emb = np.zeros(30)\n",
    "    count = 0\n",
    "    for k,v in temp.items():\n",
    "        if k in word2vec.wv:\n",
    "            emb = emb + word2vec.wv[k]*v\n",
    "            count = count + 1\n",
    "    emb = emb / count\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_gnns():\n",
    "    global num_of_ctg\n",
    "    n = num_of_ctg \n",
    "    gnn_models = []\n",
    "    for i in range(n):\n",
    "        m = GCN(30,3).to(device)\n",
    "        gnn_models.append(m)\n",
    "    return gnn_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_categories(pids):\n",
    "    global num_of_ctg\n",
    "    n = num_of_ctg - 1\n",
    "    ctg = set(pids)\n",
    "    ctg = list(ctg)\n",
    "    k, m = divmod(len(ctg), n)\n",
    "    return [set(ctg[i * k + min(i, m):(i + 1) * k + min(i + 1, m)]) for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def map_pids_to_category_indices(pids, categories):\n",
    "    pid_to_category_index = {}\n",
    "    \n",
    "    for pid in pids:\n",
    "        for category_index, category_set in enumerate(categories):\n",
    "            if pid in category_set:\n",
    "                pid_to_category_index[pid] = category_index \n",
    "                break \n",
    "    \n",
    "    return pid_to_category_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from sklearn.utils import class_weight\n",
    "import copy\n",
    "\n",
    "templates = init_gnns()\n",
    "\n",
    "def train_gnn_func(nodes,labels,edges,pids,idx_to_pid):\n",
    "    \n",
    "    global categories ,epochs\n",
    "    \n",
    "    pid_to_gnn_index = map_pids_to_category_indices(pids, categories)\n",
    "\n",
    "    proc_label_index = [i for i in range(len(labels)) if labels[i] == 0]\n",
    "\n",
    "    train_splits = [[] for _ in range(len(categories))]\n",
    "\n",
    "    for i in proc_label_index:\n",
    "        if i in idx_to_pid:\n",
    "            pname = idx_to_pid[i]\n",
    "            split_indx = pid_to_gnn_index[pname]\n",
    "            train_splits[split_indx].append(i)\n",
    "        else:\n",
    "            train_splits[-1].append(i)\n",
    "\n",
    "    local_models = [copy.deepcopy(x) for x in templates]\n",
    "    \n",
    "    for i in range(len(local_models)-1):\n",
    "            \n",
    "        if len(train_splits[i]) == 0:\n",
    "            local_models[i] = None\n",
    "        else:\n",
    "            if f\"target_e3_global{i}.pth\" in os.listdir(\"Content_FL_Exp\"):\n",
    "                local_models[i].load_state_dict(torch.load(f\"Content_FL_Exp/target_e3_global{i}.pth\"))\n",
    "\n",
    "            optimizer = torch.optim.Adam(local_models[i].parameters(), lr=0.01, weight_decay=5e-4)\n",
    "            criterion = CrossEntropyLoss()\n",
    "\n",
    "            graph = Data(x=torch.tensor(nodes,dtype=torch.float).to(device),y=torch.tensor(labels,dtype=torch.long).to(device), edge_index=torch.tensor(edges,dtype=torch.long).to(device))\n",
    "            mask = torch.tensor([False]*graph.num_nodes, dtype=torch.bool)\n",
    "            mask[train_splits[i]] = True\n",
    "            \n",
    "            def get_neighbors(edge_index, nodes):\n",
    "                neighbors = []\n",
    "                for node in nodes:\n",
    "                    mask = edge_index[0] == node\n",
    "                    neighbors.extend(edge_index[1, mask].tolist())\n",
    "                return torch.tensor(list(set(neighbors)), dtype=torch.long)\n",
    "\n",
    "            one_hop_neighbors = get_neighbors(graph.edge_index, train_splits[i])\n",
    "            two_hop_neighbors = get_neighbors(graph.edge_index, one_hop_neighbors)\n",
    "            two_hop_neighbors = two_hop_neighbors[~mask[two_hop_neighbors]]\n",
    "            mask[two_hop_neighbors] = True\n",
    "            \n",
    "            for epoch in range(epochs):\n",
    "                print(f'Training GNN Category {i} Model for Epoch {epoch}')\n",
    "\n",
    "                loader = NeighborLoader(graph, num_neighbors=[-1,-1], batch_size=5000,input_nodes=mask)\n",
    "                total_loss = 0\n",
    "                for subg in loader:\n",
    "                    local_models[i].train()\n",
    "                    optimizer.zero_grad() \n",
    "                    out = local_models[i](subg.x, subg.edge_index) \n",
    "                    loss = criterion(out, subg.y) \n",
    "                    loss.backward() \n",
    "                    optimizer.step()      \n",
    "                    total_loss += loss.item() * subg.batch_size\n",
    "                print(\"Loss: \", total_loss / mask.sum().item(), '\\n')\n",
    "    \n",
    "    graph = Data(x=torch.tensor(nodes,dtype=torch.float).to(device),y=torch.tensor(labels,dtype=torch.long).to(device), edge_index=torch.tensor(edges,dtype=torch.long).to(device))\n",
    "    optimizer = torch.optim.Adam(local_models[-1].parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    criterion = CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f'Training Catch all GNN Category Model for Epoch {epoch}')    \n",
    "        local_models[-1].train()\n",
    "        optimizer.zero_grad() \n",
    "        out = local_models[-1](graph.x, graph.edge_index) \n",
    "        loss = criterion(out, graph.y) \n",
    "        loss.backward() \n",
    "        optimizer.step()      \n",
    "        print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "    return local_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "procs_total = []\n",
    "data_cache = {}\n",
    "categories = None\n",
    "\n",
    "def load_clients_data():\n",
    "    \n",
    "    global data_cache,categories,procs_total\n",
    "    \n",
    "    for name in ['cadets','theia','trace']:\n",
    "        if name == 'cadets':\n",
    "            train_file = 'content/darpatc/cadets_train.txt'\n",
    "            attribute_file = \"content/ta1-cadets-e3-official.json.1\"\n",
    "\n",
    "        if name == 'theia':\n",
    "            train_file = \"content/darpatc/theia_train.txt\"\n",
    "            attribute_file = \"content/ta1-theia-e3-official-1r.json\"\n",
    "\n",
    "        if name == 'trace':\n",
    "            train_file = \"content/darpatc/trace_train.txt\"\n",
    "            attribute_file = \"content/ta1-trace-e3-official-1.json\"  \n",
    "\n",
    "        f = open(train_file)\n",
    "\n",
    "        data = f.read().split('\\n')\n",
    "        data = [line.split('\\t') for line in data]\n",
    "\n",
    "        df = pd.DataFrame (data, columns = ['actorID', 'actor_type','objectID','object','action','timestamp'])\n",
    "        df = df.dropna()\n",
    "        df.sort_values(by='timestamp', ascending=True,inplace=True)\n",
    "        df = add_attributes(df,attribute_file)\n",
    "        df = df[df['actor_type'] == 'SUBJECT_PROCESS'] \n",
    "        df = df[df['object'].isin(['FILE_OBJECT_FILE', 'NetFlowObject', 'SUBJECT_PROCESS'])]    \n",
    "\n",
    "        docs,labels,edges,mapp,pids,idx_to_pid = prepare_graph(df)\n",
    "        data_cache[name] = [docs,labels,edges,mapp,pids,idx_to_pid]\n",
    "        procs_total = procs_total + pids\n",
    "\n",
    "    categories = define_categories(procs_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def client_handling_loop(client_id):    \n",
    "    print(f\"Running Setup on Client {client_id} \\n\")\n",
    "    \n",
    "    docs,labels,edges,mapp,pids,idx_to_pid = data_cache[client_id]\n",
    "    \n",
    "    nodes_feat = []\n",
    "    for x in docs:\n",
    "        nodes_feat.append(infer(x)) \n",
    "        \n",
    "    trained_local_models = train_gnn_func(nodes_feat,labels,edges,pids,idx_to_pid)\n",
    "    return trained_local_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def server_aggregate(all_models):\n",
    "    global_models = copy.deepcopy(templates)\n",
    "    \n",
    "    for l in range(len(all_models)):\n",
    "        \n",
    "        current_models = all_models[l]\n",
    "        current_models = [x for x in current_models if x != None]\n",
    "        \n",
    "        if not len(current_models) == 0:\n",
    "        \n",
    "            global_dict = global_models[l].state_dict()\n",
    "\n",
    "            for k in global_dict.keys():\n",
    "                param_list = [current_models[i].state_dict()[k] for i in range(len(current_models))]\n",
    "                global_dict[k] = torch.stack(param_list, 0).mean(0)\n",
    "\n",
    "            global_models[l].load_state_dict(global_dict)\n",
    "            torch.save(global_models[l].state_dict(), f\"Content_FL_Exp/target_e3_global{l}.pth\")\n",
    "                   \n",
    "    return global_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def perform_federated_learning(n_clients):\n",
    "    client_models = []\n",
    "    for c in n_clients:\n",
    "        local_gnns = client_handling_loop(c)\n",
    "        client_models.append(local_gnns)\n",
    "    return client_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm Content_FL_Exp/target_e3_*.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('Content_FL_Exp/e3_ensemble_ben.json', 'r') as f:\n",
    "    data_cache = json.load(f)\n",
    "\n",
    "proc_total = []\n",
    "for x in ['cadets','theia','trace']:\n",
    "    proc_total = proc_total + data_cache[x][-2]\n",
    "    \n",
    "categories = define_categories(proc_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_clients_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Federated Learning Round Number: 0\n",
      "\n",
      "Running Setup on Client cadets \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.9624765316732339 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.8799056855755691 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8715500834302088 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8656484187286543 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8590891473082705 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8542371986605544 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8490660467297477 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.845884280034085 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8432742625054365 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8429242807295929 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.0405890941619873\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 0.9588620662689209\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9296485781669617\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.8915128111839294\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.8933729529380798\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.8857926726341248\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.8897050619125366\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.8820511102676392\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.8741858005523682\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.8756363391876221\n",
      "Running Setup on Client theia \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  1.0366975880729814 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.895729760706591 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8624467535532119 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8501619422164794 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8434934865927114 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8401080068954996 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8375082210210076 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.83601820112104 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8341535106469671 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8330573380492587 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.1434062719345093\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.034019112586975\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9659128785133362\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.9360811114311218\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.9140674471855164\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.9023163914680481\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.8990507125854492\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.8885734677314758\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.8749340176582336\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.872857391834259\n",
      "Running Setup on Client trace \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  1.0524055370824592 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.9449639270282774 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.9106989740921962 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8809384612867674 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8736136619209638 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.866896886073864 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8626372485058629 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8601343825720019 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8584364057259578 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8546662590830459 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.1883200407028198\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.057928442955017\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9509665369987488\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.9344861507415771\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.9173056483268738\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.8992485404014587\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.8855751752853394\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.8900463581085205\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.9124726057052612\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.8780190348625183\n",
      "Federated Learning Round Number: 1\n",
      "\n",
      "Running Setup on Client cadets \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.8687901581192994 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.8704738395887011 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.84943490052776 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8442737735713944 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8418648769692196 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8424130265189808 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8416222188628093 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8404366374656137 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8385275587103365 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8396978616665987 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.0252107381820679\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.0130515098571777\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9159058332443237\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.8906735777854919\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.8913077712059021\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.8850627541542053\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.8813266754150391\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.8774092793464661\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.8823954463005066\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.8720986843109131\n",
      "Running Setup on Client theia \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.850244085128689 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.837525075016713 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8344909432634855 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8324805584642206 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8313544746901814 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8304564831390924 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8301142780970627 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8298395873304537 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.829447125243942 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8292511467248264 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.1367099285125732\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.0349944829940796\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9619165658950806\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.9359275102615356\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.9183679819107056\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.9052965044975281\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.896841287612915\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.8838712573051453\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.8767611980438232\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.873898983001709\n",
      "Running Setup on Client trace \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.9056640151053986 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.8724331746179373 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8609480084972199 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8571594910169817 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8531221390711811 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8504458193851606 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8487808391056825 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8475723273661334 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.846725577126098 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8448199068363682 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.199081540107727\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.0195037126541138\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9506974220275879\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.9392666220664978\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.9282335638999939\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.8996527194976807\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.9017277359962463\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.8878383636474609\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.8895076513290405\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.8798595070838928\n",
      "Federated Learning Round Number: 2\n",
      "\n",
      "Running Setup on Client cadets \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.8576492027683991 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.8494427782025523 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8433579605012161 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8421505561082778 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8422262538218824 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8476682458256413 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8463791907533037 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8427957522587739 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8412559486899414 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8401455238211425 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.0599801540374756\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 0.9586325287818909\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.901081383228302\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.9070054888725281\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.8875139355659485\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.8838080167770386\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.8833048343658447\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.8815367221832275\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.8810424208641052\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.8808672428131104\n",
      "Running Setup on Client theia \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.8416251598523629 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.8345828010910313 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.832799011642929 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8312524182514737 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8303129532740838 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8301073420195128 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.829891662972889 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8296364198980104 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.829211973674941 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8290452421321588 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.1368849277496338\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.0340434312820435\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.964857280254364\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.9385015368461609\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.9132853746414185\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.9053096175193787\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.8896593451499939\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.8867982625961304\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.8756879568099976\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.8725208044052124\n",
      "Running Setup on Client trace \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.8726481338442885 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.852926576231673 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8511068154645383 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8484230091258489 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.846689452475501 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8453914339234448 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.843211742726276 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8407712659456604 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8388560848322146 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8372510304507467 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.1913713216781616\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.0293866395950317\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9608579277992249\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.937971830368042\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.9149516820907593\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.9091773629188538\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.9074515104293823\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.8906342387199402\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.8879558444023132\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.8826320171356201\n",
      "Federated Learning Round Number: 3\n",
      "\n",
      "Running Setup on Client cadets \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.8499792703589817 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.844924623150053 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8433002828973536 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8440641216285706 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8427574477292274 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8411890958600025 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.837668761101364 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8373230836441358 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8371397937968095 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.840052853834607 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.068719744682312\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.0042513608932495\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9054572582244873\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.8875008225440979\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.9053872227668762\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.893074095249176\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.8883578777313232\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.8835322260856628\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.8735173344612122\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.8747605085372925\n",
      "Running Setup on Client theia \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.8407796663103193 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.832755818663958 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8309189549810394 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8298618612737764 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8296636872680531 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8291431998951951 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8288166819167467 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8283554422949925 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8280461943853656 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8281386472927547 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.1417406797409058\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.038648247718811\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.963723361492157\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.9303469061851501\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.9162113666534424\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.9034688472747803\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.8966919779777527\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.8836836218833923\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.8772723078727722\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.8708961009979248\n",
      "Running Setup on Client trace \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.8663039595409765 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.8538478473049063 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8496486171113523 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8472637837711728 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8454601904865853 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8444431454397096 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8423625551840712 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.841278578222504 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8384008533660127 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8364073453619194 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.2005809545516968\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.0326437950134277\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9462196826934814\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.9243788123130798\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.9184577465057373\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.8992050886154175\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.9003356695175171\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.8991641998291016\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.8871607184410095\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.883025586605072\n",
      "Federated Learning Round Number: 4\n",
      "\n",
      "Running Setup on Client cadets \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.8453090433683889 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.8426881802916727 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8399695814689704 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.839692135826598 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.837118915448615 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8364995090312449 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8361166867441991 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8381805028786793 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8390996243812037 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8438997676249013 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.0749131441116333\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 0.9487529397010803\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9202398657798767\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.8960518836975098\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.8919153213500977\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.8815677165985107\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.8888651132583618\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.8750709295272827\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.8782694339752197\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.885344386100769\n",
      "Running Setup on Client theia \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.8352147853840881 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.8313740932068323 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8304531055214271 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8295074266812498 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8291340203599813 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8286335500301111 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8284391533066593 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8279318909603036 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8281648650991884 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8278291632965483 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.1451945304870605\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.033705472946167\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9653604030609131\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.9385189414024353\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.9166961908340454\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.900914192199707\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.8939017057418823\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.8874483108520508\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.8774265646934509\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.8740175366401672\n",
      "Running Setup on Client trace \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.8646404681001353 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.8593054533139233 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8490172736199643 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8462576924981334 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8446716240954413 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8423146978651005 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8409041028135722 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8382096321853083 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8380357297006059 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.836580190259188 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.1759669780731201\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.082390546798706\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9684669971466064\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.9343634247779846\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.9249505400657654\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.9164490699768066\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.9161262512207031\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.8950135707855225\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.8976022005081177\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.8939862847328186\n",
      "Federated Learning Round Number: 5\n",
      "\n",
      "Running Setup on Client cadets \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.8455396445711358 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.841668880433915 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8397146573934773 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8396573668775719 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8383627014655908 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.838746827006575 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8383555877059133 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8370480273493487 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8353840383383514 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8350776634703256 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.0757920742034912\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 0.9241778254508972\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9115839600563049\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.8893117904663086\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.8926535844802856\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.8936325311660767\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.8846160173416138\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.8845876455307007\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.8814340233802795\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.879015326499939\n",
      "Running Setup on Client theia \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.8344543719012798 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.830598328539707 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8299040563074106 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.829586277010592 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8289524298485615 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8284142738752632 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8280884136448585 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.828132208498956 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8279319817788833 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8277774771588067 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.1359226703643799\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.0340492725372314\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9717709422111511\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.9357219934463501\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.9145669937133789\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.9031832814216614\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.8919020295143127\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.8827006220817566\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.876182496547699\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.871475338935852\n",
      "Running Setup on Client trace \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.8712119024753302 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.852497406585433 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.849314939821096 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8462697725745156 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8446849155614286 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8403770638870373 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.83741916490018 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8370348270236605 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8364808147933882 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8372332930766588 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.1866520643234253\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.060166597366333\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9555814862251282\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.9480611085891724\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.931770920753479\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.9191350936889648\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.918361485004425\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.8990810513496399\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.8991427421569824\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.8788318634033203\n",
      "Federated Learning Round Number: 6\n",
      "\n",
      "Running Setup on Client cadets \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.8471617112339817 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.8454448149732358 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8481517090425362 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8416386055633273 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8398953082651587 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8378845091072585 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8365252922435877 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8356696851358424 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8372834029309545 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8410258383376019 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.0673606395721436\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 0.9444791674613953\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9111092686653137\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.9060105085372925\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.8833529949188232\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.890092134475708\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.8918074369430542\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.874868631362915\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.8748390078544617\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.8786101937294006\n",
      "Running Setup on Client theia \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.8376615855256363 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.8312120765343297 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8305067359711854 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8295669054693481 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8288996537082761 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8286360589897708 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8282458658650239 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8280576996452771 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8279417393912062 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8278090556779525 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.146754503250122\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.0358588695526123\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9638023972511292\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.932482123374939\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.9175557494163513\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.903523862361908\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.892778217792511\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.8863002061843872\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.8780600428581238\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.877866804599762\n",
      "Running Setup on Client trace \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.8662043638775326 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.8521037487007438 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.846471111820165 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8445611761844031 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8422950590591409 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8395084310102382 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8381807839070345 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8378942744313695 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8366714199249582 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8379914287921069 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.1777695417404175\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.0529898405075073\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9604460597038269\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.9598813056945801\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.939185619354248\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.9171814918518066\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.9041611552238464\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.8916135430335999\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.884425163269043\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.903339684009552\n",
      "Federated Learning Round Number: 7\n",
      "\n",
      "Running Setup on Client cadets \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.8469027191870205 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.8427199013537037 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8399219004102029 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8413366248066353 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.843099843113267 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8391955748761637 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8390131938733141 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8373715898421348 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8368128926487894 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8390286282498008 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.09005868434906\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 0.9494742155075073\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.8986061811447144\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.8937597870826721\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.9002203345298767\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.8792101144790649\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.8787086009979248\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.8766661286354065\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.87283855676651\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.8753674030303955\n",
      "Running Setup on Client theia \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.8372642099791305 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.8308859550803431 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8300194040061659 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.829264169131454 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8287713393912982 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.828634995164782 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8281106348633317 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8280444091986562 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8276552004498073 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8278009656778261 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.1494743824005127\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.034960150718689\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9598546624183655\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.929567813873291\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.9134607911109924\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.9058387875556946\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.8942807912826538\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.8861469030380249\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.8766001462936401\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.874981164932251\n",
      "Running Setup on Client trace \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.8670657614631567 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.8547404551667409 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8502213302400915 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8463511231318074 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8435501283800542 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8414639924719585 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8406517894605561 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8376735172161461 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8378746308180416 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8390328610810733 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.1970112323760986\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.0196934938430786\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9531927108764648\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.9308809041976929\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.9022077918052673\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.9021841287612915\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.9208753108978271\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.8991824984550476\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.8978373408317566\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.9003247022628784\n",
      "Federated Learning Round Number: 8\n",
      "\n",
      "Running Setup on Client cadets \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.843878039916891 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.8440645307512913 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8409633569973688 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8398507228786843 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.83961577857206 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8369298374026086 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8370317615223529 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8358518686116209 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8363884828650352 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8378925530455449 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.0919709205627441\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 0.9801522493362427\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9038044214248657\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.9017161726951599\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.8909556865692139\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.8897539973258972\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.8796907067298889\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.8783336877822876\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.8842272162437439\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.8727959990501404\n",
      "Running Setup on Client theia \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.8376438527806785 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.8317378123036104 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8298295081847581 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.82960694927419 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8291236511325376 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8285355331747832 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8283953612625818 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8282247955557505 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8279076535234084 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8279384174457423 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.1467958688735962\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.0361226797103882\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9642338752746582\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.9323336482048035\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.9215868711471558\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.9063984155654907\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.8950808048248291\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.8918235898017883\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.8790653944015503\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.8725411295890808\n",
      "Running Setup on Client trace \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.8716794154903543 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.8512693537337189 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8477825614199824 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8447084737509842 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8433388627254553 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8415120755019191 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8414890138160288 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8403785750480002 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8378688404268285 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8380112025069437 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.1707351207733154\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.072310447692871\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.969194233417511\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.9457036852836609\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.9363088607788086\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.9166554808616638\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.9049853086471558\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.9042852520942688\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.8938009142875671\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.8864564895629883\n",
      "Federated Learning Round Number: 9\n",
      "\n",
      "Running Setup on Client cadets \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.8451296407153364 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.8442168625620801 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8414131328069566 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8405445896946449 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8419427936327555 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.838345867903996 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8367715242489003 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8356351924637353 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8350667249154631 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8358405859970172 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.0905441045761108\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 0.9584009647369385\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9478104710578918\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.9273450970649719\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.88784259557724\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.8937416672706604\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.8905448317527771\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.890403151512146\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.8815953135490417\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.8815218210220337\n",
      "Running Setup on Client theia \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.8359906738215035 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.8309889125266197 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8294182437603641 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8290279560351309 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.8284808691949045 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8283929476032724 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8285590123525989 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8282256066638063 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.828047462993205 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.8283707949503444 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.1428821086883545\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.033544898033142\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9658951759338379\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.928777813911438\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.9134061336517334\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.8996009230613708\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.8953179717063904\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.8882867097854614\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.8788089156150818\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.8691447377204895\n",
      "Running Setup on Client trace \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 0\n",
      "Loss:  0.8662664076062292 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 1\n",
      "Loss:  0.8541446192682765 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 2\n",
      "Loss:  0.8483141284169144 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 3\n",
      "Loss:  0.8456110142074731 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 4\n",
      "Loss:  0.841820388948319 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 5\n",
      "Loss:  0.8423374774962983 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 6\n",
      "Loss:  0.8399258569614133 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 7\n",
      "Loss:  0.8375362429790959 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 8\n",
      "Loss:  0.8375139045163997 \n",
      "\n",
      "Training GNN Category 1 Model for Epoch 9\n",
      "Loss:  0.836283818484025 \n",
      "\n",
      "Training Catch all GNN Category Model for Epoch 0\n",
      "Epoch: 0, Loss: 1.2027859687805176\n",
      "Training Catch all GNN Category Model for Epoch 1\n",
      "Epoch: 1, Loss: 1.0436793565750122\n",
      "Training Catch all GNN Category Model for Epoch 2\n",
      "Epoch: 2, Loss: 0.9712415933609009\n",
      "Training Catch all GNN Category Model for Epoch 3\n",
      "Epoch: 3, Loss: 0.9400149583816528\n",
      "Training Catch all GNN Category Model for Epoch 4\n",
      "Epoch: 4, Loss: 0.9270052313804626\n",
      "Training Catch all GNN Category Model for Epoch 5\n",
      "Epoch: 5, Loss: 0.9063879251480103\n",
      "Training Catch all GNN Category Model for Epoch 6\n",
      "Epoch: 6, Loss: 0.8923741579055786\n",
      "Training Catch all GNN Category Model for Epoch 7\n",
      "Epoch: 7, Loss: 0.8867496252059937\n",
      "Training Catch all GNN Category Model for Epoch 8\n",
      "Epoch: 8, Loss: 0.8851844072341919\n",
      "Training Catch all GNN Category Model for Epoch 9\n",
      "Epoch: 9, Loss: 0.8891909718513489\n"
     ]
    }
   ],
   "source": [
    "for r in range(learning_rounds):\n",
    "    print(f\"Federated Learning Round Number: {r}\\n\")\n",
    "    client_models = perform_federated_learning(hosts)\n",
    "    arranged_models =  [list(group) for group in zip(*client_models)]\n",
    "    global_models = server_aggregate(arranged_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the trained GNN model starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "PKJ53Fh5ogvy"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This function is used for constructing neighborhood around a given \n",
    "set of nodes for backwards or forward tracking\n",
    "'''\n",
    "from itertools import compress\n",
    "from torch_geometric import utils\n",
    "\n",
    "def construct_neighborhood(ids,mapp,edges,hops):\n",
    "    if hops == 0:\n",
    "        return set()\n",
    "    else:\n",
    "        neighbors = set()\n",
    "        for i in range(len(edges[0])):\n",
    "            if mapp[edges[0][i]] in ids:\n",
    "                neighbors.add(mapp[edges[1][i]])\n",
    "            if mapp[edges[1][i]] in ids:\n",
    "                neighbors.add(mapp[edges[0][i]])\n",
    "        return neighbors.union( construct_neighborhood(neighbors,mapp,edges,hops-1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "vgqyu7E5qPet"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This function logs the evaluation metrics.\n",
    "'''\n",
    "\n",
    "def helper(MP,all_pids,GP,edges,mapp):\n",
    "\n",
    "    #GN = all_pids - GP\n",
    "    #MN = all_pids - MP\n",
    "\n",
    "    #TP = MP.intersection(GP)\n",
    "    #FP = MP.intersection(GN)\n",
    "    #FN = MN.intersection(GP)\n",
    "    #TN = MN.intersection(GN)\n",
    "    \n",
    "    TP = MP.intersection(GP)  # Correct\n",
    "    FP = MP - GP              # Detected positives that are not true positives\n",
    "    FN = GP - MP              # True positives that were not detected as positives\n",
    "    TN = all_pids - (GP | MP)\n",
    "    \n",
    "    two_hop_gp = construct_neighborhood(GP,mapp,edges,2)\n",
    "    two_hop_tp = construct_neighborhood(TP,mapp,edges,2)\n",
    "    FPL = FP - two_hop_gp\n",
    "    TPL = TP.union(FN.intersection(two_hop_tp))\n",
    "    FN = FN - two_hop_tp\n",
    "    \n",
    "    alerts = TP.union(FP)\n",
    "\n",
    "    TP,FP,FN,TN = len(TPL),len(FPL),len(FN),len(TN)\n",
    "    \n",
    "    FPR = FP / (FP+TN)\n",
    "    TPR = TP / (TP+FN)\n",
    "\n",
    "    print(f\"Number of True Positives: {TP}\")\n",
    "    print(f\"Number of Fasle Positives: {FP}\")\n",
    "    print(f\"Number of False Negatives: {FN}\")\n",
    "    print(f\"Number of True Negatives: {TN}\\n\")\n",
    "\n",
    "    prec = TP / (TP + FP)\n",
    "    print(f\"Precision: {prec}\")\n",
    "\n",
    "    rec = TP / (TP + FN)\n",
    "    print(f\"Recall: {rec}\")\n",
    "\n",
    "    fscore = (2*prec*rec) / (prec + rec)\n",
    "    print(f\"Fscore: {fscore}\\n\")\n",
    "    \n",
    "    #return alerts\n",
    "    return TPL,FPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cache_mal = {}\n",
    "def load_data_test():\n",
    "    \n",
    "    test_file = None\n",
    "    attribute_file = None\n",
    "    \n",
    "    for name in ['cadets','theia','trace']:\n",
    "\n",
    "        if name == 'cadets':\n",
    "            test_file = 'content/darpatc/cadets_test.txt'\n",
    "            attribute_file = \"content/ta1-cadets-e3-official-2.json\"\n",
    "\n",
    "        if name == 'theia':\n",
    "            test_file = \"content/darpatc/theia_test.txt\"\n",
    "            attribute_file = \"content/ta1-theia-e3-official-6r.json.8\"\n",
    "\n",
    "        if name == 'trace':\n",
    "            test_file = \"content/darpatc/trace_test.txt\"\n",
    "            attribute_file = \"content/ta1-trace-e3-official-1.json.4\"\n",
    "\n",
    "        f = open(test_file)\n",
    "\n",
    "        data = f.read().split('\\n')\n",
    "        data = [line.split('\\t') for line in data]\n",
    "\n",
    "        df = pd.DataFrame (data, columns = ['actorID', 'actor_type','objectID','object','action','timestamp'])\n",
    "        df = df.dropna()\n",
    "        df.sort_values(by='timestamp', ascending=True,inplace=True)\n",
    "\n",
    "        df = add_attributes(df,attribute_file)\n",
    "\n",
    "        df = df[df['actor_type'] == 'SUBJECT_PROCESS'] \n",
    "        df = df[df['object'].isin(['FILE_OBJECT_FILE', 'NetFlowObject', 'SUBJECT_PROCESS'])]\n",
    "\n",
    "        docs,labels,edges,mapp,pids,idx_to_pid = prepare_graph(df)\n",
    "        data_cache_mal[name] = [docs,labels,edges,mapp,pids,idx_to_pid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load_data_test()\n",
    "with open('e3_ensemble_mal.json', 'r') as f:\n",
    "    data_cache_mal = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation(data_name,thresh):    \n",
    "    global word2vec\n",
    "\n",
    "    client_data = data_cache_mal[data_name]\n",
    "            \n",
    "    phrases,labels,edges,mapp,pids,idx_to_pid = client_data\n",
    "\n",
    "    gt = open(f\"{data_name}.txt\").read()\n",
    "    GT_mal = gt.split(\"\\n\")\n",
    "    GT_mal = set([x for x in GT_mal if x in mapp])\n",
    "\n",
    "    model = GCN(30,3).to(device)\n",
    "    word2vec = Word2Vec.load(\"Content_FL_Exp/global_word2vec_E3.model\")\n",
    "\n",
    "    nodes = [infer(x) for x in phrases]\n",
    "    nodes = np.array(nodes)  \n",
    "\n",
    "    all_ids = set(mapp)\n",
    "        \n",
    "    graph = Data(x=torch.tensor(nodes,dtype=torch.float).to(device),y=torch.tensor(labels,dtype=torch.long).to(device), edge_index=torch.tensor(edges,dtype=torch.long).to(device))\n",
    "\n",
    "    flag = torch.tensor([True]*graph.num_nodes, dtype=torch.bool)\n",
    "    \n",
    "    for m_n in range(num_of_ctg):\n",
    "        \n",
    "        if f\"target_e3_global{m_n}.pth\" in os.listdir(\"Content_FL_Exp\"): \n",
    "            model.load_state_dict(torch.load(f\"Content_FL_Exp/target_e3_global{m_n}.pth\"))\n",
    "            \n",
    "        model.eval()\n",
    "        out = model(graph.x, graph.edge_index)\n",
    "\n",
    "        sorted, indices = out.sort(dim=1,descending=True)\n",
    "        conf = (sorted[:,0] - sorted[:,1]) / sorted[:,0]\n",
    "        conf = (conf - conf.min()) / conf.max()\n",
    "\n",
    "        pred = indices[:,0]\n",
    "        cond = (pred == graph.y) & (conf >= thresh)\n",
    "        flag[cond] = torch.logical_and(flag[cond], torch.tensor([False]*len(flag[cond]), dtype=torch.bool))\n",
    "\n",
    "    index = utils.mask_to_index(flag).tolist()\n",
    "    ids = set([mapp[x] for x in index])\n",
    "    TPL,FPL = helper(set(ids),set(all_ids),GT_mal,edges,mapp)\n",
    "    mapp_to_labels = {x:y for x,y in zip(mapp,labels)}\n",
    "    return TPL,FPL,mapp_to_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of True Positives: 12845\n",
      "Number of Fasle Positives: 189\n",
      "Number of False Negatives: 1\n",
      "Number of True Negatives: 104445\n",
      "\n",
      "Precision: 0.985499462943072\n",
      "Recall: 0.9999221547563444\n",
      "Fscore: 0.9926584234930448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = run_evaluation('cadets',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of True Positives: 25310\n",
      "Number of Fasle Positives: 699\n",
      "Number of False Negatives: 4\n",
      "Number of True Negatives: 32033\n",
      "\n",
      "Precision: 0.9731246876081356\n",
      "Recall: 0.9998419846725133\n",
      "Fscore: 0.9863024375036534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = run_evaluation('theia',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of True Positives: 67357\n",
      "Number of Fasle Positives: 1922\n",
      "Number of False Negatives: 0\n",
      "Number of True Negatives: 34200\n",
      "\n",
      "Precision: 0.9722571053277328\n",
      "Recall: 1.0\n",
      "Fscore: 0.9859334289645482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = run_evaluation('trace',0)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "PyTorch 1.12.0",
   "language": "python",
   "name": "pytorch-1.12.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
