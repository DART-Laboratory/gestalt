{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/Trustwatch'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"Trustwatch\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_ctg = 10\n",
    "learning_rounds = 3\n",
    "epochs = 10\n",
    "hosts = ['051.txt','501.txt','201.txt']\n",
    "TRAIN=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import json\n",
    "import copy\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from multiprocessing import Pool\n",
    "from itertools import compress\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import multiprocessing\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "from multiprocessing import Pool\n",
    "from itertools import compress\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def infer(doc,word2vec):  \n",
    "    word_emb = []\n",
    "    for word in doc:\n",
    "        if word in word2vec.wv:\n",
    "            word_emb.append(word2vec.wv[word])\n",
    "            \n",
    "    if len(word_emb) == 0:\n",
    "        return np.zeros(20)\n",
    "\n",
    "    out_emb = torch.tensor(word_emb,dtype=torch.float)\n",
    "    out_emb = out_emb.detach().cpu().numpy()\n",
    "    out_emb = np.mean(out_emb,axis=0)\n",
    "    return out_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    new_data = {}\n",
    "    for x in data:\n",
    "        check1 = x['object'] in ['PROCESS','FILE','FLOW','MODULE']\n",
    "        check2 = not (x['action'] in ['START','TERMINATE'])\n",
    "        check3 = x['actorID'] != x['objectID']\n",
    "        key = (x['action'],x['actorID'],x['objectID'],x['object'],x['pid'],x['ppid'])\n",
    "        if check1 and check2 and check3:\n",
    "            new_data[key] = x\n",
    "    return list(new_data.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Extract_Semantic_Info(event):\n",
    "    object_type = event['object']\n",
    "    properties = event['properties']\n",
    "\n",
    "    label_mapping = {\n",
    "        \"PROCESS\": ('parent_image_path', 'image_path'),\n",
    "        \"FILE\": ('image_path', 'file_path'),\n",
    "        \"MODULE\": ('image_path', 'module_path'),\n",
    "        \"FLOW\": ('image_path', 'dest_ip', 'dest_port')\n",
    "    }\n",
    "\n",
    "    label_keys = label_mapping.get(object_type, None)\n",
    "    if label_keys:\n",
    "        labels = [properties.get(key) for key in label_keys]\n",
    "        if all(labels):\n",
    "            event[\"actorname\"], event[\"objectname\"] = labels[0], ' '.join(labels[1:])\n",
    "            return event\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def describe(x):\n",
    "    action = x[\"action\"]\n",
    "    props = x['properties']\n",
    "    typ = x['object']\n",
    "\n",
    "    phrase = ''\n",
    "    try:\n",
    "        if typ == 'PROCESS':\n",
    "            phrase = f\"{props['parent_image_path']} {action} {props['image_path']} {props['command_line']}\" \n",
    "\n",
    "        elif typ == 'FILE':\n",
    "            phrase = f\"{props['image_path']} {action} {props['file_path']}\"    \n",
    "\n",
    "        elif typ == 'FLOW':\n",
    "            phrase = f\"{props['image_path']} {action}  {props['dest_ip']} {props['dest_port']} {props['direction']}\"    \n",
    "\n",
    "        else:\n",
    "            phrase = f\"{props['image_path']} {action} {props['module_path']}\"\n",
    "    except:\n",
    "        phrase = ''\n",
    "  \n",
    "    return phrase.split(' ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform(text):\n",
    "    text = [event for event in (Extract_Semantic_Info(x) for x in text) if event]\n",
    "    data = preprocess(text)\n",
    "\n",
    "    temp = [describe(x) for x in data]\n",
    "    temp = [x for x in temp if len(x) != 0]\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        data[i]['phrase'] = temp[i]\n",
    "        try:\n",
    "            data[i]['proc_name'] = data[i]['properties']['image_path']\n",
    "        except:\n",
    "            data[i]['proc_name'] = ''\n",
    "\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    df['timestamp'] = df['timestamp'].str[:-6]\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'],infer_datetime_format=True)\n",
    "    df.sort_values(by='timestamp', ascending=True,inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def load_data(dataset_id):\n",
    "    f = open(f\"content/data/hosts/{dataset_id}\")\n",
    "    content = [json.loads(line) for line in f]\n",
    "    return prepare_graph(transform(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_graph(df):\n",
    "    nodes = {}\n",
    "    labels = {}\n",
    "    edges = []\n",
    "    proc = {}\n",
    "    dummies = {'PROCESS':0,'FLOW':1,'FILE':2,'MODULE':3}\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        x = df.iloc[i]\n",
    "\n",
    "        actorid = x['actorID']\n",
    "        if not (actorid in nodes):\n",
    "            nodes[actorid] = []\n",
    "        nodes[actorid] += x['phrase']\n",
    "        labels[actorid] = dummies['PROCESS']\n",
    "\n",
    "        objectid = x[\"objectID\"]\n",
    "        if not (objectid in nodes):\n",
    "            nodes[objectid] = []\n",
    "        nodes[objectid] += x['phrase']\n",
    "        labels[objectid] = dummies[x['object']]\n",
    "        \n",
    "        edges.append(( actorid, objectid, x['action'] ))\n",
    "        \n",
    "        proc[actorid] = x['proc_name']\n",
    "\n",
    "    features = []\n",
    "    feat_labels = []\n",
    "    edge_index = [[],[]]\n",
    "    index  = {}\n",
    "    mapp = []\n",
    "    \n",
    "    all_procs = set()\n",
    "              \n",
    "    for k,v in nodes.items():\n",
    "        features.append(v)\n",
    "        feat_labels.append(labels[k])\n",
    "        index[k] = len(features) - 1\n",
    "        mapp.append(k)\n",
    "        \n",
    "        if k in proc:\n",
    "            all_procs.add(proc[k])\n",
    "\n",
    "    for x in edges:\n",
    "        src = index[x[0]]\n",
    "        dst = index[x[1]]\n",
    "    \n",
    "        edge_index[0].append(src)\n",
    "        edge_index[1].append(dst)    \n",
    "    \n",
    "    idx_to_proc = {}\n",
    "    for i in range(len(mapp)):\n",
    "        if mapp[i] in proc:\n",
    "            idx_to_proc[i] = proc[mapp[i]]\n",
    "            \n",
    "    all_procs = list(all_procs)\n",
    "    \n",
    "    return features,feat_labels,edge_index,mapp,all_procs,idx_to_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import SAGEConv, GATConv\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = SAGEConv(20, 32, normalize=True)\n",
    "        self.conv2 = SAGEConv(32, 20, normalize=True)\n",
    "        self.linear = nn.Linear(in_features=20, out_features=4)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
    "    \n",
    "        x = self.encode(x, edge_index)\n",
    "        x = self.linear(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "    \n",
    "    def encode(self, x: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "    \n",
    "    def freeze_conv_layers(self):\n",
    "        for param in self.conv1.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.conv2.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from multiprocessing import Pool\n",
    "from itertools import compress\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "class EpochSaver(CallbackAny2Vec):\n",
    "\n",
    "    def __init__(self,client_id):\n",
    "        self.epoch = 0\n",
    "        self.cid = client_id\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        model.save(f\"Content_FL_Exp/{self.cid}.model\")\n",
    "        self.epoch += 1\n",
    "        \n",
    "class EpochLogger(CallbackAny2Vec):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_begin(self, model):\n",
    "        pass\n",
    "        #print(\"Epoch #{} start\".format(self.epoch))\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        #print(\"Epoch #{} end\".format(self.epoch))\n",
    "        self.epoch += 1\n",
    "        \n",
    "def train_word2vec_func(docs,client_id):\n",
    "    logger = EpochLogger()\n",
    "    saver = EpochSaver(client_id)\n",
    "    word2vec = Word2Vec(sentences=docs, vector_size=20, window=5, min_count=1,workers=5,epochs=100,callbacks=[saver,logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_gnns():\n",
    "    global num_of_ctg\n",
    "    n = num_of_ctg\n",
    "    gnn_models = []\n",
    "    for i in range(n):\n",
    "        m = GCN().to(device)\n",
    "        gnn_models.append(m)\n",
    "    return gnn_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_categories(pids):\n",
    "    global num_of_ctg\n",
    "    n = num_of_ctg - 1\n",
    "    ctg = set(pids)\n",
    "    ctg = list(ctg)\n",
    "    k, m = divmod(len(ctg), n)\n",
    "    return [set(ctg[i * k + min(i, m):(i + 1) * k + min(i + 1, m)]) for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def map_pids_to_category_indices(pids, categories):\n",
    "    pid_to_category_index = {}\n",
    "    \n",
    "    for pid in pids:\n",
    "        for category_index, category_set in enumerate(categories):\n",
    "            if pid in category_set:\n",
    "                pid_to_category_index[pid] = category_index\n",
    "                break \n",
    "    \n",
    "    return pid_to_category_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "procs_total = []\n",
    "data_cache = {}\n",
    "categories = None\n",
    "\n",
    "def load_clients_data(client_ids):\n",
    "    \n",
    "    global data_cache,categories,procs_total\n",
    "    \n",
    "    for x in client_ids:\n",
    "        docs,labels,edges,mapp,pids,idx_to_pid = load_data(x)\n",
    "        data_cache[x] = [docs,labels,edges,mapp,pids,idx_to_pid]\n",
    "        procs_total = procs_total + pids\n",
    "        \n",
    "    categories = define_categories(procs_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from sklearn.utils import class_weight\n",
    "import copy\n",
    "\n",
    "templates = init_gnns()\n",
    "\n",
    "def train_gnn_func(nodes,labels,edges,mapp,pids,idx_to_pid):\n",
    "    \n",
    "    global categories ,epochs\n",
    "    \n",
    "    pid_to_gnn_index = map_pids_to_category_indices(pids, categories)\n",
    "    \n",
    "    set_pids = set(pids)\n",
    "\n",
    "    proc_index = list(idx_to_pid.keys())\n",
    "\n",
    "    train_splits = [[] for _ in range(len(categories))]\n",
    "    \n",
    "    for i in proc_index:\n",
    "        pname = idx_to_pid[str(i)]\n",
    "        split_indx = pid_to_gnn_index[pname]\n",
    "        train_splits[split_indx].append(int(i))\n",
    "        \n",
    "    local_models = [copy.deepcopy(x) for x in templates]\n",
    "    \n",
    "    for i in range(len(local_models)-1):\n",
    "            \n",
    "        if len(train_splits[i]) == 0:\n",
    "            local_models[i] = None\n",
    "        else:\n",
    "            if f\"global{i}.pth\" in os.listdir(\"Content_FL_Exp\"):\n",
    "                local_models[i].load_state_dict(torch.load(f\"Content_FL_Exp/global{i}.pth\"))\n",
    "\n",
    "            optimizer = torch.optim.Adam(local_models[i].parameters(), lr=0.01, weight_decay=5e-4)\n",
    "            criterion = CrossEntropyLoss()\n",
    "\n",
    "            graph = Data(x=torch.tensor(nodes,dtype=torch.float).to(device),y=torch.tensor(labels,dtype=torch.long).to(device), edge_index=torch.tensor(edges,dtype=torch.long).to(device))\n",
    "            mask = torch.tensor([False]*graph.num_nodes, dtype=torch.bool)\n",
    "            mask[train_splits[i]] = True\n",
    "            \n",
    "            def get_neighbors(edge_index, nodes):\n",
    "                neighbors = []\n",
    "                for node in nodes:\n",
    "                    mask = edge_index[0] == node\n",
    "                    neighbors.extend(edge_index[1, mask].tolist())\n",
    "                return torch.tensor(list(set(neighbors)), dtype=torch.long)\n",
    "\n",
    "            one_hop_neighbors = get_neighbors(graph.edge_index, train_splits[i])\n",
    "            two_hop_neighbors = get_neighbors(graph.edge_index, one_hop_neighbors)\n",
    "            two_hop_neighbors = two_hop_neighbors[~mask[two_hop_neighbors]]\n",
    "            mask[two_hop_neighbors] = True\n",
    "            \n",
    "            for epoch in range(epochs):\n",
    "                print(f'Training GNN Category {i} Model for Epoch {epoch}')\n",
    "\n",
    "                loader = NeighborLoader(graph, num_neighbors=[-1,-1], batch_size=5000,input_nodes=mask)\n",
    "                total_loss = 0\n",
    "                for subg in loader:\n",
    "                    local_models[i].train()\n",
    "                    optimizer.zero_grad() \n",
    "                    out = local_models[i](subg.x, subg.edge_index) \n",
    "                    loss = criterion(out, subg.y) \n",
    "                    loss.backward() \n",
    "                    optimizer.step()      \n",
    "                    total_loss += loss.item() * subg.batch_size\n",
    "                print(\"Loss: \", total_loss / mask.sum().item(), '\\n')\n",
    "    \n",
    "    graph = Data(x=torch.tensor(nodes,dtype=torch.float).to(device),y=torch.tensor(labels,dtype=torch.long).to(device), edge_index=torch.tensor(edges,dtype=torch.long).to(device))\n",
    "    optimizer = torch.optim.Adam(local_models[-1].parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    criterion = CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f'Training Catch all GNN Category Model for Epoch {epoch}')    \n",
    "        local_models[-1].train()\n",
    "        optimizer.zero_grad() \n",
    "        out = local_models[-1](graph.x, graph.edge_index) \n",
    "        loss = criterion(out, graph.y) \n",
    "        loss.backward() \n",
    "        optimizer.step()      \n",
    "        print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "    return local_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def client_handling_loop(client_id):\n",
    "    print(f\"Running Setup on Client {client_id} \\n\")\n",
    "    \n",
    "    docs,labels,edges,mapp,pids,idx_to_pid = data_cache[client_id]\n",
    "    \n",
    "    nodes_feat = []\n",
    "    word2vec = Word2Vec.load(f\"Content_FL_Exp/unified_word2vec.model\")\n",
    "    for x in docs:\n",
    "        nodes_feat.append( infer(x,word2vec) ) \n",
    "        \n",
    "    trained_local_models = train_gnn_func(nodes_feat,labels,edges,mapp,pids,idx_to_pid)\n",
    "    return trained_local_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def perform_federated_learning(n_clients):\n",
    "    client_models = []\n",
    "    for c in n_clients:\n",
    "        local_gnns = client_handling_loop(c)\n",
    "        client_models.append(local_gnns)\n",
    "    return client_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def server_aggregate(all_models):\n",
    "    global_models = copy.deepcopy(templates)\n",
    "    \n",
    "    for l in range(len(all_models)):\n",
    "        \n",
    "        current_models = all_models[l]\n",
    "        current_models = [x for x in current_models if x != None]\n",
    "        \n",
    "        if not len(current_models) == 0:\n",
    "        \n",
    "            global_dict = global_models[l].state_dict()\n",
    "\n",
    "            for k in global_dict.keys():\n",
    "                param_list = [current_models[i].state_dict()[k] for i in range(len(current_models))]\n",
    "                global_dict[k] = torch.stack(param_list, 0).mean(0)\n",
    "\n",
    "            global_models[l].load_state_dict(global_dict)\n",
    "            torch.save(global_models[l].state_dict(), f\"Content_FL_Exp/global{l}.pth\")\n",
    "                   \n",
    "    return global_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import compress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def helper(MP,acts,objs,GP,edges,mapp):\n",
    "\n",
    "    all_pids = acts.union(objs)\n",
    "    GN = all_pids - GP\n",
    "    MN = all_pids - MP\n",
    "\n",
    "    TP = MP.intersection(GP)\n",
    "    FP = MP.intersection(GN)\n",
    "    FN = MN.intersection(GP)\n",
    "    \n",
    "    two_hop_gp = construct_neighborhood(GP,mapp,edges,2)\n",
    "    two_hop_tp = construct_neighborhood(TP,mapp,edges,2)\n",
    "    FP = FP - two_hop_gp\n",
    "    TP = TP.union(FN.intersection(two_hop_tp))\n",
    "    FN = FN - two_hop_tp\n",
    "\n",
    "    TP,FPC,FN = len(TP),len(FP),len(FN)\n",
    "    \n",
    "    TN = (len(acts) + len(objs)) - TP - FPC - FN\n",
    "    \n",
    "    FPR = FPC / (FPC+TN)\n",
    "    TPR = TP / (TP+FN)\n",
    "    \n",
    "    return TP,FPC,FN,TN,FP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import compress\n",
    "from torch_geometric import utils\n",
    "\n",
    "def construct_neighborhood(ids,mapp,edges,hops):\n",
    "    if hops == 0:\n",
    "        return set()\n",
    "    else:\n",
    "        neighbors = set()\n",
    "        for i in range(len(edges[0])):\n",
    "            if mapp[edges[0][i]] in ids:\n",
    "                neighbors.add(mapp[edges[1][i]])\n",
    "            if mapp[edges[1][i]] in ids:\n",
    "                neighbors.add(mapp[edges[0][i]])\n",
    "        return neighbors.union( construct_neighborhood(neighbors,mapp,edges,hops-1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    !rm Content_FL_Exp/global*.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_clients_data(hosts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('Content_FL_Exp/optc_ensemble_ben.json', 'r') as f:\n",
    "    data_cache = json.load(f)\n",
    "\n",
    "proc_total = []\n",
    "for x in ['051.txt','501.txt','201.txt']:\n",
    "    proc_total = proc_total + data_cache[x][-2]\n",
    "    \n",
    "categories = define_categories(proc_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "if TRAIN:\n",
    "    for r in range(learning_rounds):\n",
    "        print(f\"Federated Learning Round Number: {r}\\n\")\n",
    "        client_models = perform_federated_learning(hosts)\n",
    "        arranged_models =  [list(group) for group in zip(*client_models)]\n",
    "        global_models = server_aggregate(arranged_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_cache_mal = {}\n",
    "\n",
    "def load_test_data():\n",
    "    global data_cache_mal\n",
    "        \n",
    "    for x in ['201','501','051']:\n",
    "        path = f\"Content_FL_Exp/eval_data/SysClient0{x}.systemia.com.txt\"\n",
    "        f = open(path)\n",
    "        content = [json.loads(line) for line in f]\n",
    "        docs,labels,edges,mapp,pids,idx_to_pid = prepare_graph(transform(content))\n",
    "        data_cache_mal[x] = [docs,labels,edges,mapp,pids,idx_to_pid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_data_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('Content_FL_Exp/optc_ensemble_mal.json', 'r') as f:\n",
    "    data_cache_mal = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of True Positives: 615\n",
      "Number of Fasle Positives: 65\n",
      "Number of False Negatives: 35\n",
      "Precision: 0.9044117647058824\n",
      "Recall: 0.9461538461538461\n",
      "Fscore: 0.9248120300751879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TP,FP,FN,TN = 0,0,0,0\n",
    "FPL = set()\n",
    "for data_id in ['201','501','051']:\n",
    "\n",
    "    docs,labels,edges,mapp,pids,idx_to_pid = data_cache_mal[data_id]\n",
    "\n",
    "    nodes_feat = []\n",
    "    word2vec = Word2Vec.load(f\"Content_FL_Exp/unified_word2vec.model\")\n",
    "    for x in docs:\n",
    "        nodes_feat.append( infer(x,word2vec) ) \n",
    "\n",
    "    with open(f\"gt_{data_id}.json\", \"r\") as json_file:\n",
    "        gt,acts,objs = json.load(json_file)  \n",
    "\n",
    "    gt,acts,objs = set(gt),set(acts),set(objs)\n",
    "\n",
    "    graph = Data(x=torch.tensor(nodes_feat,dtype=torch.float).to(device),y=torch.tensor(labels,dtype=torch.long).to(device), edge_index=torch.tensor(edges,dtype=torch.long).to(device))\n",
    "\n",
    "    flag = torch.tensor([True]*graph.num_nodes, dtype=torch.bool)\n",
    "\n",
    "    model = GCN().to(device)\n",
    "\n",
    "    for m_n in range(num_of_ctg):\n",
    "        if f\"global{m_n}.pth\" in os.listdir(\"Content_FL_Exp\"): \n",
    "            model.load_state_dict(torch.load(f\"Content_FL_Exp/global{m_n}.pth\",map_location=torch.device('cpu')))\n",
    "            \n",
    "        model.eval()\n",
    "        out = model(graph.x, graph.edge_index)\n",
    "\n",
    "        sorted, indices = out.sort(dim=1,descending=True)\n",
    "        conf = (sorted[:,0] - sorted[:,1]) / sorted[:,0]\n",
    "        conf = (conf - conf.min()) / conf.max()\n",
    "\n",
    "        pred = indices[:,0]\n",
    "        cond = (pred == graph.y) & (conf >= 0.7)\n",
    "        flag[cond] = torch.logical_and(flag[cond], torch.tensor([False]*len(flag[cond]), dtype=torch.bool))\n",
    "\n",
    "    index = utils.mask_to_index(flag).tolist()\n",
    "    ids = set([mapp[x] for x in index])\n",
    "\n",
    "    metrics = helper(set(ids),acts,objs,gt,edges,mapp) \n",
    "        \n",
    "    fp = [i for i in range(len(mapp)) if mapp[i] in metrics[4] and labels[i] in [0,1,2]]\n",
    "          \n",
    "    TP = TP + metrics[0]\n",
    "    FP = FP + len(fp)\n",
    "    FN = FN + metrics[2]\n",
    "    TN = TN + metrics[3]\n",
    "\n",
    "print(f\"Number of True Positives: {TP}\")\n",
    "print(f\"Number of Fasle Positives: {FP}\")\n",
    "print(f\"Number of False Negatives: {FN}\")\n",
    "\n",
    "prec = TP / (TP + FP)\n",
    "print(f\"Precision: {prec}\")\n",
    "\n",
    "rec = TP / (TP + FN)\n",
    "print(f\"Recall: {rec}\")\n",
    "\n",
    "fscore = (2*prec*rec) / (prec + rec)\n",
    "print(f\"Fscore: {fscore}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "\n",
    "# Define the visualization function\n",
    "def visualize_explanation(node_idx, graph, explanation):\n",
    "    # Extract the subgraph around the node of interest\n",
    "    subset, edge_index, mapping, hard_edge_mask = k_hop_subgraph(\n",
    "        node_idx, num_hops=2, edge_index=graph.edge_index, relabel_nodes=True\n",
    "    )\n",
    "    edge_mask = explanation.edge_mask[hard_edge_mask].cpu().detach().numpy()\n",
    "    edge_mask = (edge_mask - edge_mask.min()) / (edge_mask.max() - edge_mask.min() + 1e-6)\n",
    "    \n",
    "    # Create a NetworkX graph\n",
    "    G = nx.Graph()\n",
    "    edge_list = edge_index.cpu().numpy().T\n",
    "    G.add_edges_from(edge_list)\n",
    "    \n",
    "    # Get node labels from graph.node_labels\n",
    "    subset_indices = subset.cpu().numpy()\n",
    "    node_labels = [graph.node_labels[i] for i in subset_indices]\n",
    "    \n",
    "    # Initialize PyVis network\n",
    "    net = Network(notebook=True, cdn_resources='in_line', width='100%', height='750px')\n",
    "    \n",
    "    # Add nodes with labels and colors\n",
    "    for i, node in enumerate(G.nodes()):\n",
    "        node = int(node)  # Ensure node ID is an int\n",
    "        label = node_labels[i]\n",
    "        # Shorten label for display if necessary\n",
    "        short_label = label if len(label) <= 15 else label[:15] + '...'\n",
    "        title = f\"Node {subset_indices[i]}: {label}\"\n",
    "        color = 'red' if int(subset_indices[i]) == int(node_idx) else 'blue'\n",
    "        net.add_node(node, label=short_label, title=title, color=color)\n",
    "    \n",
    "    # Add edges with edge weights (from edge_mask)\n",
    "    for i, (u, v) in enumerate(G.edges()):\n",
    "        u = int(u)  # Ensure node IDs are ints\n",
    "        v = int(v)\n",
    "        weight = float(edge_mask[i])  # Convert weight to native Python float\n",
    "        net.add_edge(u, v, value=weight, title=f\"Edge weight: {weight:.2f}\")\n",
    "    \n",
    "    # Customize physics and layout\n",
    "    net.set_options(\"\"\"\n",
    "    var options = {\n",
    "      \"physics\": {\n",
    "        \"forceAtlas2Based\": {\n",
    "          \"gravitationalConstant\": -50,\n",
    "          \"centralGravity\": 0.01,\n",
    "          \"springLength\": 100,\n",
    "          \"springConstant\": 0.08\n",
    "        },\n",
    "        \"maxVelocity\": 50,\n",
    "        \"solver\": \"forceAtlas2Based\",\n",
    "        \"timestep\": 0.35,\n",
    "        \"stabilization\": {\"iterations\": 150}\n",
    "      }\n",
    "    }\n",
    "    \"\"\")\n",
    "    \n",
    "    # Display the interactive network\n",
    "    net.show('../graph_explanation.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import Explainer, GNNExplainer\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "\n",
    "TP, FP, FN, TN = 0, 0, 0, 0\n",
    "FPL = set()\n",
    "data_id = '051'\n",
    "\n",
    "docs, labels, edges, mapp, pids, idx_to_pid = data_cache_mal[data_id]\n",
    "\n",
    "for i in range(len(docs)):\n",
    "    docs[i] = [s for s in docs[i] if s]\n",
    "    \n",
    "node_labels = [x[2] if x else \"Undefined\" for x in docs]\n",
    "\n",
    "nodes_feat = []\n",
    "word2vec = Word2Vec.load(f\"Content_FL_Exp/unified_word2vec.model\")\n",
    "for x in docs:\n",
    "    nodes_feat.append(infer(x, word2vec))\n",
    "\n",
    "with open(f\"gt_{data_id}.json\", \"r\") as json_file:\n",
    "    gt, acts, objs = json.load(json_file)\n",
    "\n",
    "gt, acts, objs = set(gt), set(acts), set(objs)\n",
    "\n",
    "graph = Data(\n",
    "    x=torch.tensor(nodes_feat, dtype=torch.float).to(device),\n",
    "    y=torch.tensor(labels, dtype=torch.long).to(device),\n",
    "    edge_index=torch.tensor(edges, dtype=torch.long).to(device)\n",
    ")\n",
    "\n",
    "graph.node_labels = node_labels\n",
    "\n",
    "flag = torch.tensor([True] * graph.num_nodes, dtype=torch.bool)\n",
    "\n",
    "model = GCN().to(device)\n",
    "\n",
    "for m_n in range(num_of_ctg):\n",
    "    if f\"global{m_n}.pth\" in os.listdir(\"Content_FL_Exp\"):\n",
    "        model.load_state_dict(torch.load(f\"Content_FL_Exp/global{m_n}.pth\", map_location=torch.device('cpu')))\n",
    "\n",
    "    model.eval()\n",
    "    out = model(graph.x, graph.edge_index)\n",
    "\n",
    "    sorted, indices = out.sort(dim=1, descending=True)\n",
    "    conf = (sorted[:, 0] - sorted[:, 1]) / sorted[:, 0]\n",
    "    conf = (conf - conf.min()) / conf.max()\n",
    "\n",
    "    pred = indices[:, 0]\n",
    "    cond = (pred == graph.y) & (conf >= 0.7)\n",
    "    flag[cond] = torch.logical_and(flag[cond], torch.tensor([False] * len(flag[cond]), dtype=torch.bool))\n",
    "\n",
    "index = utils.mask_to_index(flag).tolist()\n",
    "ids = set([mapp[x] for x in index])\n",
    "\n",
    "metrics = helper(set(ids), acts, objs, gt, edges, mapp)\n",
    "\n",
    "fp = [i for i in range(len(mapp)) if mapp[i] in metrics[4] and labels[i] in [0, 1, 2]]\n",
    "\n",
    "TP = TP + metrics[0]\n",
    "FP = FP + len(fp)\n",
    "FN = FN + metrics[2]\n",
    "TN = TN + metrics[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Index 900, Loss 0.32459557056427\n",
      "Epoch 1, Index 900, Loss 0.3059388995170593\n",
      "Epoch 2, Index 900, Loss 0.34295621514320374\n",
      "Epoch 3, Index 900, Loss 0.3244819641113281\n",
      "Epoch 4, Index 900, Loss 0.340915709733963\n",
      "Epoch 5, Index 900, Loss 0.30620065331459045\n",
      "Epoch 6, Index 900, Loss 0.3348388075828552\n",
      "Epoch 7, Index 900, Loss 0.28341543674468994\n",
      "Epoch 8, Index 900, Loss 0.3204033374786377\n",
      "Epoch 9, Index 900, Loss 0.3351432681083679\n",
      "Epoch 10, Index 900, Loss 0.3182681202888489\n",
      "Epoch 11, Index 900, Loss 0.30358701944351196\n",
      "Epoch 12, Index 900, Loss 0.3247605860233307\n",
      "Epoch 13, Index 900, Loss 0.2685743570327759\n",
      "Epoch 14, Index 900, Loss 0.27715545892715454\n",
      "Epoch 15, Index 900, Loss 0.25207388401031494\n",
      "Epoch 16, Index 900, Loss 0.14641112089157104\n",
      "Epoch 17, Index 900, Loss 0.26627397537231445\n",
      "Epoch 18, Index 900, Loss 0.267794668674469\n",
      "Epoch 19, Index 900, Loss 0.09481802582740784\n",
      "Epoch 20, Index 900, Loss 0.1924840211868286\n",
      "Epoch 21, Index 900, Loss 0.15308839082717896\n",
      "Epoch 22, Index 900, Loss 0.09545111656188965\n",
      "Epoch 23, Index 900, Loss 0.12177136540412903\n",
      "Epoch 24, Index 900, Loss 0.056634366512298584\n",
      "Epoch 25, Index 900, Loss 0.03810703754425049\n",
      "Epoch 26, Index 900, Loss 0.04164484143257141\n",
      "Epoch 27, Index 900, Loss 0.09162342548370361\n",
      "Epoch 28, Index 900, Loss -0.07956576347351074\n",
      "Epoch 29, Index 900, Loss -0.07149261236190796\n",
      "../graph_explanation.html\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.explain import Explainer, PGExplainer, ModelConfig\n",
    "import torch\n",
    "\n",
    "# Ensure the model is in evaluation mode during explanation setup\n",
    "model.eval()\n",
    "\n",
    "# Initialize the Explainer with PGExplainer\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=PGExplainer(epochs=30, lr=0.003),\n",
    "    explanation_type='phenomenon',\n",
    "    edge_mask_type='object',\n",
    "    model_config=ModelConfig(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='log_probs'\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Train the explainer on a set of indices\n",
    "# Ensure to replace `[...]` with actual indices you want to train against\n",
    "for epoch in range(30):\n",
    "    for index in [900]:  # Replace `[...]` with the actual list of indices\n",
    "        loss = explainer.algorithm.train(\n",
    "            epoch,\n",
    "            model,\n",
    "            graph.x,\n",
    "            graph.edge_index,\n",
    "            target=graph.y,\n",
    "            index=index\n",
    "        )\n",
    "        print(f\"Epoch {epoch}, Index {index}, Loss {loss}\")\n",
    "\n",
    "# Use the explainer on a specific node index\n",
    "explanation = explainer(\n",
    "    x=graph.x,\n",
    "    edge_index=graph.edge_index,\n",
    "    target=graph.y,\n",
    "    index=10\n",
    ")\n",
    "\n",
    "# Visualization or further processing of the explanation\n",
    "# This might involve a function like visualize_explanation if available\n",
    "visualize_explanation(node_idx, graph, explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../graph_explanation.html\n"
     ]
    }
   ],
   "source": [
    "# === GNNExplainer Integration ===\n",
    "# Initialize the Explainer\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(epochs=200),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='log_probs',\n",
    "    ),\n",
    ")\n",
    "\n",
    "pred = indices[:, 0]\n",
    "misclassified = (pred != graph.y) & (graph.y == 0)\n",
    "nodes_to_explain = misclassified.nonzero(as_tuple=False).squeeze().tolist()\n",
    "\n",
    "node_idx = nodes_to_explain[900]\n",
    "\n",
    "explanation = explainer(\n",
    "    x=graph.x,\n",
    "    edge_index=graph.edge_index,\n",
    "    target=graph.y,\n",
    "    index=node_idx,\n",
    ")\n",
    "\n",
    "visualize_explanation(node_idx, graph, explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train explainer for node(s) tensor([40481]) with layer 1: 100%|███████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:04<00:00, 22.21it/s]\n",
      "Train explainer for node(s) tensor([40481]) with layer 0: 100%|███████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:09<00:00, 11.07it/s]\n",
      "Explain: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 148.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../graph_explanation.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.explain import Explainer, GNNExplainer, AttentionExplainer, GraphMaskExplainer\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GraphMaskExplainer(num_layers=2),\n",
    "    explanation_type='model',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='log_probs',\n",
    "    ),\n",
    ")\n",
    "\n",
    "pred = indices[:, 0]\n",
    "misclassified = (pred != graph.y) & (graph.y == 0)\n",
    "nodes_to_explain = misclassified.nonzero(as_tuple=False).squeeze().tolist()\n",
    "\n",
    "node_idx = nodes_to_explain[900]\n",
    "\n",
    "explanation = explainer(\n",
    "    x=graph.x,\n",
    "    edge_index=graph.edge_index,\n",
    "    target=graph.y,\n",
    "    index=node_idx,\n",
    ")\n",
    "\n",
    "visualize_explanation(node_idx, graph, explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explanation.visualize_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\Device\\\\HarddiskVolume1\\\\Program'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.node_labels[6966]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indices for 051\n",
    "#1000\n",
    "#1009\n",
    "#900"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
