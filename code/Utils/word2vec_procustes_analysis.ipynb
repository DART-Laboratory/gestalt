{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import json\n",
    "import copy\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from multiprocessing import Pool\n",
    "from itertools import compress\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import multiprocessing\n",
    "import random\n",
    "import xxhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procrustes(X, Y, scaling=True, reflection='best'):\n",
    "    \"\"\"\n",
    "    A port of MATLAB's `procrustes` function to Numpy.\n",
    "\n",
    "    Procrustes analysis determines a linear transformation (translation,\n",
    "    reflection, orthogonal rotation and scaling) of the points in Y to best\n",
    "    conform them to the points in matrix X, using the sum of squared errors\n",
    "    as the goodness of fit criterion.\n",
    "\n",
    "        d, Z, [tform] = procrustes(X, Y)\n",
    "\n",
    "    Inputs:\n",
    "    ------------\n",
    "    X, Y    \n",
    "        matrices of target and input coordinates. they must have equal\n",
    "        numbers of  points (rows), but Y may have fewer dimensions\n",
    "        (columns) than X.\n",
    "\n",
    "    scaling \n",
    "        if False, the scaling component of the transformation is forced\n",
    "        to 1\n",
    "\n",
    "    reflection\n",
    "        if 'best' (default), the transformation solution may or may not\n",
    "        include a reflection component, depending on which fits the data\n",
    "        best. setting reflection to True or False forces a solution with\n",
    "        reflection or no reflection respectively.\n",
    "\n",
    "    Outputs\n",
    "    ------------\n",
    "    d       \n",
    "        the residual sum of squared errors, normalized according to a\n",
    "        measure of the scale of X, ((X - X.mean(0))**2).sum()\n",
    "\n",
    "    Z\n",
    "        the matrix of transformed Y-values\n",
    "\n",
    "    tform   \n",
    "        a dict specifying the rotation, translation and scaling that\n",
    "        maps X --> Y\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    n,m = X.shape\n",
    "    ny,my = Y.shape\n",
    "\n",
    "    muX = X.mean(0)\n",
    "    muY = Y.mean(0)\n",
    "\n",
    "    X0 = X - muX\n",
    "    Y0 = Y - muY\n",
    "\n",
    "    ssX = (X0**2.).sum()\n",
    "    ssY = (Y0**2.).sum()\n",
    "\n",
    "    # centred Frobenius norm\n",
    "    normX = np.sqrt(ssX)\n",
    "    normY = np.sqrt(ssY)\n",
    "\n",
    "    # scale to equal (unit) norm\n",
    "    X0 /= normX\n",
    "    Y0 /= normY\n",
    "\n",
    "    if my < m:\n",
    "        Y0 = np.concatenate((Y0, np.zeros(n, m-my)),0)\n",
    "\n",
    "    # optimum rotation matrix of Y\n",
    "    A = np.dot(X0.T, Y0)\n",
    "    U,s,Vt = np.linalg.svd(A,full_matrices=False)\n",
    "    V = Vt.T\n",
    "    T = np.dot(V, U.T)\n",
    "\n",
    "    if reflection != 'best':\n",
    "\n",
    "        # does the current solution use a reflection?\n",
    "        have_reflection = np.linalg.det(T) < 0\n",
    "\n",
    "        # if that's not what was specified, force another reflection\n",
    "        if reflection != have_reflection:\n",
    "            V[:,-1] *= -1\n",
    "            s[-1] *= -1\n",
    "            T = np.dot(V, U.T)\n",
    "\n",
    "    traceTA = s.sum()\n",
    "\n",
    "    if scaling:\n",
    "\n",
    "        # optimum scaling of Y\n",
    "        b = traceTA * normX / normY\n",
    "\n",
    "        # standarised distance between X and b*Y*T + c\n",
    "        d = 1 - traceTA**2\n",
    "\n",
    "        # transformed coords\n",
    "        Z = normX*traceTA*np.dot(Y0, T) + muX\n",
    "\n",
    "    else:\n",
    "        b = 1\n",
    "        d = 1 + ssY/ssX - 2 * traceTA * normY / normX\n",
    "        Z = normY*np.dot(Y0, T) + muX\n",
    "\n",
    "    # transformation matrix\n",
    "    if my < m:\n",
    "        T = T[:my,:]\n",
    "    c = muX - b*np.dot(muY, T)\n",
    "    \n",
    "    #transformation values \n",
    "    tform = {'rotation':T, 'scale':b, 'translation':c}\n",
    "   \n",
    "    return d, Z, tform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "def align_word2vec_models(models, overlap_percentage):\n",
    "    # Check if there are at least two models to align\n",
    "    if len(models) < 2:\n",
    "        raise ValueError(\"At least two models are required for alignment.\")\n",
    "    \n",
    "    np.random.seed(42)  # Set the random seed for reproducibility\n",
    "\n",
    "    # Determine the overlapping vocabulary\n",
    "    common_vocab = set(models[0].wv.index_to_key)\n",
    "    for model in models[1:]:\n",
    "        common_vocab = common_vocab.intersection(set(model.wv.index_to_key))\n",
    "\n",
    "    # Calculate the sample size based on the specified percentage\n",
    "    sample_size = int(len(common_vocab) * overlap_percentage / 100)\n",
    "\n",
    "    # Randomly select vocabulary words from the overlapping set\n",
    "    sampled_vocab = np.random.choice(list(common_vocab), size=sample_size, replace=False)\n",
    "\n",
    "    # Extract vectors for the sampled vocabulary from all models\n",
    "    vectors = []\n",
    "    vocab = None\n",
    "    for model in models:\n",
    "        def get_vectors_for_vocab(model, vocab):\n",
    "            vectors = []\n",
    "            for word in vocab:\n",
    "                vectors.append(model.wv[word])\n",
    "            return np.array(vectors)\n",
    "\n",
    "        model_vectors = get_vectors_for_vocab(model, sampled_vocab)\n",
    "        vectors.append(model_vectors)\n",
    "        vocab = sampled_vocab\n",
    "        \n",
    "    # Reset the random seed to its original state\n",
    "    np.random.seed(None)\n",
    "\n",
    "    # Perform Procrustes analysis for each model with respect to the first model\n",
    "    aligned_models = []\n",
    "    for i, model in enumerate(models):\n",
    "        if i == 0:\n",
    "            aligned_model = model  # No transformation needed for the first model\n",
    "        else:\n",
    "            _, _, tform = procrustes(vectors[0], vectors[i], scaling=True)\n",
    "            aligned_vectors = np.dot(model.wv.vectors, tform['rotation']) * tform['scale'] + tform['translation']\n",
    "            aligned_model = Word2Vec(vector_size=model.vector_size, window=model.window, min_count=model.min_count, sg=model.sg)\n",
    "            aligned_model.build_vocab([model.wv.index_to_key])  # Use the original vocabulary\n",
    "            aligned_model.wv.vectors = aligned_vectors\n",
    "\n",
    "        aligned_models.append(aligned_model)\n",
    "\n",
    "    return aligned_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def calculate_disparity(models):\n",
    "    # Find common vocabulary\n",
    "    common_vocab = set(models[0].wv.index_to_key)\n",
    "    for model in models[1:]:\n",
    "        common_vocab &= set(model.wv.index_to_key)\n",
    "\n",
    "    # Calculate disparity between each pair of models\n",
    "    num_models = len(models)\n",
    "    disparities = np.zeros((num_models, num_models))\n",
    "\n",
    "    for i, j in combinations(range(num_models), 2):\n",
    "        common_vectors_i = [models[i].wv[word] for word in common_vocab]\n",
    "        common_vectors_j = [models[j].wv[word] for word in common_vocab]\n",
    "\n",
    "        # Compute the sum of square differences\n",
    "        disparity = sum(np.sum((np.array(common_vectors_i) - np.array(common_vectors_j))**2, axis=1))\n",
    "        disparities[i, j] = disparity\n",
    "        disparities[j, i] = disparity\n",
    "\n",
    "    return disparities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rounded_matrix(matrix):\n",
    "    for row in matrix:\n",
    "        print([round(value) for value in row])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Word2Vec.load(\"Content_FL_Exp/051.txt.model\")\n",
    "model2 = Word2Vec.load(\"Content_FL_Exp/201.txt.model\")\n",
    "model3 = Word2Vec.load(\"Content_FL_Exp/501.txt.model\")\n",
    "\n",
    "models = [model1, model2, model3]\n",
    "\n",
    "disparities = calculate_disparity(models)\n",
    "\n",
    "print(\"Disparity Matrix:\")\n",
    "print_rounded_matrix(disparities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for overlap in range(10,100,10):\n",
    "    aligned_models = align_word2vec_models([model1, model2, model3], overlap_percentage=overlap)\n",
    "\n",
    "    disparities = calculate_disparity(aligned_models)\n",
    "\n",
    "    print(\"Disparity Matrix:\")\n",
    "    print_rounded_matrix(disparities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.12.0",
   "language": "python",
   "name": "pytorch-1.12.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
